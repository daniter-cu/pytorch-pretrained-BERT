{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n"
     ]
    }
   ],
   "source": [
    "res = predictor.predict(\n",
    "  sentence=\"If I bring 10 dollars tomorrow, can you buy me lunch?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_probabilities', 'spans', 'tokens', 'pos_tags', 'num_spans', 'hierplane_tree', 'trees'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spans\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [9, 9], [9, 10], [9, 11], [9, 12], [10, 10], [10, 11], [10, 12], [11, 11], [11, 12], [12, 12]]\n",
      "####################\n",
      "tokens\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['If', 'I', 'bring', '10', 'dollars', 'tomorrow', ',', 'can', 'you', 'buy', 'me', 'lunch', '?']\n",
      "####################\n",
      "pos_tags\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['IN', 'PRP', 'VBP', 'CD', 'NNS', 'NN', ',', 'MD', 'PRP', 'VB', 'PRP', 'NN', '.']\n",
      "####################\n",
      "num_spans\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "91\n",
      "####################\n",
      "hierplane_tree\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "{'linkNameToLabel': {'.': 'pos', ',': 'pos', '-LRB-': 'pos', '-RRB-': 'pos', '``': 'pos', '\"\"': 'pos', \"''\": 'pos', ':': 'pos', '$': 'pos', '#': 'pos', 'AFX': 'pos', 'CC': 'pos', 'CD': 'pos', 'DT': 'pos', 'EX': 'pos', 'FW': 'pos', 'HYPH': 'pos', 'IN': 'pos', 'JJ': 'pos', 'JJR': 'pos', 'JJS': 'pos', 'LS': 'pos', 'MD': 'pos', 'NIL': 'pos', 'NN': 'pos', 'NNP': 'pos', 'NNPS': 'pos', 'NNS': 'pos', 'PDT': 'pos', 'POS': 'pos', 'PRP': 'pos', 'PRP$': 'pos', 'RB': 'pos', 'RBR': 'pos', 'RBS': 'pos', 'RP': 'pos', 'SP': 'pos', 'SYM': 'pos', 'TO': 'pos', 'UH': 'pos', 'VB': 'pos', 'VBD': 'pos', 'VBG': 'pos', 'VBN': 'pos', 'VBP': 'pos', 'VBZ': 'pos', 'WDT': 'pos', 'WP': 'pos', 'WP$': 'pos', 'WRB': 'pos', 'ADD': 'pos', 'NFP': 'pos', 'GW': 'pos', 'XX': 'pos', 'BES': 'pos', 'HVS': 'pos', '_SP': 'pos'}, 'nodeTypeToStyle': {'.': ['color0'], ',': ['color0'], '-LRB-': ['color0'], '-RRB-': ['color0'], '``': ['color0'], '\"\"': ['color0'], \"''\": ['color0'], ':': ['color0'], '$': ['color0'], '#': ['color0'], 'AFX': ['color0'], 'CC': ['color0'], 'CD': ['color0'], 'DT': ['color0'], 'EX': ['color0'], 'FW': ['color0'], 'HYPH': ['color0'], 'IN': ['color0'], 'JJ': ['color0'], 'JJR': ['color0'], 'JJS': ['color0'], 'LS': ['color0'], 'MD': ['color0'], 'NIL': ['color0'], 'NN': ['color0'], 'NNP': ['color0'], 'NNPS': ['color0'], 'NNS': ['color0'], 'PDT': ['color0'], 'POS': ['color0'], 'PRP': ['color0'], 'PRP$': ['color0'], 'RB': ['color0'], 'RBR': ['color0'], 'RBS': ['color0'], 'RP': ['color0'], 'SP': ['color0'], 'SYM': ['color0'], 'TO': ['color0'], 'UH': ['color0'], 'VB': ['color0'], 'VBD': ['color0'], 'VBG': ['color0'], 'VBN': ['color0'], 'VBP': ['color0'], 'VBZ': ['color0'], 'WDT': ['color0'], 'WP': ['color0'], 'WP$': ['color0'], 'WRB': ['color0'], 'ADD': ['color0'], 'NFP': ['color0'], 'GW': ['color0'], 'XX': ['color0'], 'BES': ['color0'], 'HVS': ['color0'], '_SP': ['color0'], 'NP': ['color1'], 'NX': ['color1'], 'QP': ['color1'], 'NAC': ['color1'], 'VP': ['color2'], 'S': ['color3'], 'SQ': ['color3'], 'SBAR': ['color3'], 'SBARQ': ['color3'], 'SINQ': ['color3'], 'FRAG': ['color3'], 'X': ['color3'], 'WHADVP': ['color4'], 'WHADJP': ['color4'], 'WHNP': ['color4'], 'WHPP': ['color4'], 'PP': ['color6'], 'ADJP': ['color5'], 'ADVP': ['color5'], 'CONJP': ['color5'], 'INTJ': ['color5'], 'LST': ['color5', 'seq'], 'PRN': ['color5'], 'PRT': ['color5'], 'RRC': ['color5'], 'UCP': ['color5']}, 'text': 'If I bring 10 dollars tomorrow , can you buy me lunch ?', 'root': {'word': 'If I bring 10 dollars tomorrow , can you buy me lunch ?', 'nodeType': 'SQ', 'attributes': ['SQ'], 'link': 'SQ', 'children': [{'word': 'If I bring 10 dollars tomorrow', 'nodeType': 'SBAR', 'attributes': ['SBAR'], 'link': 'SBAR', 'children': [{'word': 'If', 'nodeType': 'IN', 'attributes': ['IN'], 'link': 'IN'}, {'word': 'I bring 10 dollars tomorrow', 'nodeType': 'S', 'attributes': ['S'], 'link': 'S', 'children': [{'word': 'I', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'I', 'nodeType': 'PRP', 'attributes': ['PRP'], 'link': 'PRP'}]}, {'word': 'bring 10 dollars tomorrow', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'bring', 'nodeType': 'VBP', 'attributes': ['VBP'], 'link': 'VBP'}, {'word': '10 dollars', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': '10', 'nodeType': 'CD', 'attributes': ['CD'], 'link': 'CD'}, {'word': 'dollars', 'nodeType': 'NNS', 'attributes': ['NNS'], 'link': 'NNS'}]}, {'word': 'tomorrow', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'tomorrow', 'nodeType': 'NN', 'attributes': ['NN'], 'link': 'NN'}]}]}]}]}, {'word': ',', 'nodeType': ',', 'attributes': [','], 'link': ','}, {'word': 'can', 'nodeType': 'MD', 'attributes': ['MD'], 'link': 'MD'}, {'word': 'you', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'you', 'nodeType': 'PRP', 'attributes': ['PRP'], 'link': 'PRP'}]}, {'word': 'buy me lunch', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'buy', 'nodeType': 'VB', 'attributes': ['VB'], 'link': 'VB'}, {'word': 'me', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'me', 'nodeType': 'PRP', 'attributes': ['PRP'], 'link': 'PRP'}]}, {'word': 'lunch', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'lunch', 'nodeType': 'NN', 'attributes': ['NN'], 'link': 'NN'}]}]}, {'word': '?', 'nodeType': '.', 'attributes': ['.'], 'link': '.'}]}}\n",
      "####################\n",
      "trees\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "(SQ (SBAR (IN If) (S (NP (PRP I)) (VP (VBP bring) (NP (CD 10) (NNS dollars)) (NP (NN tomorrow))))) (, ,) (MD can) (NP (PRP you)) (VP (VB buy) (NP (PRP me)) (NP (NN lunch))) (. ?))\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "for k, v in res.items():\n",
    "    if k == 'class_probabilities':\n",
    "        continue\n",
    "    print(k)\n",
    "    print(\"~\"*20)\n",
    "    print(v)\n",
    "    print(\"#\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SQ   \n",
    " (SBAR    \n",
    "  (IN If)    \n",
    "  (S    \n",
    "   (NP (PRP I))    \n",
    "   (VP (VBP bring)    \n",
    "    (NP (CD 10) (NNS dollars))    \n",
    "    (NP (NN tomorrow)))   \n",
    "  )   \n",
    " )    \n",
    " (, ,)    \n",
    " (MD can)    \n",
    " (NP (PRP you))    \n",
    " (VP (VB buy)    \n",
    "  (NP (PRP me))    \n",
    "  (NP (NN lunch))   \n",
    " )    \n",
    " (. ?)   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"dataset/dev-v2.0.json\", 'r') as handle:\n",
    "    jdata = json.load(handle)\n",
    "    data = jdata['data']\n",
    "for i in range(len(data)):\n",
    "    section = data[i]['paragraphs']\n",
    "    for sec in section:\n",
    "        context = sec['context']\n",
    "        #contexts.append(context)\n",
    "        qas = sec['qas']\n",
    "        for j in range(len(qas)):\n",
    "            question = qas[j]['question']\n",
    "            unanswerable = qas[j]['is_impossible']\n",
    "            questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.86 s, sys: 22.7 ms, total: 4.88 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trees = []\n",
    "for q in questions[:10]:\n",
    "    res = predictor.predict(sentence=q)\n",
    "    trees.append(res['trees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(SBARQ (IN In) (WHNP (WP what) (NN country)) (SQ (VBZ is) (NP (NNP Normandy)) (VP (VBN located))) (. ?))',\n",
       " '(SBARQ (WHADVP (WRB When)) (SINV (VBD were) (NP (DT the) (NNPS Normans)) (PP (IN in) (NP (NNP Normandy)))) (. ?))',\n",
       " '(SBARQ (WHPP (IN From) (WHNP (WDT which) (NNS countries))) (SQ (VBD did) (NP (DT the) (NNP Norse)) (VP (VB originate))) (. ?))',\n",
       " '(SBARQ (WHNP (WP Who)) (SQ (VP (VBD was) (NP (DT the) (NNP Norse) (NN leader)))) (. ?))',\n",
       " '(SBARQ (WHNP (WDT What) (NN century)) (SQ (VBD did) (NP (DT the) (NNPS Normans)) (ADVP (RB first)) (VP (VBP gain) (NP (PRP$ their) (JJ separate) (NN identity)))) (. ?))',\n",
       " \"(SBARQ (WHNP (WP Who)) (S (VP (VBD gave) (NP (PRP$ their) (NN name)) (PP (IN to) (NP (NNP Normandy))) (PP (IN in) (NP (NP (DT the) (CD 1000) (POS 's)) (CC and) (NP (CD 1100) (POS 's)))))))\",\n",
       " '(SBARQ (WHNP (WP What)) (SQ (VBZ is) (NP (NNP France)) (NP (NP (DT a) (NN region)) (PP (IN of)))) (. ?))',\n",
       " '(SBARQ (WHNP (WP Who)) (SQ (VBD did) (NP (NNP King) (NNP Charles) (NNP III)) (VP (VBP swear) (NP (NN fealty)) (PP (IN to)))) (. ?))',\n",
       " '(SBARQ (WHADVP (WRB When)) (SQ (VBD did) (NP (DT the) (JJ Frankish) (NN identity)) (VP (VB emerge))) (. ?))',\n",
       " '(SBARQ (WHNP (WP Who)) (SQ (VBD was) (NP (DT the) (NN duke)) (PP (IN in) (NP (NP (DT the) (NN battle)) (PP (IN of) (NP (NNP Hastings)))))) (. ?))']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is not used for a precise definition of what it means to solve a problem using a given amount of time and space?\n",
      "Calling...\n",
      "####################\n",
      "How is Turing machine M said not to operate?\n",
      "Calling...\n",
      "####################\n",
      "What is the expression used to identify any given series of solutions capable of being solved within time on a deterministic Turing machine?\n",
      "Calling...\n",
      "####################\n",
      "What is the least critical resource measured in assessing the determination of a Turing machine's ability to solve any given set of problems?\n",
      "Calling...\n",
      "####################\n",
      "How can decision problem B be solved in time x(f)?\n",
      "Calling...\n",
      "####################\n",
      "Time and space are both examples of what type of resource?\n",
      "Calling...\n",
      "####################\n",
      "A complexity resource can also be described as what other type of resource?\n",
      "Calling...\n",
      "####################\n",
      "What is typically used to broadly define complexity measures?\n",
      "Calling...\n",
      "####################\n",
      "Communication complexity is an example of what type of measure?\n",
      "Calling...\n",
      "####################\n",
      "Decision tree is an example of what type of measure?\n",
      "Calling...\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "def print_np(entry):\n",
    "    phrase = \"\"\n",
    "    for child in entry['children']:\n",
    "        if child['nodeType'] != 'DT':\n",
    "            phrase += child['word']+\" \"\n",
    "    return(\"[\"+entry['nodeType']+\"]\"+phrase.strip())\n",
    "\n",
    "def print_nps(entry, pos=None):\n",
    "    print(\"Calling...\")\n",
    "    if entry['nodeType'].startswith('VB'):\n",
    "        if not nlp.vocab[entry['word'].lower()].is_stop:\n",
    "            yield \"[\"+entry['nodeType']+\"]\"+ entry['word']\n",
    "    elif entry['nodeType'].startswith(\"WH\"):\n",
    "        yield \"[\"+entry['nodeType']+\"]\"+ entry['word']\n",
    "    elif entry['nodeType'] == 'NP':\n",
    "        keep = True\n",
    "        for child in entry['children']:\n",
    "            if child['nodeType'] == 'NP' or child['nodeType'] == 'PP':\n",
    "                keep = False\n",
    "        if keep:\n",
    "            yield print_np(entry) # (entry['word'])\n",
    "        else:\n",
    "            if 'children' in entry and entry['children']:\n",
    "                for  child in entry['children']:\n",
    "                    print_nps(child)\n",
    "    else:\n",
    "        if 'children' in entry and entry['children']:\n",
    "            for child in entry['children']:\n",
    "                print_nps(child)\n",
    "\n",
    "for q in questions[360:370]:\n",
    "    print(q)\n",
    "    res = predictor.predict(sentence=q)\n",
    "    for x in print_nps(res['hierplane_tree']['root']):\n",
    "        print(x)\n",
    "    #print(res['trees'])\n",
    "    print(\"#\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "maintain order in x of y scenarios  \n",
    "capture the NN part of NP where there is a PP inside the NP\n",
    "\n",
    "* generate all the parts\n",
    "* include any required dependencies\n",
    "* generate the training data with masks and different # of conditionals \n",
    "* write model to train\n",
    "* kick off a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['located'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import examples.build_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.build_labels.build_labels(\"dataset/dev-v2.0.json\",\"dataset/train-v2.0.json\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = {}\n",
    "(dev_data_file, test_data_file) = (\"dataset/dev-v2.0.json\",\"dataset/train-v2.0.json\")\n",
    "for data_file in [dev_data_file, test_data_file]:\n",
    "    with open(data_file, 'r') as handle: # update\n",
    "        jdata = json.load(handle)\n",
    "        data = jdata['data']\n",
    "    for i in range(len(data)):\n",
    "        section = data[i]['paragraphs']\n",
    "        for sec in section:\n",
    "            qas = sec['qas']\n",
    "            for j in range(len(qas)):\n",
    "                qid = qas[j]['id']\n",
    "                question = qas[j]['question']\n",
    "                questions[qid] = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142192"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"part_labels.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['56ddde6b9a695914005b9628', '56ddde6b9a695914005b9629', '56ddde6b9a695914005b962a', '56ddde6b9a695914005b962b', '56ddde6b9a695914005b962c', '5ad39d53604f3c001a3fe8d1', '5ad39d53604f3c001a3fe8d2', '5ad39d53604f3c001a3fe8d3', '5ad39d53604f3c001a3fe8d4', '56dddf4066d3e219004dad5f', '56dddf4066d3e219004dad60', '56dddf4066d3e219004dad61', '5ad3a266604f3c001a3fea27', '5ad3a266604f3c001a3fea28', '5ad3a266604f3c001a3fea29', '5ad3a266604f3c001a3fea2a', '5ad3a266604f3c001a3fea2b', '56dde0379a695914005b9636', '56dde0379a695914005b9637', '5ad3ab70604f3c001a3feb89', '5ad3ab70604f3c001a3feb8a', '56dde0ba66d3e219004dad75', '56dde0ba66d3e219004dad76', '56dde0ba66d3e219004dad77', '5ad3ad61604f3c001a3fec0d', '5ad3ad61604f3c001a3fec0e', '5ad3ad61604f3c001a3fec0f', '5ad3ad61604f3c001a3fec10', '56dde1d966d3e219004dad8d', '5ad3ae14604f3c001a3fec39', '5ad3ae14604f3c001a3fec3a', '56dde27d9a695914005b9651', '56dde27d9a695914005b9652', '5ad3af11604f3c001a3fec63', '5ad3af11604f3c001a3fec64', '5ad3af11604f3c001a3fec65', '56dde2fa66d3e219004dad9b', '5ad3c626604f3c001a3ff011', '5ad3c626604f3c001a3ff012', '5ad3c626604f3c001a3ff013', '56de0f6a4396321400ee257f', '5ad3dbc6604f3c001a3ff3e9', '5ad3dbc6604f3c001a3ff3ea', '5ad3dbc6604f3c001a3ff3eb', '5ad3dbc6604f3c001a3ff3ec', '56de0ffd4396321400ee258d', '56de0ffd4396321400ee258e', '56de0ffd4396321400ee258f', '5ad3de8b604f3c001a3ff467', '5ad3de8b604f3c001a3ff468', '5ad3de8b604f3c001a3ff469', '5ad3de8b604f3c001a3ff46a', '56de10b44396321400ee2593', '56de10b44396321400ee2594', '56de10b44396321400ee2595', '5ad3e96b604f3c001a3ff689', '5ad3e96b604f3c001a3ff68a', '5ad3e96b604f3c001a3ff68b', '5ad3e96b604f3c001a3ff68c', '56de11154396321400ee25aa', '5ad3ea79604f3c001a3ff6e9', '5ad3ea79604f3c001a3ff6ea', '5ad3ea79604f3c001a3ff6eb', '56de148dcffd8e1900b4b5bc', '56de148dcffd8e1900b4b5bd', '56de148dcffd8e1900b4b5be', '5ad3ed26604f3c001a3ff799', '5ad3ed26604f3c001a3ff79a', '5ad3ed26604f3c001a3ff79b', '5ad3ed26604f3c001a3ff79c', '56de15104396321400ee25b7', '56de15104396321400ee25b8', '56de15104396321400ee25b9', '5ad3ee2d604f3c001a3ff7e1', '5ad3ee2d604f3c001a3ff7e2', '5ad3ee2d604f3c001a3ff7e3', '56de1563cffd8e1900b4b5c2', '56de1563cffd8e1900b4b5c3', '56de1563cffd8e1900b4b5c4', '5ad3f028604f3c001a3ff823', '5ad3f028604f3c001a3ff824', '5ad3f028604f3c001a3ff825', '56de15dbcffd8e1900b4b5c8', '56de15dbcffd8e1900b4b5c9', '56de15dbcffd8e1900b4b5ca', '56de15dbcffd8e1900b4b5cb', '5ad3f187604f3c001a3ff86f', '5ad3f187604f3c001a3ff870', '5ad3f187604f3c001a3ff871', '56de1645cffd8e1900b4b5d0', '56de1645cffd8e1900b4b5d1', '56de1645cffd8e1900b4b5d2', '5ad3f350604f3c001a3ff8ef', '5ad3f350604f3c001a3ff8f0', '5ad3f350604f3c001a3ff8f1', '56de16ca4396321400ee25c5', '56de16ca4396321400ee25c6', '56de16ca4396321400ee25c7', '56de16ca4396321400ee25c8', '5ad3f4b1604f3c001a3ff951'])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
