{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n"
     ]
    }
   ],
   "source": [
    "res = predictor.predict(\n",
    "  sentence=\"If I bring 10 dollars tomorrow, can you buy me lunch?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_probabilities', 'spans', 'tokens', 'pos_tags', 'num_spans', 'hierplane_tree', 'trees'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spans\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [9, 9], [9, 10], [9, 11], [9, 12], [10, 10], [10, 11], [10, 12], [11, 11], [11, 12], [12, 12]]\n",
      "####################\n",
      "tokens\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['If', 'I', 'bring', '10', 'dollars', 'tomorrow', ',', 'can', 'you', 'buy', 'me', 'lunch', '?']\n",
      "####################\n",
      "pos_tags\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['IN', 'PRP', 'VBP', 'CD', 'NNS', 'NN', ',', 'MD', 'PRP', 'VB', 'PRP', 'NN', '.']\n",
      "####################\n",
      "num_spans\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "91\n",
      "####################\n",
      "hierplane_tree\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "{'linkNameToLabel': {'.': 'pos', ',': 'pos', '-LRB-': 'pos', '-RRB-': 'pos', '``': 'pos', '\"\"': 'pos', \"''\": 'pos', ':': 'pos', '$': 'pos', '#': 'pos', 'AFX': 'pos', 'CC': 'pos', 'CD': 'pos', 'DT': 'pos', 'EX': 'pos', 'FW': 'pos', 'HYPH': 'pos', 'IN': 'pos', 'JJ': 'pos', 'JJR': 'pos', 'JJS': 'pos', 'LS': 'pos', 'MD': 'pos', 'NIL': 'pos', 'NN': 'pos', 'NNP': 'pos', 'NNPS': 'pos', 'NNS': 'pos', 'PDT': 'pos', 'POS': 'pos', 'PRP': 'pos', 'PRP$': 'pos', 'RB': 'pos', 'RBR': 'pos', 'RBS': 'pos', 'RP': 'pos', 'SP': 'pos', 'SYM': 'pos', 'TO': 'pos', 'UH': 'pos', 'VB': 'pos', 'VBD': 'pos', 'VBG': 'pos', 'VBN': 'pos', 'VBP': 'pos', 'VBZ': 'pos', 'WDT': 'pos', 'WP': 'pos', 'WP$': 'pos', 'WRB': 'pos', 'ADD': 'pos', 'NFP': 'pos', 'GW': 'pos', 'XX': 'pos', 'BES': 'pos', 'HVS': 'pos', '_SP': 'pos'}, 'nodeTypeToStyle': {'.': ['color0'], ',': ['color0'], '-LRB-': ['color0'], '-RRB-': ['color0'], '``': ['color0'], '\"\"': ['color0'], \"''\": ['color0'], ':': ['color0'], '$': ['color0'], '#': ['color0'], 'AFX': ['color0'], 'CC': ['color0'], 'CD': ['color0'], 'DT': ['color0'], 'EX': ['color0'], 'FW': ['color0'], 'HYPH': ['color0'], 'IN': ['color0'], 'JJ': ['color0'], 'JJR': ['color0'], 'JJS': ['color0'], 'LS': ['color0'], 'MD': ['color0'], 'NIL': ['color0'], 'NN': ['color0'], 'NNP': ['color0'], 'NNPS': ['color0'], 'NNS': ['color0'], 'PDT': ['color0'], 'POS': ['color0'], 'PRP': ['color0'], 'PRP$': ['color0'], 'RB': ['color0'], 'RBR': ['color0'], 'RBS': ['color0'], 'RP': ['color0'], 'SP': ['color0'], 'SYM': ['color0'], 'TO': ['color0'], 'UH': ['color0'], 'VB': ['color0'], 'VBD': ['color0'], 'VBG': ['color0'], 'VBN': ['color0'], 'VBP': ['color0'], 'VBZ': ['color0'], 'WDT': ['color0'], 'WP': ['color0'], 'WP$': ['color0'], 'WRB': ['color0'], 'ADD': ['color0'], 'NFP': ['color0'], 'GW': ['color0'], 'XX': ['color0'], 'BES': ['color0'], 'HVS': ['color0'], '_SP': ['color0'], 'NP': ['color1'], 'NX': ['color1'], 'QP': ['color1'], 'NAC': ['color1'], 'VP': ['color2'], 'S': ['color3'], 'SQ': ['color3'], 'SBAR': ['color3'], 'SBARQ': ['color3'], 'SINQ': ['color3'], 'FRAG': ['color3'], 'X': ['color3'], 'WHADVP': ['color4'], 'WHADJP': ['color4'], 'WHNP': ['color4'], 'WHPP': ['color4'], 'PP': ['color6'], 'ADJP': ['color5'], 'ADVP': ['color5'], 'CONJP': ['color5'], 'INTJ': ['color5'], 'LST': ['color5', 'seq'], 'PRN': ['color5'], 'PRT': ['color5'], 'RRC': ['color5'], 'UCP': ['color5']}, 'text': 'If I bring 10 dollars tomorrow , can you buy me lunch ?', 'root': {'word': 'If I bring 10 dollars tomorrow , can you buy me lunch ?', 'nodeType': 'SQ', 'attributes': ['SQ'], 'link': 'SQ', 'children': [{'word': 'If I bring 10 dollars tomorrow', 'nodeType': 'SBAR', 'attributes': ['SBAR'], 'link': 'SBAR', 'children': [{'word': 'If', 'nodeType': 'IN', 'attributes': ['IN'], 'link': 'IN'}, {'word': 'I bring 10 dollars tomorrow', 'nodeType': 'S', 'attributes': ['S'], 'link': 'S', 'children': [{'word': 'I', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'I', 'nodeType': 'PRP', 'attributes': ['PRP'], 'link': 'PRP'}]}, {'word': 'bring 10 dollars tomorrow', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'bring', 'nodeType': 'VBP', 'attributes': ['VBP'], 'link': 'VBP'}, {'word': '10 dollars', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': '10', 'nodeType': 'CD', 'attributes': ['CD'], 'link': 'CD'}, {'word': 'dollars', 'nodeType': 'NNS', 'attributes': ['NNS'], 'link': 'NNS'}]}, {'word': 'tomorrow', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'tomorrow', 'nodeType': 'NN', 'attributes': ['NN'], 'link': 'NN'}]}]}]}]}, {'word': ',', 'nodeType': ',', 'attributes': [','], 'link': ','}, {'word': 'can', 'nodeType': 'MD', 'attributes': ['MD'], 'link': 'MD'}, {'word': 'you', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'you', 'nodeType': 'PRP', 'attributes': ['PRP'], 'link': 'PRP'}]}, {'word': 'buy me lunch', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'buy', 'nodeType': 'VB', 'attributes': ['VB'], 'link': 'VB'}, {'word': 'me', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'me', 'nodeType': 'PRP', 'attributes': ['PRP'], 'link': 'PRP'}]}, {'word': 'lunch', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'lunch', 'nodeType': 'NN', 'attributes': ['NN'], 'link': 'NN'}]}]}, {'word': '?', 'nodeType': '.', 'attributes': ['.'], 'link': '.'}]}}\n",
      "####################\n",
      "trees\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "(SQ (SBAR (IN If) (S (NP (PRP I)) (VP (VBP bring) (NP (CD 10) (NNS dollars)) (NP (NN tomorrow))))) (, ,) (MD can) (NP (PRP you)) (VP (VB buy) (NP (PRP me)) (NP (NN lunch))) (. ?))\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "for k, v in res.items():\n",
    "    if k == 'class_probabilities':\n",
    "        continue\n",
    "    print(k)\n",
    "    print(\"~\"*20)\n",
    "    print(v)\n",
    "    print(\"#\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SQ   \n",
    " (SBAR    \n",
    "  (IN If)    \n",
    "  (S    \n",
    "   (NP (PRP I))    \n",
    "   (VP (VBP bring)    \n",
    "    (NP (CD 10) (NNS dollars))    \n",
    "    (NP (NN tomorrow)))   \n",
    "  )   \n",
    " )    \n",
    " (, ,)    \n",
    " (MD can)    \n",
    " (NP (PRP you))    \n",
    " (VP (VB buy)    \n",
    "  (NP (PRP me))    \n",
    "  (NP (NN lunch))   \n",
    " )    \n",
    " (. ?)   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"dataset/dev-v2.0.json\", 'r') as handle:\n",
    "    jdata = json.load(handle)\n",
    "    data = jdata['data']\n",
    "for i in range(len(data)):\n",
    "    section = data[i]['paragraphs']\n",
    "    for sec in section:\n",
    "        context = sec['context']\n",
    "        #contexts.append(context)\n",
    "        qas = sec['qas']\n",
    "        for j in range(len(qas)):\n",
    "            question = qas[j]['question']\n",
    "            unanswerable = qas[j]['is_impossible']\n",
    "            questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.86 s, sys: 22.7 ms, total: 4.88 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trees = []\n",
    "for q in questions[:10]:\n",
    "    res = predictor.predict(sentence=q)\n",
    "    trees.append(res['trees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(SBARQ (IN In) (WHNP (WP what) (NN country)) (SQ (VBZ is) (NP (NNP Normandy)) (VP (VBN located))) (. ?))',\n",
       " '(SBARQ (WHADVP (WRB When)) (SINV (VBD were) (NP (DT the) (NNPS Normans)) (PP (IN in) (NP (NNP Normandy)))) (. ?))',\n",
       " '(SBARQ (WHPP (IN From) (WHNP (WDT which) (NNS countries))) (SQ (VBD did) (NP (DT the) (NNP Norse)) (VP (VB originate))) (. ?))',\n",
       " '(SBARQ (WHNP (WP Who)) (SQ (VP (VBD was) (NP (DT the) (NNP Norse) (NN leader)))) (. ?))',\n",
       " '(SBARQ (WHNP (WDT What) (NN century)) (SQ (VBD did) (NP (DT the) (NNPS Normans)) (ADVP (RB first)) (VP (VBP gain) (NP (PRP$ their) (JJ separate) (NN identity)))) (. ?))',\n",
       " \"(SBARQ (WHNP (WP Who)) (S (VP (VBD gave) (NP (PRP$ their) (NN name)) (PP (IN to) (NP (NNP Normandy))) (PP (IN in) (NP (NP (DT the) (CD 1000) (POS 's)) (CC and) (NP (CD 1100) (POS 's)))))))\",\n",
       " '(SBARQ (WHNP (WP What)) (SQ (VBZ is) (NP (NNP France)) (NP (NP (DT a) (NN region)) (PP (IN of)))) (. ?))',\n",
       " '(SBARQ (WHNP (WP Who)) (SQ (VBD did) (NP (NNP King) (NNP Charles) (NNP III)) (VP (VBP swear) (NP (NN fealty)) (PP (IN to)))) (. ?))',\n",
       " '(SBARQ (WHADVP (WRB When)) (SQ (VBD did) (NP (DT the) (JJ Frankish) (NN identity)) (VP (VB emerge))) (. ?))',\n",
       " '(SBARQ (WHNP (WP Who)) (SQ (VBD was) (NP (DT the) (NN duke)) (PP (IN in) (NP (NP (DT the) (NN battle)) (PP (IN of) (NP (NNP Hastings)))))) (. ?))']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is not used for a precise definition of what it means to solve a problem using a given amount of time and space?\n",
      "Calling...\n",
      "####################\n",
      "How is Turing machine M said not to operate?\n",
      "Calling...\n",
      "####################\n",
      "What is the expression used to identify any given series of solutions capable of being solved within time on a deterministic Turing machine?\n",
      "Calling...\n",
      "####################\n",
      "What is the least critical resource measured in assessing the determination of a Turing machine's ability to solve any given set of problems?\n",
      "Calling...\n",
      "####################\n",
      "How can decision problem B be solved in time x(f)?\n",
      "Calling...\n",
      "####################\n",
      "Time and space are both examples of what type of resource?\n",
      "Calling...\n",
      "####################\n",
      "A complexity resource can also be described as what other type of resource?\n",
      "Calling...\n",
      "####################\n",
      "What is typically used to broadly define complexity measures?\n",
      "Calling...\n",
      "####################\n",
      "Communication complexity is an example of what type of measure?\n",
      "Calling...\n",
      "####################\n",
      "Decision tree is an example of what type of measure?\n",
      "Calling...\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "def print_np(entry):\n",
    "    phrase = \"\"\n",
    "    for child in entry['children']:\n",
    "        if child['nodeType'] != 'DT':\n",
    "            phrase += child['word']+\" \"\n",
    "    return(\"[\"+entry['nodeType']+\"]\"+phrase.strip())\n",
    "\n",
    "def print_nps(entry, pos=None):\n",
    "    print(\"Calling...\")\n",
    "    if entry['nodeType'].startswith('VB'):\n",
    "        if not nlp.vocab[entry['word'].lower()].is_stop:\n",
    "            yield \"[\"+entry['nodeType']+\"]\"+ entry['word']\n",
    "    elif entry['nodeType'].startswith(\"WH\"):\n",
    "        yield \"[\"+entry['nodeType']+\"]\"+ entry['word']\n",
    "    elif entry['nodeType'] == 'NP':\n",
    "        keep = True\n",
    "        for child in entry['children']:\n",
    "            if child['nodeType'] == 'NP' or child['nodeType'] == 'PP':\n",
    "                keep = False\n",
    "        if keep:\n",
    "            yield print_np(entry) # (entry['word'])\n",
    "        else:\n",
    "            if 'children' in entry and entry['children']:\n",
    "                for  child in entry['children']:\n",
    "                    print_nps(child)\n",
    "    else:\n",
    "        if 'children' in entry and entry['children']:\n",
    "            for child in entry['children']:\n",
    "                print_nps(child)\n",
    "\n",
    "for q in questions[360:370]:\n",
    "    print(q)\n",
    "    res = predictor.predict(sentence=q)\n",
    "    for x in print_nps(res['hierplane_tree']['root']):\n",
    "        print(x)\n",
    "    #print(res['trees'])\n",
    "    print(\"#\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "maintain order in x of y scenarios  \n",
    "capture the NN part of NP where there is a PP inside the NP\n",
    "\n",
    "* generate all the parts\n",
    "* include any required dependencies\n",
    "* generate the training data with masks and different # of conditionals \n",
    "* write model to train\n",
    "* kick off a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['located'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import examples.build_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'56ddde6b9a695914005b9628': [('[WHNP]', 'what country'), ('[NP]', 'Normandy'), ('[VBN]', 'located')], '56ddde6b9a695914005b9629': [('[WHADVP]', 'When'), ('[NP]', 'Normans'), ('[NP]', 'Normandy')], '56ddde6b9a695914005b962a': [('[WHPP]', 'From which countries'), ('[NP]', 'Norse'), ('[VB]', 'originate')], '56ddde6b9a695914005b962b': [('[WHNP]', 'Who'), ('[NP]', 'Norse leader')], '56ddde6b9a695914005b962c': [('[WHNP]', 'What century'), ('[NP]', 'Normans'), ('[VBP]', 'gain'), ('[NP]', 'their separate identity')]}\n"
     ]
    }
   ],
   "source": [
    "examples.build_labels.build_labels(\"dataset/dev-v2.0.json\",\"dataset/train-v2.0.json\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
