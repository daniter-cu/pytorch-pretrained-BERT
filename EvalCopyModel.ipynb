{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"examples/\")\n",
    "\n",
    "import logging\n",
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTraining \n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_cond_with_copy import InputExample, random_word, InputFeatures, BERTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "gradient_accumulation_steps = 1\n",
    "train_batch_size = 1\n",
    "eval_file = \"dataset/dev-v2.0.json\"\n",
    "max_seq_length=256\n",
    "on_memory = True\n",
    "bert_model = \"model_copy/pytorch_model1.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2019 14:36:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/daniter/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "Loading Squad: 100%|██████████| 35/35 [00:00<00:00, 1394.14it/s]\n",
      "Loading Squad: 100%|██████████| 35/35 [00:00<00:00, 1454.26it/s]\n",
      "04/26/2019 14:36:57 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "04/26/2019 14:36:57 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmpe346s511\n",
      "04/26/2019 14:37:01 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "# Load eval_data\n",
    "eval_dataset_answerable = BERTDataset(eval_file, \"qparts/copy_parts2/parsed_qs_labels%s.pkl\", tokenizer, seq_len=max_seq_length,\n",
    "                                    on_memory=on_memory)\n",
    "eval_dataset_unanswerable = BERTDataset(eval_file, \"qparts/copy_parts2/parsed_qs_labels%s.pkl\", tokenizer, seq_len=max_seq_length,\n",
    "                                    on_memory=on_memory, keep_answerable=False)\n",
    "\n",
    "# Prepare model\n",
    "model_state_dict = torch.load(bert_model, map_location='cpu') #TODO daniter: remove this map_location\n",
    "## TODO daniter: check if bert model is being loaded correctly\n",
    "model = BertForPreTraining.from_pretrained(\"bert-base-uncased\", state_dict=model_state_dict)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Prepare optimizer\n",
    "print(\"Checking the vocab size:\", len(tokenizer.vocab))\n",
    "# 768 is bert hidden size, 256 is GRU hidden size, 1 is the layers in the GRU\n",
    "\n",
    "# eval loader\n",
    "eval_sampler_ans = SequentialSampler(eval_dataset_answerable)\n",
    "eval_dataloader_ans = DataLoader(eval_dataset_answerable, sampler=eval_sampler_ans,\n",
    "                                 batch_size=train_batch_size)\n",
    "eval_sampler_unans = SequentialSampler(eval_dataset_unanswerable)\n",
    "eval_dataloader_unans = DataLoader(eval_dataset_unanswerable, sampler=eval_sampler_unans,\n",
    "                                   batch_size=train_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(contexts):\n",
    "    ans_examples = []\n",
    "    unans_examples = []\n",
    "    for context in contexts:\n",
    "        ans_questions = set()\n",
    "        unans_questions = set()\n",
    "        for x in eval_dataloader_unans.dataset.examples:\n",
    "            if x[0] == context:\n",
    "                if x[1] not in unans_questions:\n",
    "                    unans_examples.append(x)\n",
    "                unans_questions.add(x[1])        \n",
    "        for x in eval_dataloader_ans.dataset.examples:\n",
    "            if x[0] == context:\n",
    "                if x[1] not in ans_questions:\n",
    "                    ans_examples.append(x)\n",
    "                ans_questions.add(x[1])\n",
    "        #print (eval_dataloader_unans.dataset.contexts[context])\n",
    "    return((ans_examples, unans_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "softmax_model = LogSoftmax(dim=0)\n",
    "\n",
    "def perplexity(logit_idx, dist):\n",
    "    log_prob = 0\n",
    "    for i, lg_idx in enumerate(logit_idx):\n",
    "        prob = softmax_model(dist[i])[lg_idx]\n",
    "        log_prob += prob\n",
    "    return (log_prob / len(logit_idx)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input(context, tokens_b, target_tokens, multihint=False):\n",
    "    tokenized_context = tokenizer.tokenize(context)\n",
    "    buff_size = sum([len(t[0]) for t in tokens_b]) + len(tokens_b) - 1 + len(target_tokens[2]) + len(target_tokens[1]) + 2\n",
    "    if len(tokenized_context) + buff_size > max_seq_length - 3:\n",
    "        end = max_seq_length - 3 - buff_size\n",
    "        tokenized_context = tokenized_context[:end]\n",
    "    \n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokenized_context:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    for i, conditional in enumerate(tokens_b):\n",
    "        for token in conditional[0]:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "    \n",
    "    for token in target_tokens[1]:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(1)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(1)\n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    return torch.tensor([input_ids]), torch.tensor([input_mask]), torch.tensor([segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_odds(examples, dataloader, multihint=False):\n",
    "    if len(examples) == 0:\n",
    "        return 0\n",
    "    total_total_odds = 0\n",
    "    total_total_perlex = 0\n",
    "    max_perplex = 0\n",
    "    results = {}\n",
    "    for example in examples:\n",
    "        cid, qid, targetid, _ = example\n",
    "        context = dataloader.dataset.contexts[cid]\n",
    "        question = dataloader.dataset.questions[qid]\n",
    "        raw_targ = dataloader.dataset.raw_targets[targetid]\n",
    "        results[(context, question)] = {}\n",
    "\n",
    "        raw_targ_copy = list(raw_targ)\n",
    "        raw_targ = [(tag,word) for (word,(_,tag)) in raw_targ if word]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            targs_2_tokens = []#[tokenizer.tokenize(t) for _, t in raw_targ]            \n",
    "            for tidx, (tag, words) in enumerate(raw_targ):\n",
    "                clean_tag = tag\n",
    "                if multihint:\n",
    "                    span = tokenizer.tokenize(clean_tag) + [\"[SEP]\"] + words\n",
    "                else:\n",
    "                    span = words\n",
    "                targs_2_tokens.append((span, tokenizer.tokenize(clean_tag), words))\n",
    "                    \n",
    "            targs_2_ids = [list(map(tokenizer.convert_tokens_to_ids, t)) for t in targs_2_tokens]\n",
    "\n",
    "            total_odds = 0\n",
    "            min_odds = 100\n",
    "            total_perplex = 0\n",
    "            for token_idx in range(len(raw_targ)):\n",
    "                odds = 0\n",
    "                odds_list = []\n",
    "                input_ids, input_mask, segment_ids = build_input(context, targs_2_tokens[:token_idx], targs_2_tokens[token_idx], multihint)\n",
    "                output, _ = model(input_ids, segment_ids, input_mask, None, None)\n",
    "                \n",
    "                #print(input_mask)\n",
    "                start_i = np.where(input_mask.data.numpy() == 0)[1][0]\n",
    "                for t_i, t in enumerate(targs_2_ids[token_idx][2]):\n",
    "                    odds += output[0][start_i+t_i][t]\n",
    "                    odds_list.append(output[0][start_i+t_i][t])\n",
    "                if len(targs_2_ids[token_idx]) == 0:\n",
    "                    print(token_idx, targs_2_ids, targs_2_ids[token_idx], raw_targ)\n",
    "                odds = odds/len(targs_2_ids[token_idx])\n",
    "                if odds < min_odds:\n",
    "                    min_odds = odds\n",
    "                # print(odds)\n",
    "                total_odds += odds\n",
    "                perplex = perplexity(targs_2_ids[token_idx][2], output[0][start_i:])\n",
    "                results[(context, question)][(str([tt[0] for tt in targs_2_tokens[:token_idx]]), \n",
    "                                              str(targs_2_tokens[token_idx][1:]))] = -perplex\n",
    "                total_perplex += perplex / len(raw_targ)\n",
    "                #print(perplex)\n",
    "            #print(\"Perplexity\", -total_perplex)\n",
    "            total_odds /= len(raw_targ)\n",
    "            total_total_odds += total_odds\n",
    "            total_total_perlex += -total_perplex\n",
    "            if -total_perplex > max_perplex:\n",
    "                max_perplex = -total_perplex\n",
    "            #print(\"Total Odds:\", total_odds)\n",
    "            #print(\"Min odds:\", min_odds)\n",
    "    return (total_total_perlex / len(examples)), max_perplex, results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans\n",
      "unans\n",
      "3.01093453168869 3.430787698427836 3.6493123173713684 3.924611647923787\n",
      "ans\n",
      "unans\n",
      "3.3914772987365724 3.611902741591136 4.343588173389435 5.67276151974996\n",
      "ans\n",
      "unans\n",
      "3.189954300721486 2.663303724924723 3.6898910999298096 3.496266365051269\n",
      "ans\n",
      "unans\n",
      "2.865437759955724 3.0485681335131334 3.9908872842788696 4.132670561472575\n",
      "ans\n",
      "unans\n",
      "3.386874198913574 3.6901659837790897 4.159728765487671 5.5820057051522385\n"
     ]
    }
   ],
   "source": [
    "contexts = random.sample(range(1203), 5)\n",
    "ans_e, unans_e = get_examples(contexts)\n",
    "ans_res, unans_res = {}, {}\n",
    "for context in contexts:\n",
    "    #print_context_and_questions(context, ans_e, unans_e)\n",
    "    print(\"ans\")\n",
    "    avg_ans_odds, max_ent_ans, r = get_avg_odds([e for e in ans_e if e[0] == context], eval_dataloader_ans)\n",
    "    ans_res.update(r)\n",
    "    print(\"unans\")\n",
    "    avg_unans_odds, max_ent_unans, r = get_avg_odds([e for e in unans_e if e[0] == context], eval_dataloader_unans)\n",
    "    unans_res.update(r)\n",
    "    print(avg_ans_odds, avg_unans_odds, max_ent_ans, max_ent_unans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-2ab61fd9a76f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mtotal_odds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0modds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mperplex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargs_2_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 results[(context_text, question)][(str([tt[0] for tt in targs_2_tokens[:token_idx]]), \n\u001b[1;32m     61\u001b[0m                                               str(targs_2_tokens[token_idx][1:]))] = -perplex\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "contexts = random.sample(range(1203), 1)\n",
    "ans_e, unans_e = get_examples(contexts)\n",
    "for context in contexts:\n",
    "    #avg_ans_odds, max_ent_ans, r = get_avg_odds([e for e in ans_e if e[0] == context], eval_dataloader_ans)\n",
    "    examples = [e for e in unans_e if e[0] == context]\n",
    "    dataloader = eval_dataloader_unans\n",
    "    multihint = False\n",
    "    total_total_odds = 0\n",
    "    total_total_perlex = 0\n",
    "    max_perplex = 0\n",
    "    results = {}\n",
    "    for example in examples:\n",
    "        cid, qid, targetid, _ = example\n",
    "        context_text = dataloader.dataset.contexts[cid]\n",
    "        question = dataloader.dataset.questions[qid]\n",
    "        raw_targ = dataloader.dataset.raw_targets[targetid]\n",
    "        results[(context_text, question)] = {}\n",
    "\n",
    "        raw_targ_copy = list(raw_targ)\n",
    "        raw_targ = [(tag,word) for (word,(_,tag)) in raw_targ if word]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            targs_2_tokens = []#[tokenizer.tokenize(t) for _, t in raw_targ]            \n",
    "            for tidx, (tag, words) in enumerate(raw_targ):\n",
    "                clean_tag = tag\n",
    "                if multihint:\n",
    "                    span = tokenizer.tokenize(clean_tag) + [\"[SEP]\"] + words\n",
    "                else:\n",
    "                    span = words\n",
    "                targs_2_tokens.append((span, tokenizer.tokenize(clean_tag), words))\n",
    "\n",
    "            targs_2_ids = [list(map(tokenizer.convert_tokens_to_ids, t)) for t in targs_2_tokens]\n",
    "\n",
    "            total_odds = 0\n",
    "            min_odds = 100\n",
    "            total_perplex = 0\n",
    "            for token_idx in range(len(raw_targ)):\n",
    "                odds = 0\n",
    "                odds_list = []\n",
    "                input_ids, input_mask, segment_ids = build_input(context_text, targs_2_tokens[:token_idx], targs_2_tokens[token_idx], multihint)\n",
    "                output, _ = model(input_ids, segment_ids, input_mask, None, None)\n",
    "\n",
    "                #print(input_mask)\n",
    "                start_i = np.where(input_mask.data.numpy() == 0)[1][0]\n",
    "                for t_i, t in enumerate(targs_2_ids[token_idx][2]):\n",
    "                    odds += output[0][start_i+t_i][t]\n",
    "                    odds_list.append(output[0][start_i+t_i][t])\n",
    "                if len(targs_2_ids[token_idx]) == 0:\n",
    "                    print(token_idx, targs_2_ids, targs_2_ids[token_idx], raw_targ)\n",
    "                odds = odds/len(targs_2_ids[token_idx])\n",
    "                if odds < min_odds:\n",
    "                    min_odds = odds\n",
    "                # print(odds)\n",
    "                total_odds += odds\n",
    "                perplex = perplexity(targs_2_ids[token_idx][2], output[0][start_i:])\n",
    "                assert False\n",
    "                results[(context_text, question)][(str([tt[0] for tt in targs_2_tokens[:token_idx]]), \n",
    "                                              str(targs_2_tokens[token_idx][1:]))] = -perplex\n",
    "                total_perplex += perplex / len(raw_targ)\n",
    "                #print(perplex)\n",
    "            print(\"Perplexity\", -total_perplex)\n",
    "            total_odds /= len(raw_targ)\n",
    "            total_total_odds += total_odds\n",
    "            total_total_perlex += -total_perplex\n",
    "            if -total_perplex > max_perplex:\n",
    "                max_perplex = -total_perplex\n",
    "            #print(\"Total Odds:\", total_odds)\n",
    "            #print(\"Min odds:\", min_odds)\n",
    "    #return (total_total_perlex / len(examples)), max_perplex, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As in the House of Commons, a number of qualifications apply to being an MSP. Such qualifications were introduced under the House of Commons Disqualification Act 1975 and the British Nationality Act 1981. Specifically, members must be over the age of 18 and must be a citizen of the United Kingdom, the Republic of Ireland, one of the countries in the Commonwealth of Nations, a citizen of a British overseas territory, or a European Union citizen resident in the UK. Members of the police and the armed forces are disqualified from sitting in the Scottish Parliament as elected MSPs, and similarly, civil servants and members of foreign legislatures are disqualified. An individual may not sit in the Scottish Parliament if he or she is judged to be insane under the terms of the Mental Health (Care and Treatment) (Scotland) Act 2003.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "The House of Lords introduced qualifications for which position?\n",
      "('NNP', ['house']) 9.108257293701172\n",
      "('VBD', ['introduced']) 4.0582075119018555\n",
      "('NNS', ['qualifications']) 0.14187145233154297\n",
      "('NP', ['lords']) 6.993594169616699\n",
      "('WHNP', ['which', 'position']) 7.222714424133301\n"
     ]
    }
   ],
   "source": [
    "print(context_text)\n",
    "#print(raw_targ)\n",
    "print(\"~\"*20)\n",
    "print(question)\n",
    "for step in range(len(targs_2_tokens)):\n",
    "    with torch.no_grad():\n",
    "        input_ids, input_mask, segment_ids = build_input(context_text, targs_2_tokens[:step], targs_2_tokens[step], multihint)\n",
    "        output, _ = model(input_ids, segment_ids, input_mask, None, None)\n",
    "        start_i = np.where(input_mask.data.numpy() == 0)[1][0]\n",
    "\n",
    "    perplex = perplexity(targs_2_ids[step][2], output[0][start_i:])\n",
    "    print(raw_targ[step], -perplex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-bb70c3df58ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mtotal_odds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0modds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mperplex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargs_2_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 results[(context_text, question)][(str([tt[0] for tt in targs_2_tokens[:token_idx]]), \n\u001b[1;32m     61\u001b[0m                                               str(targs_2_tokens[token_idx][1:]))] = -perplex\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "contexts = random.sample(range(1203), 1)\n",
    "ans_e, unans_e = get_examples(contexts)\n",
    "for context in contexts:\n",
    "    #avg_ans_odds, max_ent_ans, r = get_avg_odds([e for e in ans_e if e[0] == context], eval_dataloader_ans)\n",
    "    examples = [e for e in ans_e if e[0] == context]\n",
    "    dataloader = eval_dataloader_ans\n",
    "    multihint = False\n",
    "    total_total_odds = 0\n",
    "    total_total_perlex = 0\n",
    "    max_perplex = 0\n",
    "    results = {}\n",
    "    for example in examples:\n",
    "        cid, qid, targetid, _ = example\n",
    "        context_text = dataloader.dataset.contexts[cid]\n",
    "        question = dataloader.dataset.questions[qid]\n",
    "        raw_targ = dataloader.dataset.raw_targets[targetid]\n",
    "        results[(context_text, question)] = {}\n",
    "\n",
    "        raw_targ_copy = list(raw_targ)\n",
    "        raw_targ = [(tag,word) for (word,(_,tag)) in raw_targ if word]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            targs_2_tokens = []#[tokenizer.tokenize(t) for _, t in raw_targ]            \n",
    "            for tidx, (tag, words) in enumerate(raw_targ):\n",
    "                clean_tag = tag\n",
    "                if multihint:\n",
    "                    span = tokenizer.tokenize(clean_tag) + [\"[SEP]\"] + words\n",
    "                else:\n",
    "                    span = words\n",
    "                targs_2_tokens.append((span, tokenizer.tokenize(clean_tag), words))\n",
    "\n",
    "            targs_2_ids = [list(map(tokenizer.convert_tokens_to_ids, t)) for t in targs_2_tokens]\n",
    "\n",
    "            total_odds = 0\n",
    "            min_odds = 100\n",
    "            total_perplex = 0\n",
    "            for token_idx in range(len(raw_targ)):\n",
    "                odds = 0\n",
    "                odds_list = []\n",
    "                input_ids, input_mask, segment_ids = build_input(context_text, targs_2_tokens[:token_idx], targs_2_tokens[token_idx], multihint)\n",
    "                output, _ = model(input_ids, segment_ids, input_mask, None, None)\n",
    "\n",
    "                #print(input_mask)\n",
    "                start_i = np.where(input_mask.data.numpy() == 0)[1][0]\n",
    "                for t_i, t in enumerate(targs_2_ids[token_idx][2]):\n",
    "                    odds += output[0][start_i+t_i][t]\n",
    "                    odds_list.append(output[0][start_i+t_i][t])\n",
    "                if len(targs_2_ids[token_idx]) == 0:\n",
    "                    print(token_idx, targs_2_ids, targs_2_ids[token_idx], raw_targ)\n",
    "                odds = odds/len(targs_2_ids[token_idx])\n",
    "                if odds < min_odds:\n",
    "                    min_odds = odds\n",
    "                # print(odds)\n",
    "                total_odds += odds\n",
    "                perplex = perplexity(targs_2_ids[token_idx][2], output[0][start_i:])\n",
    "                assert False\n",
    "                results[(context_text, question)][(str([tt[0] for tt in targs_2_tokens[:token_idx]]), \n",
    "                                              str(targs_2_tokens[token_idx][1:]))] = -perplex\n",
    "                total_perplex += perplex / len(raw_targ)\n",
    "                #print(perplex)\n",
    "            print(\"Perplexity\", -total_perplex)\n",
    "            total_odds /= len(raw_targ)\n",
    "            total_total_odds += total_odds\n",
    "            total_total_perlex += -total_perplex\n",
    "            if -total_perplex > max_perplex:\n",
    "                max_perplex = -total_perplex\n",
    "            #print(\"Total Odds:\", total_odds)\n",
    "            #print(\"Min odds:\", min_odds)\n",
    "    #return (total_total_perlex / len(examples)), max_perplex, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victoria contains many topographically, geologically and climatically diverse areas, ranging from the wet, temperate climate of Gippsland in the southeast to the snow-covered Victorian alpine areas which rise to almost 2,000 m (6,600 ft), with Mount Bogong the highest peak at 1,986 m (6,516 ft). There are extensive semi-arid plains to the west and northwest. There is an extensive series of river systems in Victoria. Most notable is the Murray River system. Other rivers include: Ovens River, Goulburn River, Patterson River, King River, Campaspe River, Loddon River, Wimmera River, Elgin River, Barwon River, Thomson River, Snowy River, Latrobe River, Yarra River, Maribyrnong River, Mitta River, Hopkins River, Merri River and Kiewa River. The state symbols include the pink heath (state flower), Leadbeater's possum (state animal) and the helmeted honeyeater (state bird).\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "How high is Victoria's Mount Bogong?\n",
      "('NP', ['victoria', \"'\", 's'])\n",
      "['state'] tensor(7.3829)\n",
      "['highest'] tensor(6.1930)\n",
      "['which'] tensor(5.6877)\n",
      "['most'] tensor(5.3977)\n",
      "['melbourne'] tensor(4.8965)\n",
      "['victoria'] tensor(4.6781)\n",
      "['southern'] tensor(4.6694)\n",
      "['victorian'] tensor(4.6679)\n",
      "['australian'] tensor(4.5393)\n",
      "['high'] tensor(4.4581)\n",
      "['eastern'] tensor(4.3021)\n",
      "['western'] tensor(4.2257)\n",
      "['northern'] tensor(4.2054)\n",
      "['pink'] tensor(4.2001)\n",
      "['many'] tensor(3.9946)\n",
      "['queen'] tensor(3.9877)\n",
      "['first'] tensor(3.7905)\n",
      "['st'] tensor(3.6604)\n",
      "['red'] tensor(3.6560)\n",
      "['north'] tensor(3.5849)\n",
      "['wa'] tensor(3.4109)\n",
      "['blue'] tensor(3.2639)\n",
      "['rose'] tensor(3.2561)\n",
      "['australia'] tensor(3.2050)\n",
      "['south'] tensor(3.1841)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['peak'] tensor(5.7998)\n",
      "[\"'\"] tensor(5.7973)\n",
      "['bog'] tensor(5.6373)\n",
      "['of'] tensor(5.5753)\n",
      "['bird'] tensor(5.5210)\n",
      "['river'] tensor(5.4738)\n",
      "['flower'] tensor(5.2808)\n",
      "['park'] tensor(5.1705)\n",
      "['mountain'] tensor(5.1319)\n",
      "['birds'] tensor(5.1124)\n",
      "['and'] tensor(4.8983)\n",
      "[','] tensor(4.5836)\n",
      "['victoria'] tensor(4.4258)\n",
      "['mountains'] tensor(4.3249)\n",
      "['forest'] tensor(4.2798)\n",
      "['peaks'] tensor(4.2034)\n",
      "['forests'] tensor(4.0988)\n",
      "['plant'] tensor(4.0892)\n",
      "['[SEP]'] tensor(4.0651)\n",
      "['valley'] tensor(3.9388)\n",
      "['southern'] tensor(3.8523)\n",
      "['symbol'] tensor(3.8400)\n",
      "['level'] tensor(3.8314)\n",
      "['-'] tensor(3.8206)\n",
      "['water'] tensor(3.7989)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['##ong'] tensor(8.5280)\n",
      "['[SEP]'] tensor(8.1214)\n",
      "['s'] tensor(6.5129)\n",
      "['of'] tensor(5.0094)\n",
      "['##land'] tensor(4.9993)\n",
      "['the'] tensor(4.7144)\n",
      "[\"'\"] tensor(4.6620)\n",
      "['birds'] tensor(4.5188)\n",
      "['and'] tensor(4.4560)\n",
      "['forests'] tensor(4.3757)\n",
      "['##y'] tensor(4.3058)\n",
      "['water'] tensor(4.2453)\n",
      "['river'] tensor(4.1657)\n",
      "['##s'] tensor(4.1528)\n",
      "['in'] tensor(4.1092)\n",
      "[','] tensor(3.9654)\n",
      "['##est'] tensor(3.9201)\n",
      "['##water'] tensor(3.7911)\n",
      "['south'] tensor(3.7875)\n",
      "['forest'] tensor(3.7234)\n",
      "['region'] tensor(3.5377)\n",
      "['##op'] tensor(3.5250)\n",
      "['##es'] tensor(3.4224)\n",
      "['valley'] tensor(3.3844)\n",
      "['species'] tensor(3.3502)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "####################\n",
      "('NP', ['victoria', \"'\", 's']) 3.4457778930664062\n",
      "('NP', ['mount', 'bog', '##ong'])\n",
      "['state'] tensor(9.4240)\n",
      "['highest'] tensor(6.2870)\n",
      "['which'] tensor(5.5208)\n",
      "['southern'] tensor(4.8476)\n",
      "['northern'] tensor(4.8269)\n",
      "['most'] tensor(4.5212)\n",
      "['many'] tensor(4.5083)\n",
      "['high'] tensor(4.4856)\n",
      "['river'] tensor(4.4395)\n",
      "['australian'] tensor(4.3066)\n",
      "['water'] tensor(4.2270)\n",
      "['official'] tensor(4.1252)\n",
      "['range'] tensor(4.1006)\n",
      "['eastern'] tensor(3.9920)\n",
      "['national'] tensor(3.9609)\n",
      "['western'] tensor(3.9270)\n",
      "['red'] tensor(3.6614)\n",
      "['north'] tensor(3.6175)\n",
      "['main'] tensor(3.5694)\n",
      "['native'] tensor(3.5342)\n",
      "['wa'] tensor(3.4419)\n",
      "['first'] tensor(3.3853)\n",
      "['largest'] tensor(3.3522)\n",
      "['victoria'] tensor(3.3336)\n",
      "['major'] tensor(3.3099)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['birds'] tensor(8.0244)\n",
      "['bird'] tensor(7.4391)\n",
      "['symbols'] tensor(7.3263)\n",
      "['symbol'] tensor(7.0214)\n",
      "['flower'] tensor(6.8355)\n",
      "['animal'] tensor(6.3296)\n",
      "['[SEP]'] tensor(5.8158)\n",
      "['emblem'] tensor(5.7812)\n",
      "['park'] tensor(5.5740)\n",
      "['name'] tensor(5.4204)\n",
      "['peak'] tensor(5.4135)\n",
      "['animals'] tensor(5.2959)\n",
      "['mammal'] tensor(5.0642)\n",
      "['forests'] tensor(4.9858)\n",
      "['feature'] tensor(4.9563)\n",
      "['flowers'] tensor(4.8804)\n",
      "['mountain'] tensor(4.8708)\n",
      "['plant'] tensor(4.8000)\n",
      "['river'] tensor(4.7300)\n",
      "['range'] tensor(4.6723)\n",
      "[\"'\"] tensor(4.5973)\n",
      "['forest'] tensor(4.4885)\n",
      "['valley'] tensor(4.4423)\n",
      "['rivers'] tensor(4.3869)\n",
      "['##birds'] tensor(4.3689)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['[SEP]'] tensor(10.5081)\n",
      "['s'] tensor(6.4584)\n",
      "['area'] tensor(5.7161)\n",
      "['##land'] tensor(5.5546)\n",
      "['system'] tensor(5.1317)\n",
      "['areas'] tensor(5.0618)\n",
      "['region'] tensor(4.9968)\n",
      "['rivers'] tensor(4.8051)\n",
      "['water'] tensor(4.7584)\n",
      "['##s'] tensor(4.7433)\n",
      "['birds'] tensor(4.6515)\n",
      "['river'] tensor(4.3718)\n",
      "['land'] tensor(4.3272)\n",
      "[\"'\"] tensor(4.2912)\n",
      "['forests'] tensor(4.2704)\n",
      "['regions'] tensor(4.0512)\n",
      "['of'] tensor(3.6472)\n",
      "['valley'] tensor(3.6269)\n",
      "['##water'] tensor(3.5697)\n",
      "['and'] tensor(3.5326)\n",
      "['feature'] tensor(3.5081)\n",
      "['animals'] tensor(3.4612)\n",
      "['the'] tensor(3.4553)\n",
      "['##er'] tensor(3.3848)\n",
      "['##ong'] tensor(3.3781)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "####################\n",
      "('NP', ['mount', 'bog', '##ong']) 8.748794555664062\n",
      "('WHADVP', ['how', 'high'])\n",
      "['how'] tensor(15.2280)\n",
      "['where'] tensor(12.9014)\n",
      "['when'] tensor(10.6720)\n",
      "['why'] tensor(10.3310)\n",
      "['what'] tensor(6.6405)\n",
      "['about'] tensor(5.9532)\n",
      "['approximately'] tensor(5.6089)\n",
      "['which'] tensor(5.4992)\n",
      "['at'] tensor(5.0039)\n",
      "['in'] tensor(4.7431)\n",
      "['as'] tensor(4.4067)\n",
      "['who'] tensor(4.4021)\n",
      "['that'] tensor(4.1482)\n",
      "['.'] tensor(3.9665)\n",
      "['and'] tensor(3.9567)\n",
      "['on'] tensor(3.8250)\n",
      "['high'] tensor(3.6311)\n",
      "['[SEP]'] tensor(3.4314)\n",
      "['so'] tensor(3.3807)\n",
      "['up'] tensor(3.3468)\n",
      "['whereby'] tensor(3.1883)\n",
      "['far'] tensor(3.1161)\n",
      "['if'] tensor(3.0970)\n",
      "[\"'\"] tensor(3.0834)\n",
      "[','] tensor(3.0104)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "['high'] tensor(11.0994)\n",
      "['tall'] tensor(11.0554)\n",
      "['[SEP]'] tensor(9.9883)\n",
      "['far'] tensor(9.5174)\n",
      "['long'] tensor(8.0485)\n",
      "['many'] tensor(7.6853)\n",
      "['big'] tensor(7.4185)\n",
      "['large'] tensor(7.0083)\n",
      "['much'] tensor(6.8264)\n",
      "['in'] tensor(6.5351)\n",
      "['deep'] tensor(6.5036)\n",
      "['low'] tensor(6.3079)\n",
      "['how'] tensor(5.6859)\n",
      "['close'] tensor(5.6024)\n",
      "['highest'] tensor(5.0193)\n",
      "['old'] tensor(4.4858)\n",
      "['well'] tensor(4.3130)\n",
      "['wide'] tensor(4.1668)\n",
      "[','] tensor(4.1196)\n",
      "['often'] tensor(3.8402)\n",
      "['great'] tensor(3.7192)\n",
      "['at'] tensor(3.5714)\n",
      "['level'] tensor(3.5632)\n",
      "['higher'] tensor(3.5124)\n",
      "['thick'] tensor(3.4353)\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "####################\n",
      "('WHADVP', ['how', 'high']) 0.5511116981506348\n"
     ]
    }
   ],
   "source": [
    "print(context_text)\n",
    "print(\"~\"*20)\n",
    "#print(raw_targ)\n",
    "print(question)\n",
    "for step in range(len(targs_2_tokens)):\n",
    "    with torch.no_grad():\n",
    "        input_ids, input_mask, segment_ids = build_input(context_text, targs_2_tokens[:step], targs_2_tokens[step], multihint)\n",
    "        output, _ = model(input_ids, segment_ids, input_mask, None, None)\n",
    "        start_i = np.where(input_mask.data.numpy() == 0)[1][0]\n",
    "        print(raw_targ[step])\n",
    "        for j in range(len(raw_targ[step][1])):\n",
    "            c = Counter()\n",
    "            for i, o in enumerate(output[0][start_i+j]):\n",
    "                c[i] = o\n",
    "            for x, val in c.most_common(25):\n",
    "                print(tokenizer.convert_ids_to_tokens([x]), val)\n",
    "            print(\"~\"*20)\n",
    "        print(\"#\"*20)\n",
    "\n",
    "    perplex = perplexity(targs_2_ids[step][2], output[0][start_i:])\n",
    "    print(raw_targ[step], -perplex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger drugs (>500 Da) can provoke a neutralizing immune response, particularly if the drugs are administered repeatedly, or in larger doses. This limits the effectiveness of drugs based on larger peptides and proteins (which are typically larger than 6000 Da). In some cases, the drug itself is not immunogenic, but may be co-administered with an immunogenic compound, as is sometimes the case for Taxol. Computational methods have been developed to predict the immunogenicity of peptides and proteins, which are particularly useful in designing therapeutic antibodies, assessing likely virulence of mutations in viral coat particles, and validation of proposed peptide-based drug treatments. Early techniques relied mainly on the observation that hydrophilic amino acids are overrepresented in epitope regions than hydrophobic amino acids; however, more recent developments rely on machine learning techniques using databases of existing known epitopes, usually on well-studied virus proteins, as a training set. A publicly accessible database has been established for the cataloguing of epitopes from pathogens known to be recognizable by B cells. The emerging field of bioinformatics-based studies of immunogenicity is referred to as immunoinformatics. Immunoproteomics is the study of large sets of proteins (proteomics) involved in the immune response.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What is the field of studying immunogenicity through bioinformatics known as?\n",
      "[['im'], ['n', '##n'], ['im']]\n",
      "tensor([[  101,  3469,  5850,  1006,  1028,  3156,  4830,  1007,  2064, 27895,\n",
      "          1037,  8699,  6026, 11311,  3433,  1010,  3391,  2065,  1996,  5850,\n",
      "          2024,  8564,  8385,  1010,  2030,  1999,  3469, 21656,  1012,  2023,\n",
      "          6537,  1996, 12353,  1997,  5850,  2241,  2006,  3469, 25117,  2015,\n",
      "          1998,  8171,  1006,  2029,  2024,  4050,  3469,  2084, 25961,  4830,\n",
      "          1007,  1012,  1999,  2070,  3572,  1010,  1996,  4319,  2993,  2003,\n",
      "          2025, 10047, 23041, 24278,  1010,  2021,  2089,  2022,  2522,  1011,\n",
      "          8564,  2007,  2019, 10047, 23041, 24278,  7328,  1010,  2004,  2003,\n",
      "          2823,  1996,  2553,  2005,  4171,  4747,  1012, 15078,  4725,  2031,\n",
      "          2042,  2764,  2000, 16014,  1996, 10047, 23041, 24278,  3012,  1997,\n",
      "         25117,  2015,  1998,  8171,  1010,  2029,  2024,  3391,  6179,  1999,\n",
      "         12697, 17261, 22931,  1010, 20077,  3497,  6819,  6820, 22717,  1997,\n",
      "         14494,  1999, 13434,  5435,  9309,  1010,  1998, 27354,  1997,  3818,\n",
      "         25117,  1011,  2241,  4319, 13441,  1012,  2220,  5461, 13538,  3701,\n",
      "          2006,  1996,  8089,  2008, 18479, 21850, 10415, 13096, 12737,  2024,\n",
      "          2058,  2890, 28994, 14088,  1999,  4958,  9956,  5051,  4655,  2084,\n",
      "         18479, 20200, 13096, 12737,  1025,  2174,  1010,  2062,  3522,  8973,\n",
      "         11160,  2006,  3698,  4083,  5461,  2478, 17881,  1997,  4493,  2124,\n",
      "          4958,  9956, 10374,  1010,  2788,  2006,  2092,  1011,  3273,  7865,\n",
      "          8171,  1010,  2004,  1037,  2731,  2275,  1012,  1037,  7271,  7801,\n",
      "          7809,  2038,  2042,  2511,  2005,  1996, 12105, 25165,  1997,  4958,\n",
      "          9956, 10374,  2013, 26835,  2015,  2124,  2000,  2022, 20123,  2011,\n",
      "          1038,  4442,  1012,  1996,  8361,  2492,  1997, 16012,  2378, 14192,\n",
      "         17592,  1011,  2241,  2913,  1997, 10047, 23041, 24278,  3012,  2003,\n",
      "          3615,  2000,  2004, 10047, 23041, 28765, 14192, 17592,  1012, 10047,\n",
      "         23041,   102,  1050,  2078,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "['[CLS]', 'larger', 'drugs', '(', '>', '500', 'da', ')', 'can', 'provoke', 'a', 'neutral', '##izing', 'immune', 'response', ',', 'particularly', 'if', 'the', 'drugs', 'are', 'administered', 'repeatedly', ',', 'or', 'in', 'larger', 'doses', '.', 'this', 'limits', 'the', 'effectiveness', 'of', 'drugs', 'based', 'on', 'larger', 'peptide', '##s', 'and', 'proteins', '(', 'which', 'are', 'typically', 'larger', 'than', '6000', 'da', ')', '.', 'in', 'some', 'cases', ',', 'the', 'drug', 'itself', 'is', 'not', 'im', '##mun', '##ogenic', ',', 'but', 'may', 'be', 'co', '-', 'administered', 'with', 'an', 'im', '##mun', '##ogenic', 'compound', ',', 'as', 'is', 'sometimes', 'the', 'case', 'for', 'tax', '##ol', '.', 'computational', 'methods', 'have', 'been', 'developed', 'to', 'predict', 'the', 'im', '##mun', '##ogenic', '##ity', 'of', 'peptide', '##s', 'and', 'proteins', ',', 'which', 'are', 'particularly', 'useful', 'in', 'designing', 'therapeutic', 'antibodies', ',', 'assessing', 'likely', 'vi', '##ru', '##lence', 'of', 'mutations', 'in', 'viral', 'coat', 'particles', ',', 'and', 'validation', 'of', 'proposed', 'peptide', '-', 'based', 'drug', 'treatments', '.', 'early', 'techniques', 'relied', 'mainly', 'on', 'the', 'observation', 'that', 'hydro', '##phi', '##lic', 'amino', 'acids', 'are', 'over', '##re', '##pres', '##ented', 'in', 'ep', '##ito', '##pe', 'regions', 'than', 'hydro', '##phobic', 'amino', 'acids', ';', 'however', ',', 'more', 'recent', 'developments', 'rely', 'on', 'machine', 'learning', 'techniques', 'using', 'databases', 'of', 'existing', 'known', 'ep', '##ito', '##pes', ',', 'usually', 'on', 'well', '-', 'studied', 'virus', 'proteins', ',', 'as', 'a', 'training', 'set', '.', 'a', 'publicly', 'accessible', 'database', 'has', 'been', 'established', 'for', 'the', 'catalog', '##uing', 'of', 'ep', '##ito', '##pes', 'from', 'pathogen', '##s', 'known', 'to', 'be', 'recognizable', 'by', 'b', 'cells', '.', 'the', 'emerging', 'field', 'of', 'bio', '##in', '##form', '##atics', '-', 'based', 'studies', 'of', 'im', '##mun', '##ogenic', '##ity', 'is', 'referred', 'to', 'as', 'im', '##mun', '##oin', '##form', '##atics', '.', 'im', '##mun', '[SEP]', 'n', '##n', '[SEP]', '[PAD]']\n",
      "[10047]\n",
      "tensor(-23.5859)\n",
      "im 23.58592987060547\n",
      "[['bio'], ['n', '##ns'], ['bio']]\n",
      "tensor([[  101,  3469,  5850,  1006,  1028,  3156,  4830,  1007,  2064, 27895,\n",
      "          1037,  8699,  6026, 11311,  3433,  1010,  3391,  2065,  1996,  5850,\n",
      "          2024,  8564,  8385,  1010,  2030,  1999,  3469, 21656,  1012,  2023,\n",
      "          6537,  1996, 12353,  1997,  5850,  2241,  2006,  3469, 25117,  2015,\n",
      "          1998,  8171,  1006,  2029,  2024,  4050,  3469,  2084, 25961,  4830,\n",
      "          1007,  1012,  1999,  2070,  3572,  1010,  1996,  4319,  2993,  2003,\n",
      "          2025, 10047, 23041, 24278,  1010,  2021,  2089,  2022,  2522,  1011,\n",
      "          8564,  2007,  2019, 10047, 23041, 24278,  7328,  1010,  2004,  2003,\n",
      "          2823,  1996,  2553,  2005,  4171,  4747,  1012, 15078,  4725,  2031,\n",
      "          2042,  2764,  2000, 16014,  1996, 10047, 23041, 24278,  3012,  1997,\n",
      "         25117,  2015,  1998,  8171,  1010,  2029,  2024,  3391,  6179,  1999,\n",
      "         12697, 17261, 22931,  1010, 20077,  3497,  6819,  6820, 22717,  1997,\n",
      "         14494,  1999, 13434,  5435,  9309,  1010,  1998, 27354,  1997,  3818,\n",
      "         25117,  1011,  2241,  4319, 13441,  1012,  2220,  5461, 13538,  3701,\n",
      "          2006,  1996,  8089,  2008, 18479, 21850, 10415, 13096, 12737,  2024,\n",
      "          2058,  2890, 28994, 14088,  1999,  4958,  9956,  5051,  4655,  2084,\n",
      "         18479, 20200, 13096, 12737,  1025,  2174,  1010,  2062,  3522,  8973,\n",
      "         11160,  2006,  3698,  4083,  5461,  2478, 17881,  1997,  4493,  2124,\n",
      "          4958,  9956, 10374,  1010,  2788,  2006,  2092,  1011,  3273,  7865,\n",
      "          8171,  1010,  2004,  1037,  2731,  2275,  1012,  1037,  7271,  7801,\n",
      "          7809,  2038,  2042,  2511,  2005,  1996, 12105, 25165,  1997,  4958,\n",
      "          9956, 10374,  2013, 26835,  2015,  2124,  2000,  2022, 20123,  2011,\n",
      "          1038,  4442,  1012,  1996,  8361,  2492,  1997, 16012,  2378, 14192,\n",
      "         17592,  1011,  2241,  2913,  1997, 10047, 23041, 24278,  3012,  2003,\n",
      "          3615,  2000,  2004, 10047, 23041, 28765,   102, 10047, 23041, 24278,\n",
      "          3012,   102,  1050,  3619,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "['[CLS]', 'larger', 'drugs', '(', '>', '500', 'da', ')', 'can', 'provoke', 'a', 'neutral', '##izing', 'immune', 'response', ',', 'particularly', 'if', 'the', 'drugs', 'are', 'administered', 'repeatedly', ',', 'or', 'in', 'larger', 'doses', '.', 'this', 'limits', 'the', 'effectiveness', 'of', 'drugs', 'based', 'on', 'larger', 'peptide', '##s', 'and', 'proteins', '(', 'which', 'are', 'typically', 'larger', 'than', '6000', 'da', ')', '.', 'in', 'some', 'cases', ',', 'the', 'drug', 'itself', 'is', 'not', 'im', '##mun', '##ogenic', ',', 'but', 'may', 'be', 'co', '-', 'administered', 'with', 'an', 'im', '##mun', '##ogenic', 'compound', ',', 'as', 'is', 'sometimes', 'the', 'case', 'for', 'tax', '##ol', '.', 'computational', 'methods', 'have', 'been', 'developed', 'to', 'predict', 'the', 'im', '##mun', '##ogenic', '##ity', 'of', 'peptide', '##s', 'and', 'proteins', ',', 'which', 'are', 'particularly', 'useful', 'in', 'designing', 'therapeutic', 'antibodies', ',', 'assessing', 'likely', 'vi', '##ru', '##lence', 'of', 'mutations', 'in', 'viral', 'coat', 'particles', ',', 'and', 'validation', 'of', 'proposed', 'peptide', '-', 'based', 'drug', 'treatments', '.', 'early', 'techniques', 'relied', 'mainly', 'on', 'the', 'observation', 'that', 'hydro', '##phi', '##lic', 'amino', 'acids', 'are', 'over', '##re', '##pres', '##ented', 'in', 'ep', '##ito', '##pe', 'regions', 'than', 'hydro', '##phobic', 'amino', 'acids', ';', 'however', ',', 'more', 'recent', 'developments', 'rely', 'on', 'machine', 'learning', 'techniques', 'using', 'databases', 'of', 'existing', 'known', 'ep', '##ito', '##pes', ',', 'usually', 'on', 'well', '-', 'studied', 'virus', 'proteins', ',', 'as', 'a', 'training', 'set', '.', 'a', 'publicly', 'accessible', 'database', 'has', 'been', 'established', 'for', 'the', 'catalog', '##uing', 'of', 'ep', '##ito', '##pes', 'from', 'pathogen', '##s', 'known', 'to', 'be', 'recognizable', 'by', 'b', 'cells', '.', 'the', 'emerging', 'field', 'of', 'bio', '##in', '##form', '##atics', '-', 'based', 'studies', 'of', 'im', '##mun', '##ogenic', '##ity', 'is', 'referred', 'to', 'as', 'im', '##mun', '##oin', '[SEP]', 'im', '##mun', '##ogenic', '##ity', '[SEP]', 'n', '##ns', '[SEP]', '[PAD]']\n",
      "[16012]\n",
      "tensor(-27.9732)\n",
      "bio 27.973154067993164\n",
      "[['field'], ['n', '##n'], ['field']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3469,  5850,  1006,  1028,  3156,  4830,  1007,  2064, 27895,\n",
      "          1037,  8699,  6026, 11311,  3433,  1010,  3391,  2065,  1996,  5850,\n",
      "          2024,  8564,  8385,  1010,  2030,  1999,  3469, 21656,  1012,  2023,\n",
      "          6537,  1996, 12353,  1997,  5850,  2241,  2006,  3469, 25117,  2015,\n",
      "          1998,  8171,  1006,  2029,  2024,  4050,  3469,  2084, 25961,  4830,\n",
      "          1007,  1012,  1999,  2070,  3572,  1010,  1996,  4319,  2993,  2003,\n",
      "          2025, 10047, 23041, 24278,  1010,  2021,  2089,  2022,  2522,  1011,\n",
      "          8564,  2007,  2019, 10047, 23041, 24278,  7328,  1010,  2004,  2003,\n",
      "          2823,  1996,  2553,  2005,  4171,  4747,  1012, 15078,  4725,  2031,\n",
      "          2042,  2764,  2000, 16014,  1996, 10047, 23041, 24278,  3012,  1997,\n",
      "         25117,  2015,  1998,  8171,  1010,  2029,  2024,  3391,  6179,  1999,\n",
      "         12697, 17261, 22931,  1010, 20077,  3497,  6819,  6820, 22717,  1997,\n",
      "         14494,  1999, 13434,  5435,  9309,  1010,  1998, 27354,  1997,  3818,\n",
      "         25117,  1011,  2241,  4319, 13441,  1012,  2220,  5461, 13538,  3701,\n",
      "          2006,  1996,  8089,  2008, 18479, 21850, 10415, 13096, 12737,  2024,\n",
      "          2058,  2890, 28994, 14088,  1999,  4958,  9956,  5051,  4655,  2084,\n",
      "         18479, 20200, 13096, 12737,  1025,  2174,  1010,  2062,  3522,  8973,\n",
      "         11160,  2006,  3698,  4083,  5461,  2478, 17881,  1997,  4493,  2124,\n",
      "          4958,  9956, 10374,  1010,  2788,  2006,  2092,  1011,  3273,  7865,\n",
      "          8171,  1010,  2004,  1037,  2731,  2275,  1012,  1037,  7271,  7801,\n",
      "          7809,  2038,  2042,  2511,  2005,  1996, 12105, 25165,  1997,  4958,\n",
      "          9956, 10374,  2013, 26835,  2015,  2124,  2000,  2022, 20123,  2011,\n",
      "          1038,  4442,  1012,  1996,  8361,  2492,  1997, 16012,  2378, 14192,\n",
      "         17592,  1011,  2241,  2913,  1997, 10047, 23041, 24278,  3012,  2003,\n",
      "          3615,   102, 10047, 23041, 24278,  3012,   102, 16012,  2378, 14192,\n",
      "         17592,   102,  1050,  2078,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "['[CLS]', 'larger', 'drugs', '(', '>', '500', 'da', ')', 'can', 'provoke', 'a', 'neutral', '##izing', 'immune', 'response', ',', 'particularly', 'if', 'the', 'drugs', 'are', 'administered', 'repeatedly', ',', 'or', 'in', 'larger', 'doses', '.', 'this', 'limits', 'the', 'effectiveness', 'of', 'drugs', 'based', 'on', 'larger', 'peptide', '##s', 'and', 'proteins', '(', 'which', 'are', 'typically', 'larger', 'than', '6000', 'da', ')', '.', 'in', 'some', 'cases', ',', 'the', 'drug', 'itself', 'is', 'not', 'im', '##mun', '##ogenic', ',', 'but', 'may', 'be', 'co', '-', 'administered', 'with', 'an', 'im', '##mun', '##ogenic', 'compound', ',', 'as', 'is', 'sometimes', 'the', 'case', 'for', 'tax', '##ol', '.', 'computational', 'methods', 'have', 'been', 'developed', 'to', 'predict', 'the', 'im', '##mun', '##ogenic', '##ity', 'of', 'peptide', '##s', 'and', 'proteins', ',', 'which', 'are', 'particularly', 'useful', 'in', 'designing', 'therapeutic', 'antibodies', ',', 'assessing', 'likely', 'vi', '##ru', '##lence', 'of', 'mutations', 'in', 'viral', 'coat', 'particles', ',', 'and', 'validation', 'of', 'proposed', 'peptide', '-', 'based', 'drug', 'treatments', '.', 'early', 'techniques', 'relied', 'mainly', 'on', 'the', 'observation', 'that', 'hydro', '##phi', '##lic', 'amino', 'acids', 'are', 'over', '##re', '##pres', '##ented', 'in', 'ep', '##ito', '##pe', 'regions', 'than', 'hydro', '##phobic', 'amino', 'acids', ';', 'however', ',', 'more', 'recent', 'developments', 'rely', 'on', 'machine', 'learning', 'techniques', 'using', 'databases', 'of', 'existing', 'known', 'ep', '##ito', '##pes', ',', 'usually', 'on', 'well', '-', 'studied', 'virus', 'proteins', ',', 'as', 'a', 'training', 'set', '.', 'a', 'publicly', 'accessible', 'database', 'has', 'been', 'established', 'for', 'the', 'catalog', '##uing', 'of', 'ep', '##ito', '##pes', 'from', 'pathogen', '##s', 'known', 'to', 'be', 'recognizable', 'by', 'b', 'cells', '.', 'the', 'emerging', 'field', 'of', 'bio', '##in', '##form', '##atics', '-', 'based', 'studies', 'of', 'im', '##mun', '##ogenic', '##ity', 'is', 'referred', '[SEP]', 'im', '##mun', '##ogenic', '##ity', '[SEP]', 'bio', '##in', '##form', '##atics', '[SEP]', 'n', '##n', '[SEP]', '[PAD]']\n",
      "[2492]\n",
      "tensor(-25.9523)\n",
      "field 25.952255249023438\n",
      "[['known'], ['v', '##bn'], ['known']]\n",
      "tensor([[  101,  3469,  5850,  1006,  1028,  3156,  4830,  1007,  2064, 27895,\n",
      "          1037,  8699,  6026, 11311,  3433,  1010,  3391,  2065,  1996,  5850,\n",
      "          2024,  8564,  8385,  1010,  2030,  1999,  3469, 21656,  1012,  2023,\n",
      "          6537,  1996, 12353,  1997,  5850,  2241,  2006,  3469, 25117,  2015,\n",
      "          1998,  8171,  1006,  2029,  2024,  4050,  3469,  2084, 25961,  4830,\n",
      "          1007,  1012,  1999,  2070,  3572,  1010,  1996,  4319,  2993,  2003,\n",
      "          2025, 10047, 23041, 24278,  1010,  2021,  2089,  2022,  2522,  1011,\n",
      "          8564,  2007,  2019, 10047, 23041, 24278,  7328,  1010,  2004,  2003,\n",
      "          2823,  1996,  2553,  2005,  4171,  4747,  1012, 15078,  4725,  2031,\n",
      "          2042,  2764,  2000, 16014,  1996, 10047, 23041, 24278,  3012,  1997,\n",
      "         25117,  2015,  1998,  8171,  1010,  2029,  2024,  3391,  6179,  1999,\n",
      "         12697, 17261, 22931,  1010, 20077,  3497,  6819,  6820, 22717,  1997,\n",
      "         14494,  1999, 13434,  5435,  9309,  1010,  1998, 27354,  1997,  3818,\n",
      "         25117,  1011,  2241,  4319, 13441,  1012,  2220,  5461, 13538,  3701,\n",
      "          2006,  1996,  8089,  2008, 18479, 21850, 10415, 13096, 12737,  2024,\n",
      "          2058,  2890, 28994, 14088,  1999,  4958,  9956,  5051,  4655,  2084,\n",
      "         18479, 20200, 13096, 12737,  1025,  2174,  1010,  2062,  3522,  8973,\n",
      "         11160,  2006,  3698,  4083,  5461,  2478, 17881,  1997,  4493,  2124,\n",
      "          4958,  9956, 10374,  1010,  2788,  2006,  2092,  1011,  3273,  7865,\n",
      "          8171,  1010,  2004,  1037,  2731,  2275,  1012,  1037,  7271,  7801,\n",
      "          7809,  2038,  2042,  2511,  2005,  1996, 12105, 25165,  1997,  4958,\n",
      "          9956, 10374,  2013, 26835,  2015,  2124,  2000,  2022, 20123,  2011,\n",
      "          1038,  4442,  1012,  1996,  8361,  2492,  1997, 16012,  2378, 14192,\n",
      "         17592,  1011,  2241,  2913,  1997, 10047, 23041, 24278,  3012,   102,\n",
      "         10047, 23041, 24278,  3012,   102, 16012,  2378, 14192, 17592,   102,\n",
      "          2492,   102,  1058, 24700,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "['[CLS]', 'larger', 'drugs', '(', '>', '500', 'da', ')', 'can', 'provoke', 'a', 'neutral', '##izing', 'immune', 'response', ',', 'particularly', 'if', 'the', 'drugs', 'are', 'administered', 'repeatedly', ',', 'or', 'in', 'larger', 'doses', '.', 'this', 'limits', 'the', 'effectiveness', 'of', 'drugs', 'based', 'on', 'larger', 'peptide', '##s', 'and', 'proteins', '(', 'which', 'are', 'typically', 'larger', 'than', '6000', 'da', ')', '.', 'in', 'some', 'cases', ',', 'the', 'drug', 'itself', 'is', 'not', 'im', '##mun', '##ogenic', ',', 'but', 'may', 'be', 'co', '-', 'administered', 'with', 'an', 'im', '##mun', '##ogenic', 'compound', ',', 'as', 'is', 'sometimes', 'the', 'case', 'for', 'tax', '##ol', '.', 'computational', 'methods', 'have', 'been', 'developed', 'to', 'predict', 'the', 'im', '##mun', '##ogenic', '##ity', 'of', 'peptide', '##s', 'and', 'proteins', ',', 'which', 'are', 'particularly', 'useful', 'in', 'designing', 'therapeutic', 'antibodies', ',', 'assessing', 'likely', 'vi', '##ru', '##lence', 'of', 'mutations', 'in', 'viral', 'coat', 'particles', ',', 'and', 'validation', 'of', 'proposed', 'peptide', '-', 'based', 'drug', 'treatments', '.', 'early', 'techniques', 'relied', 'mainly', 'on', 'the', 'observation', 'that', 'hydro', '##phi', '##lic', 'amino', 'acids', 'are', 'over', '##re', '##pres', '##ented', 'in', 'ep', '##ito', '##pe', 'regions', 'than', 'hydro', '##phobic', 'amino', 'acids', ';', 'however', ',', 'more', 'recent', 'developments', 'rely', 'on', 'machine', 'learning', 'techniques', 'using', 'databases', 'of', 'existing', 'known', 'ep', '##ito', '##pes', ',', 'usually', 'on', 'well', '-', 'studied', 'virus', 'proteins', ',', 'as', 'a', 'training', 'set', '.', 'a', 'publicly', 'accessible', 'database', 'has', 'been', 'established', 'for', 'the', 'catalog', '##uing', 'of', 'ep', '##ito', '##pes', 'from', 'pathogen', '##s', 'known', 'to', 'be', 'recognizable', 'by', 'b', 'cells', '.', 'the', 'emerging', 'field', 'of', 'bio', '##in', '##form', '##atics', '-', 'based', 'studies', 'of', 'im', '##mun', '##ogenic', '##ity', '[SEP]', 'im', '##mun', '##ogenic', '##ity', '[SEP]', 'bio', '##in', '##form', '##atics', '[SEP]', 'field', '[SEP]', 'v', '##bn', '[SEP]', '[PAD]']\n",
      "[2124]\n",
      "tensor(-18.3575)\n",
      "known 18.357526779174805\n",
      "[['studying'], ['v', '##b', '##g'], ['studying']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3469,  5850,  1006,  1028,  3156,  4830,  1007,  2064, 27895,\n",
      "          1037,  8699,  6026, 11311,  3433,  1010,  3391,  2065,  1996,  5850,\n",
      "          2024,  8564,  8385,  1010,  2030,  1999,  3469, 21656,  1012,  2023,\n",
      "          6537,  1996, 12353,  1997,  5850,  2241,  2006,  3469, 25117,  2015,\n",
      "          1998,  8171,  1006,  2029,  2024,  4050,  3469,  2084, 25961,  4830,\n",
      "          1007,  1012,  1999,  2070,  3572,  1010,  1996,  4319,  2993,  2003,\n",
      "          2025, 10047, 23041, 24278,  1010,  2021,  2089,  2022,  2522,  1011,\n",
      "          8564,  2007,  2019, 10047, 23041, 24278,  7328,  1010,  2004,  2003,\n",
      "          2823,  1996,  2553,  2005,  4171,  4747,  1012, 15078,  4725,  2031,\n",
      "          2042,  2764,  2000, 16014,  1996, 10047, 23041, 24278,  3012,  1997,\n",
      "         25117,  2015,  1998,  8171,  1010,  2029,  2024,  3391,  6179,  1999,\n",
      "         12697, 17261, 22931,  1010, 20077,  3497,  6819,  6820, 22717,  1997,\n",
      "         14494,  1999, 13434,  5435,  9309,  1010,  1998, 27354,  1997,  3818,\n",
      "         25117,  1011,  2241,  4319, 13441,  1012,  2220,  5461, 13538,  3701,\n",
      "          2006,  1996,  8089,  2008, 18479, 21850, 10415, 13096, 12737,  2024,\n",
      "          2058,  2890, 28994, 14088,  1999,  4958,  9956,  5051,  4655,  2084,\n",
      "         18479, 20200, 13096, 12737,  1025,  2174,  1010,  2062,  3522,  8973,\n",
      "         11160,  2006,  3698,  4083,  5461,  2478, 17881,  1997,  4493,  2124,\n",
      "          4958,  9956, 10374,  1010,  2788,  2006,  2092,  1011,  3273,  7865,\n",
      "          8171,  1010,  2004,  1037,  2731,  2275,  1012,  1037,  7271,  7801,\n",
      "          7809,  2038,  2042,  2511,  2005,  1996, 12105, 25165,  1997,  4958,\n",
      "          9956, 10374,  2013, 26835,  2015,  2124,  2000,  2022, 20123,  2011,\n",
      "          1038,  4442,  1012,  1996,  8361,  2492,  1997, 16012,  2378, 14192,\n",
      "         17592,  1011,  2241,  2913,  1997, 10047,   102, 10047, 23041, 24278,\n",
      "          3012,   102, 16012,  2378, 14192, 17592,   102,  2492,   102,  2124,\n",
      "           102,  1058,  2497,  2290,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "['[CLS]', 'larger', 'drugs', '(', '>', '500', 'da', ')', 'can', 'provoke', 'a', 'neutral', '##izing', 'immune', 'response', ',', 'particularly', 'if', 'the', 'drugs', 'are', 'administered', 'repeatedly', ',', 'or', 'in', 'larger', 'doses', '.', 'this', 'limits', 'the', 'effectiveness', 'of', 'drugs', 'based', 'on', 'larger', 'peptide', '##s', 'and', 'proteins', '(', 'which', 'are', 'typically', 'larger', 'than', '6000', 'da', ')', '.', 'in', 'some', 'cases', ',', 'the', 'drug', 'itself', 'is', 'not', 'im', '##mun', '##ogenic', ',', 'but', 'may', 'be', 'co', '-', 'administered', 'with', 'an', 'im', '##mun', '##ogenic', 'compound', ',', 'as', 'is', 'sometimes', 'the', 'case', 'for', 'tax', '##ol', '.', 'computational', 'methods', 'have', 'been', 'developed', 'to', 'predict', 'the', 'im', '##mun', '##ogenic', '##ity', 'of', 'peptide', '##s', 'and', 'proteins', ',', 'which', 'are', 'particularly', 'useful', 'in', 'designing', 'therapeutic', 'antibodies', ',', 'assessing', 'likely', 'vi', '##ru', '##lence', 'of', 'mutations', 'in', 'viral', 'coat', 'particles', ',', 'and', 'validation', 'of', 'proposed', 'peptide', '-', 'based', 'drug', 'treatments', '.', 'early', 'techniques', 'relied', 'mainly', 'on', 'the', 'observation', 'that', 'hydro', '##phi', '##lic', 'amino', 'acids', 'are', 'over', '##re', '##pres', '##ented', 'in', 'ep', '##ito', '##pe', 'regions', 'than', 'hydro', '##phobic', 'amino', 'acids', ';', 'however', ',', 'more', 'recent', 'developments', 'rely', 'on', 'machine', 'learning', 'techniques', 'using', 'databases', 'of', 'existing', 'known', 'ep', '##ito', '##pes', ',', 'usually', 'on', 'well', '-', 'studied', 'virus', 'proteins', ',', 'as', 'a', 'training', 'set', '.', 'a', 'publicly', 'accessible', 'database', 'has', 'been', 'established', 'for', 'the', 'catalog', '##uing', 'of', 'ep', '##ito', '##pes', 'from', 'pathogen', '##s', 'known', 'to', 'be', 'recognizable', 'by', 'b', 'cells', '.', 'the', 'emerging', 'field', 'of', 'bio', '##in', '##form', '##atics', '-', 'based', 'studies', 'of', 'im', '[SEP]', 'im', '##mun', '##ogenic', '##ity', '[SEP]', 'bio', '##in', '##form', '##atics', '[SEP]', 'field', '[SEP]', 'known', '[SEP]', 'v', '##b', '##g', '[SEP]', '[PAD]']\n",
      "[5702]\n",
      "tensor(-26.1324)\n",
      "studying 26.132354736328125\n",
      "[['what'], ['w', '##hn', '##p'], ['what']]\n",
      "tensor([[  101,  3469,  5850,  1006,  1028,  3156,  4830,  1007,  2064, 27895,\n",
      "          1037,  8699,  6026, 11311,  3433,  1010,  3391,  2065,  1996,  5850,\n",
      "          2024,  8564,  8385,  1010,  2030,  1999,  3469, 21656,  1012,  2023,\n",
      "          6537,  1996, 12353,  1997,  5850,  2241,  2006,  3469, 25117,  2015,\n",
      "          1998,  8171,  1006,  2029,  2024,  4050,  3469,  2084, 25961,  4830,\n",
      "          1007,  1012,  1999,  2070,  3572,  1010,  1996,  4319,  2993,  2003,\n",
      "          2025, 10047, 23041, 24278,  1010,  2021,  2089,  2022,  2522,  1011,\n",
      "          8564,  2007,  2019, 10047, 23041, 24278,  7328,  1010,  2004,  2003,\n",
      "          2823,  1996,  2553,  2005,  4171,  4747,  1012, 15078,  4725,  2031,\n",
      "          2042,  2764,  2000, 16014,  1996, 10047, 23041, 24278,  3012,  1997,\n",
      "         25117,  2015,  1998,  8171,  1010,  2029,  2024,  3391,  6179,  1999,\n",
      "         12697, 17261, 22931,  1010, 20077,  3497,  6819,  6820, 22717,  1997,\n",
      "         14494,  1999, 13434,  5435,  9309,  1010,  1998, 27354,  1997,  3818,\n",
      "         25117,  1011,  2241,  4319, 13441,  1012,  2220,  5461, 13538,  3701,\n",
      "          2006,  1996,  8089,  2008, 18479, 21850, 10415, 13096, 12737,  2024,\n",
      "          2058,  2890, 28994, 14088,  1999,  4958,  9956,  5051,  4655,  2084,\n",
      "         18479, 20200, 13096, 12737,  1025,  2174,  1010,  2062,  3522,  8973,\n",
      "         11160,  2006,  3698,  4083,  5461,  2478, 17881,  1997,  4493,  2124,\n",
      "          4958,  9956, 10374,  1010,  2788,  2006,  2092,  1011,  3273,  7865,\n",
      "          8171,  1010,  2004,  1037,  2731,  2275,  1012,  1037,  7271,  7801,\n",
      "          7809,  2038,  2042,  2511,  2005,  1996, 12105, 25165,  1997,  4958,\n",
      "          9956, 10374,  2013, 26835,  2015,  2124,  2000,  2022, 20123,  2011,\n",
      "          1038,  4442,  1012,  1996,  8361,  2492,  1997, 16012,  2378, 14192,\n",
      "         17592,  1011,  2241,  2913,   102, 10047, 23041, 24278,  3012,   102,\n",
      "         16012,  2378, 14192, 17592,   102,  2492,   102,  2124,   102,  5702,\n",
      "           102,  1059,  7295,  2361,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "['[CLS]', 'larger', 'drugs', '(', '>', '500', 'da', ')', 'can', 'provoke', 'a', 'neutral', '##izing', 'immune', 'response', ',', 'particularly', 'if', 'the', 'drugs', 'are', 'administered', 'repeatedly', ',', 'or', 'in', 'larger', 'doses', '.', 'this', 'limits', 'the', 'effectiveness', 'of', 'drugs', 'based', 'on', 'larger', 'peptide', '##s', 'and', 'proteins', '(', 'which', 'are', 'typically', 'larger', 'than', '6000', 'da', ')', '.', 'in', 'some', 'cases', ',', 'the', 'drug', 'itself', 'is', 'not', 'im', '##mun', '##ogenic', ',', 'but', 'may', 'be', 'co', '-', 'administered', 'with', 'an', 'im', '##mun', '##ogenic', 'compound', ',', 'as', 'is', 'sometimes', 'the', 'case', 'for', 'tax', '##ol', '.', 'computational', 'methods', 'have', 'been', 'developed', 'to', 'predict', 'the', 'im', '##mun', '##ogenic', '##ity', 'of', 'peptide', '##s', 'and', 'proteins', ',', 'which', 'are', 'particularly', 'useful', 'in', 'designing', 'therapeutic', 'antibodies', ',', 'assessing', 'likely', 'vi', '##ru', '##lence', 'of', 'mutations', 'in', 'viral', 'coat', 'particles', ',', 'and', 'validation', 'of', 'proposed', 'peptide', '-', 'based', 'drug', 'treatments', '.', 'early', 'techniques', 'relied', 'mainly', 'on', 'the', 'observation', 'that', 'hydro', '##phi', '##lic', 'amino', 'acids', 'are', 'over', '##re', '##pres', '##ented', 'in', 'ep', '##ito', '##pe', 'regions', 'than', 'hydro', '##phobic', 'amino', 'acids', ';', 'however', ',', 'more', 'recent', 'developments', 'rely', 'on', 'machine', 'learning', 'techniques', 'using', 'databases', 'of', 'existing', 'known', 'ep', '##ito', '##pes', ',', 'usually', 'on', 'well', '-', 'studied', 'virus', 'proteins', ',', 'as', 'a', 'training', 'set', '.', 'a', 'publicly', 'accessible', 'database', 'has', 'been', 'established', 'for', 'the', 'catalog', '##uing', 'of', 'ep', '##ito', '##pes', 'from', 'pathogen', '##s', 'known', 'to', 'be', 'recognizable', 'by', 'b', 'cells', '.', 'the', 'emerging', 'field', 'of', 'bio', '##in', '##form', '##atics', '-', 'based', 'studies', '[SEP]', 'im', '##mun', '##ogenic', '##ity', '[SEP]', 'bio', '##in', '##form', '##atics', '[SEP]', 'field', '[SEP]', 'known', '[SEP]', 'studying', '[SEP]', 'w', '##hn', '##p', '[SEP]', '[PAD]']\n",
      "[2054]\n",
      "tensor(-17.6354)\n",
      "what 17.635421752929688\n"
     ]
    }
   ],
   "source": [
    "print(context_text)\n",
    "print(\"~\"*20)\n",
    "#print(raw_targ)\n",
    "print(question)\n",
    "for step in range(len(targs_2_tokens)):\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(targs_2_tokens[step][0])):\n",
    "            thetarg = [targs_2_tokens[step][0][:i+1], targs_2_tokens[step][1], targs_2_tokens[step][2][:i+1]]\n",
    "            print(thetarg)\n",
    "            input_ids, input_mask, segment_ids = build_input(context_text, targs_2_tokens[:step], thetarg, multihint)\n",
    "            output, _ = model(input_ids, segment_ids, input_mask, None, None)\n",
    "            start_i = np.where(input_mask.data.numpy() == 0)[1][0]\n",
    "            print(input_ids)\n",
    "            print(input_mask)\n",
    "            print(tokenizer.convert_ids_to_tokens(input_ids[0].numpy()))\n",
    "        \n",
    "            the_ids = targs_2_ids[step][2][i:i+1]\n",
    "            print(the_ids)\n",
    "            perplex = perplexity(the_ids, output[0][start_i:])\n",
    "            print(raw_targ[step][1][i], -perplex)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "add check for end token in perplexiy counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_odds(examples, dataloader, multihint=False):\n",
    "    if len(examples) == 0:\n",
    "        return 0\n",
    "    total_total_odds = 0\n",
    "    total_total_perlex = 0\n",
    "    max_perplex = 0\n",
    "    results = {}\n",
    "    for example in examples:\n",
    "        cid, qid, targetid, _ = example\n",
    "        context = dataloader.dataset.contexts[cid]\n",
    "        question = dataloader.dataset.questions[qid]\n",
    "        print(question)\n",
    "        raw_targ = dataloader.dataset.raw_targets[targetid]\n",
    "        results[(context, question)] = {}\n",
    "\n",
    "        raw_targ_copy = list(raw_targ)\n",
    "        raw_targ = [(tag,word) for (word,(_,tag)) in raw_targ if word]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            targs_2_tokens = []            \n",
    "            for tidx, (tag, words) in enumerate(raw_targ):\n",
    "                clean_tag = tag\n",
    "                if multihint:\n",
    "                    span = tokenizer.tokenize(clean_tag) + [\"[SEP]\"] + words\n",
    "                else:\n",
    "                    span = words\n",
    "                targs_2_tokens.append((span, tokenizer.tokenize(clean_tag), words))\n",
    "                    \n",
    "            targs_2_ids = [list(map(tokenizer.convert_tokens_to_ids, t)) for t in targs_2_tokens]\n",
    "\n",
    "            total_odds = 0\n",
    "            total_perplex = 0\n",
    "            for token_idx in range(len(raw_targ)):\n",
    "                input_ids, input_mask, segment_ids = build_input(context, targs_2_tokens[:token_idx], targs_2_tokens[token_idx], multihint)\n",
    "                output, _ = model(input_ids, segment_ids, input_mask, None, None)\n",
    "                \n",
    "                start_i = np.where(input_mask.data.numpy() == 0)[1][0]\n",
    "                if len(targs_2_ids[token_idx]) == 0:\n",
    "                    print(token_idx, targs_2_ids, targs_2_ids[token_idx], raw_targ)\n",
    "                perplex = perplexity(targs_2_ids[token_idx][2], output[0][start_i:])\n",
    "                results[(context, question)][(str([tt[0] for tt in targs_2_tokens[:token_idx]]), \n",
    "                                              str(targs_2_tokens[token_idx][1:]))] = -perplex\n",
    "                \n",
    "                normalizers = []\n",
    "                for ij in range(len(targs_2_ids[token_idx][2])):\n",
    "                    normalizers.append(int(np.argmax(output[0][start_i+ij]).numpy()))\n",
    "                norm_perplex = perplexity(normalizers, output[0][start_i:])\n",
    "                #print(norm_perplex)\n",
    "                #assert False\n",
    "                print(\"Target\", tokenizer.convert_ids_to_tokens(targs_2_ids[token_idx][2]))\n",
    "                print(\"Normalized\", tokenizer.convert_ids_to_tokens(normalizers))\n",
    "                print(\"perplex\", perplex)\n",
    "                print(\"Norm\", np.abs(norm_perplex))\n",
    "                print(\"normalized perplex\", perplex / np.abs(norm_perplex))\n",
    "                print(\"~\"*20)\n",
    "                total_perplex += perplex / np.abs(norm_perplex) / len(raw_targ)\n",
    "                #print(\"Total\", total_perplex)\n",
    "\n",
    "            total_odds /= len(raw_targ)\n",
    "            total_total_odds += total_odds\n",
    "            total_total_perlex += -total_perplex\n",
    "            if -total_perplex > max_perplex:\n",
    "                max_perplex = -total_perplex\n",
    "    return (total_total_perlex / len(examples)), max_perplex, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic equilibrium was first described by Galileo who noticed that certain assumptions of Aristotelian physics were contradicted by observations and logic. Galileo realized that simple velocity addition demands that the concept of an \"absolute rest frame\" did not exist. Galileo concluded that motion in a constant velocity was completely equivalent to rest. This was contrary to Aristotle's notion of a \"natural state\" of rest that objects with mass naturally approached. Simple experiments showed that Galileo's understanding of the equivalence of constant velocity and rest were correct. For example, if a mariner dropped a cannonball from the crow's nest of a ship moving at a constant velocity, Aristotelian physics would have the cannonball fall straight down while the ship moved beneath it. Thus, in an Aristotelian universe, the falling cannonball would land behind the foot of the mast of a moving ship. However, when this experiment is actually conducted, the cannonball always falls at the foot of the mast, as if the cannonball knows to travel with the ship despite being separated from it. Since there is no forward horizontal force being applied on the cannonball as it falls, the only conclusion left is that the cannonball continues to move with the same velocity as the boat as it falls. Thus, no force is required to keep the cannonball moving at the constant forward velocity.\n",
      "####################\n",
      "Start Answerable\n",
      "Where will a canonball dropped from the crow's nest of a ship land according to Aristotle?\n",
      "Target ['from', 'the', 'crow', \"'\", 's', 'nest', 'of', 'a', 'ship']\n",
      "Normalized ['at', 'an', 'ari', 'of', 'of', 'the', 'the', \"'\", 'time']\n",
      "perplex -4.236351490020752\n",
      "Norm 2.098233938217163\n",
      "normalized perplex -2.0190081824814605\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['canon', '##ball']\n",
      "Normalized ['cannon', 'cannon']\n",
      "perplex -6.3143205642700195\n",
      "Norm 1.0456690788269043\n",
      "normalized perplex -6.038545742744742\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['dropped']\n",
      "Normalized ['dropped']\n",
      "perplex -0.07864761352539062\n",
      "Norm 0.07864761352539062\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['aristotle']\n",
      "Normalized ['galileo']\n",
      "perplex -6.495388507843018\n",
      "Norm 0.3210906982421875\n",
      "normalized perplex -20.229139440669105\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['according']\n",
      "Normalized ['moving']\n",
      "perplex -5.352364540100098\n",
      "Norm 0.0744180679321289\n",
      "normalized perplex -71.9229172273269\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['where']\n",
      "Normalized ['how']\n",
      "perplex -1.7417707443237305\n",
      "Norm 0.8638916015625\n",
      "normalized perplex -2.016191315175922\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Who had the idea of a natural state for objects at rest?\n",
      "Target ['natural', 'state']\n",
      "Normalized ['dynamic', 'equilibrium']\n",
      "perplex -5.972507476806641\n",
      "Norm 0.8511242866516113\n",
      "normalized perplex -7.017197805860935\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['objects']\n",
      "Normalized ['objects']\n",
      "perplex -0.5525016784667969\n",
      "Norm 0.5525016784667969\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['rest']\n",
      "Normalized ['rest']\n",
      "perplex -0.45050621032714844\n",
      "Norm 0.45050621032714844\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['idea']\n",
      "Normalized ['it']\n",
      "perplex -3.8831820487976074\n",
      "Norm 1.9398469924926758\n",
      "normalized perplex -2.001798112854135\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['who']\n",
      "Normalized ['what']\n",
      "perplex -0.8874330520629883\n",
      "Norm 0.7084417343139648\n",
      "normalized perplex -1.252654959581614\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What does motion at a constant velocity equal?\n",
      "Target ['at', 'a', 'constant', 'velocity']\n",
      "Normalized ['at', 'an', 'ari', 'time']\n",
      "perplex -3.2445621490478516\n",
      "Norm 1.9027128219604492\n",
      "normalized perplex -1.7052295604466656\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['motion']\n",
      "Normalized ['cannon']\n",
      "perplex -5.499201774597168\n",
      "Norm 0.3947772979736328\n",
      "normalized perplex -13.929883513627118\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what']\n",
      "Normalized ['what']\n",
      "perplex -0.01660442352294922\n",
      "Norm 0.01660442352294922\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Where does a canonball dropped from the crow's nest of a ship actually land?\n",
      "Target ['from', 'the', 'crow', \"'\", 's', 'nest', 'of', 'a', 'ship']\n",
      "Normalized ['at', 'an', 'ari', 'of', 'of', 'the', 'the', \"'\", 'time']\n",
      "perplex -4.236351490020752\n",
      "Norm 2.098233938217163\n",
      "normalized perplex -2.0190081824814605\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['canon', '##ball']\n",
      "Normalized ['cannon', 'cannon']\n",
      "perplex -6.3143205642700195\n",
      "Norm 1.0456690788269043\n",
      "normalized perplex -6.038545742744742\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['dropped']\n",
      "Normalized ['dropped']\n",
      "perplex -0.07864761352539062\n",
      "Norm 0.07864761352539062\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['actually']\n",
      "Normalized ['down']\n",
      "perplex -4.61863374710083\n",
      "Norm 1.1667156219482422\n",
      "normalized perplex -3.9586628139840934\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['land']\n",
      "Normalized ['fall']\n",
      "perplex -4.927979946136475\n",
      "Norm 0.2170705795288086\n",
      "normalized perplex -22.70220108516574\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['where']\n",
      "Normalized ['when']\n",
      "perplex -2.265727996826172\n",
      "Norm 0.45937347412109375\n",
      "normalized perplex -4.9322133829366726\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Who first described dynamic equilibrium?\n",
      "Target ['first', 'described']\n",
      "Normalized ['cannon', 'in']\n",
      "perplex -5.847304344177246\n",
      "Norm 1.2204432487487793\n",
      "normalized perplex -4.791131705773299\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['dynamic', 'equilibrium']\n",
      "Normalized ['dynamic', 'equilibrium']\n",
      "perplex -0.11042308807373047\n",
      "Norm 0.11042308807373047\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['who']\n",
      "Normalized ['who']\n",
      "perplex -0.0898141860961914\n",
      "Norm 0.0898141860961914\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Start Unanswerbale\n",
      "Who concluded that motion in a constant velocity was completely equivalent to motion?\n",
      "Target ['concluded', 'that', 'motion', 'in', 'a', 'constant', 'velocity', 'was', 'completely', 'equivalent']\n",
      "Normalized ['fall', 'a', 'the', 'the', 'the', 'of', 'of', 'of', \"'\", 'time']\n",
      "perplex -6.998946189880371\n",
      "Norm 2.4291915893554688\n",
      "normalized perplex -2.8811832794700987\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['who']\n",
      "Normalized ['what']\n",
      "perplex -3.3338279724121094\n",
      "Norm 0.047430992126464844\n",
      "normalized perplex -70.28796622097114\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "In what universe would a falling cannonball land in front of the mast of a moving ship?\n",
      "Target ['mast', 'of', 'a', 'moving', 'ship']\n",
      "Normalized ['ari', '##sto', '##tel', '##ian', 'physics']\n",
      "perplex -7.095129489898682\n",
      "Norm 0.8154349327087402\n",
      "normalized perplex -8.701036962360483\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['falling', 'cannon', '##ball']\n",
      "Normalized ['cannon', 'cannon', 'ball']\n",
      "perplex -2.244511365890503\n",
      "Norm 0.6374896168708801\n",
      "normalized perplex -3.5208594877320425\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['land']\n",
      "Normalized ['foot']\n",
      "perplex -4.563633918762207\n",
      "Norm 0.7461042404174805\n",
      "normalized perplex -6.116617051001666\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['front']\n",
      "Normalized ['it']\n",
      "perplex -7.018465042114258\n",
      "Norm 0.7290782928466797\n",
      "normalized perplex -9.626490201361946\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what', 'universe']\n",
      "Normalized ['what', 'universe']\n",
      "perplex -0.6747260093688965\n",
      "Norm 0.6747260093688965\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Which physics were not contradicted by observations and logic?\n",
      "Target ['contra', '##dict', '##ed', 'by', 'observations', 'and', 'logic']\n",
      "Normalized ['fall', 'a', 'the', 'the', 'the', \"'\", 'time']\n",
      "perplex -6.4881110191345215\n",
      "Norm 2.420208692550659\n",
      "normalized perplex -2.6808064276046784\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['which', 'physics', 'were']\n",
      "Normalized ['what', 'the', 'of']\n",
      "perplex -4.15728759765625\n",
      "Norm 2.2668673992156982\n",
      "normalized perplex -1.8339350590575383\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What type of equilibrium was first described by Aristotle?\n",
      "Target ['what', 'type', 'of', 'equilibrium', 'was', 'first', 'described', 'by']\n",
      "Normalized ['what', 'the', 'of', 'the', 'the', 'the', 'the', 'time']\n",
      "perplex -5.04275369644165\n",
      "Norm 2.655755043029785\n",
      "normalized perplex -1.89880226705272\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['aristotle']\n",
      "Normalized ['galileo']\n",
      "perplex -7.675585746765137\n",
      "Norm 0.0025529861450195312\n",
      "normalized perplex -3006.5128875607024\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "6.8484967909787 387.21019778698013 17.204300318066355 1504.2058449138776\n",
      "The Catholic Church in France and many of its members opposed the Huguenots. Some Huguenot preachers and congregants were attacked as they attempted to meet for worship. The height of this persecution was the St. Bartholomew's Day massacre when 5,000 to 30,000 were killed, although there were also underlying political reasons for this as well, as some of the Huguenots were nobles trying to establish separate centers of power in southern France. Retaliating against the French Catholics, the Huguenots had their own militia.\n",
      "####################\n",
      "Start Answerable\n",
      "What was a non-religious reason for the massacre?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ['non', '-', 'religious', 'reason']\n",
      "Normalized ['catholic', '.', '##ots', 'day']\n",
      "perplex -7.427223205566406\n",
      "Norm 1.5164649486541748\n",
      "normalized perplex -4.897721646753447\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['massacre']\n",
      "Normalized ['persecution']\n",
      "perplex -4.476167678833008\n",
      "Norm 0.34348583221435547\n",
      "normalized perplex -13.031593326503245\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what']\n",
      "Normalized ['what']\n",
      "perplex -0.04803466796875\n",
      "Norm 0.04803466796875\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "How many Huguenots were killed during this purge?\n",
      "Target ['how', 'many', 'hug', '##uen', '##ots', 'were']\n",
      "Normalized ['how', 'many', 'protestants', '##ots', '##ots', '[SEP]']\n",
      "perplex -2.8615729808807373\n",
      "Norm 1.2262383699417114\n",
      "normalized perplex -2.33361885504917\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['killed']\n",
      "Normalized ['attacked']\n",
      "perplex -2.116086006164551\n",
      "Norm 0.47498321533203125\n",
      "normalized perplex -4.455075332894293\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['purge']\n",
      "Normalized ['persecution']\n",
      "perplex -9.608264923095703\n",
      "Norm 2.8478708267211914\n",
      "normalized perplex -3.3738415496035272\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What group specifically opposed the Huguenots?\n",
      "Target ['opposed', 'the', 'hug', '##uen', '##ots']\n",
      "Normalized ['people', 'church', '##ots', '##ots', '[SEP]']\n",
      "perplex -6.972914218902588\n",
      "Norm 1.3956732749938965\n",
      "normalized perplex -4.996093529793412\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['specifically']\n",
      "Normalized ['strongly']\n",
      "perplex -5.824065685272217\n",
      "Norm 2.3947792053222656\n",
      "normalized perplex -2.431984406883336\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what', 'group']\n",
      "Normalized ['what', '[SEP]']\n",
      "perplex -1.0179009437561035\n",
      "Norm 0.759373664855957\n",
      "normalized perplex -1.3404480440458593\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "How did the Huguenots defend themselves?\n",
      "Target ['hug', '##uen', '##ots']\n",
      "Normalized ['hug', '[SEP]', '##ots']\n",
      "perplex -0.8847723007202148\n",
      "Norm 0.7446317672729492\n",
      "normalized perplex -1.188201121153479\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['defend']\n",
      "Normalized ['try']\n",
      "perplex -6.133404731750488\n",
      "Norm 1.878493309020996\n",
      "normalized perplex -3.2650660517641135\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['themselves']\n",
      "Normalized ['themselves']\n",
      "perplex -0.9858713150024414\n",
      "Norm 0.9858713150024414\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['how']\n",
      "Normalized ['how']\n",
      "perplex -0.4722871780395508\n",
      "Norm 0.4722871780395508\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What event was the worst example of Huguenot persecution?\n",
      "Target ['hug', '##uen', '##ot', 'persecution']\n",
      "Normalized ['catholic', '.', '##ots', 'day']\n",
      "perplex -4.702678203582764\n",
      "Norm 1.5164649486541748\n",
      "normalized perplex -3.101079393728338\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['worst', 'example']\n",
      "Normalized ['place', '[SEP]']\n",
      "perplex -6.687450408935547\n",
      "Norm 1.7278409004211426\n",
      "normalized perplex -3.8704086743782677\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what', 'event']\n",
      "Normalized ['what', '[SEP]']\n",
      "perplex -1.4063084125518799\n",
      "Norm 0.15459775924682617\n",
      "normalized perplex -9.096564008451182\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Start Unanswerbale\n",
      "How many French Catholics died during the Bartholomew's Day massacre?\n",
      "Target ['bartholomew', \"'\", 's', 'day', 'massacre']\n",
      "Normalized ['catholic', '.', '##ots', 'day', '[SEP]']\n",
      "perplex -4.518028259277344\n",
      "Norm 1.5419267416000366\n",
      "normalized perplex -2.9301186219710065\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['died']\n",
      "Normalized ['died']\n",
      "perplex -0.20462989807128906\n",
      "Norm 0.20462989807128906\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['how', 'many', 'french', 'catholics']\n",
      "Normalized ['how', 'many', 'people', '[SEP]']\n",
      "perplex -3.3183679580688477\n",
      "Norm 0.23196983337402344\n",
      "normalized perplex -14.305170244780832\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "How many Huguenots were there in Northern France during this time?\n",
      "Target ['how', 'many', 'hug', '##uen', '##ots', 'were']\n",
      "Normalized ['how', 'many', 'protestants', '##ots', '##ots', '[SEP]']\n",
      "perplex -2.8615729808807373\n",
      "Norm 1.2262383699417114\n",
      "normalized perplex -2.33361885504917\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['northern', 'france']\n",
      "Normalized ['catholic', 'church']\n",
      "perplex -4.912137508392334\n",
      "Norm 1.1639716625213623\n",
      "normalized perplex -4.220152145071815\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['there']\n",
      "Normalized ['first']\n",
      "perplex -3.7242350578308105\n",
      "Norm 2.8014822006225586\n",
      "normalized perplex -1.3293802320083252\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['time']\n",
      "Normalized ['attacks']\n",
      "perplex -3.9359593391418457\n",
      "Norm 2.473994255065918\n",
      "normalized perplex -1.590933095775105\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "How many French nobles were Huguenots?\n",
      "Target ['hug', '##uen', '##ots']\n",
      "Normalized ['hug', '[SEP]', '##ots']\n",
      "perplex -0.8847723007202148\n",
      "Norm 0.7446317672729492\n",
      "normalized perplex -1.188201121153479\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['how', 'many', 'french', 'nobles']\n",
      "Normalized ['what', '[SEP]', '[SEP]', '[SEP]']\n",
      "perplex -5.428681373596191\n",
      "Norm 0.519812822341919\n",
      "normalized perplex -10.443531094785788\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "How many French Catholics died after the Huguenots retaliated?\n",
      "Target ['hug', '##uen', '##ots']\n",
      "Normalized ['hug', '[SEP]', '##ots']\n",
      "perplex -0.8847723007202148\n",
      "Norm 0.7446317672729492\n",
      "normalized perplex -1.188201121153479\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['re', '##tal', '##iated']\n",
      "Normalized ['attacked', '[SEP]', '[SEP]']\n",
      "perplex -5.784820556640625\n",
      "Norm 0.6012179255485535\n",
      "normalized perplex -9.621836460319331\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['died']\n",
      "Normalized ['attacked']\n",
      "perplex -7.171735763549805\n",
      "Norm 0.9488058090209961\n",
      "normalized perplex -7.558697148945366\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['how', 'many', 'french', 'catholics']\n",
      "Normalized ['who', '[SEP]', '[SEP]', '[SEP]']\n",
      "perplex -3.6639113426208496\n",
      "Norm 0.43520641326904297\n",
      "normalized perplex -8.418789868236232\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "3.917891943184818 5.239924490464988 6.309771657752231 6.696881149663602\n",
      "The principle of faunal succession is based on the appearance of fossils in sedimentary rocks. As organisms exist at the same time period throughout the world, their presence or (sometimes) absence may be used to provide a relative age of the formations in which they are found. Based on principles laid out by William Smith almost a hundred years before the publication of Charles Darwin's theory of evolution, the principles of succession were developed independently of evolutionary thought. The principle becomes quite complex, however, given the uncertainties of fossilization, the localization of fossil types due to lateral changes in habitat (facies change in sedimentary strata), and that not all fossils may be found globally at the same time.\n",
      "####################\n",
      "Start Answerable\n",
      "The presence or absence of what can be used to determine the relative age of the formations in which they are found? \n",
      "Target ['relative', 'age', 'of', 'the', 'formations', 'in', 'which', 'they', 'are', 'found']\n",
      "Normalized ['principles', 'of', 'succession', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]']\n",
      "perplex -6.757565498352051\n",
      "Norm 0.9065224528312683\n",
      "normalized perplex -7.454382930336356\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['presence', 'or', 'absence']\n",
      "Normalized ['organisms', 'of', 'succession']\n",
      "perplex -6.276908874511719\n",
      "Norm 1.141871452331543\n",
      "normalized perplex -5.497036344761175\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['determine']\n",
      "Normalized ['provide']\n",
      "perplex -7.004630088806152\n",
      "Norm 0.059510231018066406\n",
      "normalized perplex -117.70463614365154\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what']\n",
      "Normalized ['what']\n",
      "perplex -0.020630836486816406\n",
      "Norm 0.020630836486816406\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Whose principles were the principle of faunal succession built upon?\n",
      "Target ['principle', 'of', 'fauna', '##l', 'succession']\n",
      "Normalized ['principles', 'of', 'succession', '[SEP]', '[SEP]']\n",
      "perplex -3.942295789718628\n",
      "Norm 0.9276749491691589\n",
      "normalized perplex -4.249652093386173\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['built']\n",
      "Normalized ['based']\n",
      "perplex -6.7629075050354\n",
      "Norm 0.09575080871582031\n",
      "normalized perplex -70.63029122925838\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['whose', 'principles']\n",
      "Normalized ['what', '[SEP]']\n",
      "perplex -4.682814598083496\n",
      "Norm 0.5448813438415527\n",
      "normalized perplex -8.594191471244834\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Which principle is based on the appearance of fossils in sedimentary rocks?\n",
      "Target ['based', 'on', 'the', 'appearance', 'of', 'fossils', 'in', 'sedimentary', 'rocks']\n",
      "Normalized ['based', 'on', 'the', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]']\n",
      "perplex -3.501389741897583\n",
      "Norm 1.212471842765808\n",
      "normalized perplex -2.887811179111963\n",
      "~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ['which', 'principle']\n",
      "Normalized ['what', '[SEP]']\n",
      "perplex -2.380352020263672\n",
      "Norm 0.34424877166748047\n",
      "normalized perplex -6.914627490851066\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "The fact that not all fossils may be found globally at the same time causes the principle to become what?\n",
      "Target ['fact', 'that', 'not', 'all', 'fossils', 'may', 'be', 'found', 'globally', 'at', 'the', 'same', 'time']\n",
      "Normalized ['principles', 'of', 'succession', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]']\n",
      "perplex -7.518015384674072\n",
      "Norm 0.9021682143211365\n",
      "normalized perplex -8.333274510598036\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['principle']\n",
      "Normalized ['existence']\n",
      "perplex -6.338626861572266\n",
      "Norm 1.9399747848510742\n",
      "normalized perplex -3.2673759015166075\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['causes']\n",
      "Normalized ['describes']\n",
      "perplex -3.7770395278930664\n",
      "Norm 2.2571983337402344\n",
      "normalized perplex -1.673330815212156\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "The principle of faunal succession was developed 100 years before whose theory of evolution?\n",
      "Target ['principle', 'of', 'fauna', '##l', 'succession']\n",
      "Normalized ['principles', 'of', 'succession', '[SEP]', '[SEP]']\n",
      "perplex -3.942295789718628\n",
      "Norm 0.9276749491691589\n",
      "normalized perplex -4.249652093386173\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['whose', 'theory', 'of', 'evolution']\n",
      "Normalized ['based', 'on', 'on', 'on']\n",
      "perplex -5.333693504333496\n",
      "Norm 0.7238907814025879\n",
      "normalized perplex -7.368091487501886\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['100', 'years', 'before']\n",
      "Normalized ['based', 'on', 'on']\n",
      "perplex -10.341841697692871\n",
      "Norm 0.3420480191707611\n",
      "normalized perplex -30.23505799789444\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['developed']\n",
      "Normalized ['published']\n",
      "perplex -1.781794548034668\n",
      "Norm 1.0028057098388672\n",
      "normalized perplex -1.7768093365971862\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Start Unanswerbale\n",
      "What can changes in habitat be used to provide about formations?\n",
      "Target ['be', 'used', 'to', 'provide']\n",
      "Normalized ['based', 'on', 'the', '[SEP]']\n",
      "perplex -7.800359725952148\n",
      "Norm 1.0327363014221191\n",
      "normalized perplex -7.553099194064101\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['changes', 'in', 'habitat']\n",
      "Normalized ['relative', 'of', '[SEP]']\n",
      "perplex -8.712723731994629\n",
      "Norm 0.9656794667243958\n",
      "normalized perplex -9.022376505061626\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['formations']\n",
      "Normalized ['organisms']\n",
      "perplex -9.613029479980469\n",
      "Norm 0.43136024475097656\n",
      "normalized perplex -22.285385816048144\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what']\n",
      "Normalized ['what']\n",
      "perplex -0.021596908569335938\n",
      "Norm 0.021596908569335938\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What is the theory of evolution based on?\n",
      "Target ['theory', 'of', 'evolution']\n",
      "Normalized ['principles', 'of', 'succession']\n",
      "perplex -3.188722610473633\n",
      "Norm 0.9003005027770996\n",
      "normalized perplex -3.5418425299525915\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['based', 'on']\n",
      "Normalized ['based', 'on']\n",
      "perplex -0.21177339553833008\n",
      "Norm 0.21177339553833008\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what']\n",
      "Normalized ['what']\n",
      "perplex -0.5687885284423828\n",
      "Norm 0.5687885284423828\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What is one uncertainty about the theory of evolution that makes it complex?\n",
      "Target ['theory', 'of', 'evolution']\n",
      "Normalized ['principles', 'of', 'succession']\n",
      "perplex -3.188722610473633\n",
      "Norm 0.9003005027770996\n",
      "normalized perplex -3.5418425299525915\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['one', 'uncertainty']\n",
      "Normalized ['charles', 'smith']\n",
      "perplex -8.65058422088623\n",
      "Norm 0.9207777976989746\n",
      "normalized perplex -9.394866212569477\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['complex']\n",
      "Normalized ['complex']\n",
      "perplex -0.03846549987792969\n",
      "Norm 0.03846549987792969\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['makes']\n",
      "Normalized ['makes']\n",
      "perplex -0.3389577865600586\n",
      "Norm 0.3389577865600586\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['it']\n",
      "Normalized ['it']\n",
      "perplex -1.1433658599853516\n",
      "Norm 1.1433658599853516\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what']\n",
      "Normalized ['what']\n",
      "perplex -0.041656494140625\n",
      "Norm 0.041656494140625\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['that']\n",
      "Normalized ['that']\n",
      "perplex -0.02019214630126953\n",
      "Norm 0.02019214630126953\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "The principles of succession are dependent on what thought?\n",
      "Target ['principles', 'of', 'succession']\n",
      "Normalized ['principles', 'of', 'succession']\n",
      "perplex -0.9003005027770996\n",
      "Norm 0.9003005027770996\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['thought']\n",
      "Normalized ['development']\n",
      "perplex -6.53094482421875\n",
      "Norm 2.227182388305664\n",
      "normalized perplex -2.932379879847733\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['what']\n",
      "Normalized ['what']\n",
      "perplex -0.8075971603393555\n",
      "Norm 0.8075971603393555\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "How much time after Charles Darwin, did William Smith develop the principles of succession?\n",
      "Target ['principles', 'of', 'succession']\n",
      "Normalized ['principles', 'of', 'succession']\n",
      "perplex -0.9003005027770996\n",
      "Norm 0.9003005027770996\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['charles', 'darwin']\n",
      "Normalized ['charles', 'smith']\n",
      "perplex -2.518123149871826\n",
      "Norm 1.0257127285003662\n",
      "normalized perplex -2.454998441477298\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['william', 'smith']\n",
      "Normalized ['his', 'smith']\n",
      "perplex -1.484246015548706\n",
      "Norm 1.4438579082489014\n",
      "normalized perplex -1.0279723559147085\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['develop']\n",
      "Normalized ['publish']\n",
      "perplex -3.110356330871582\n",
      "Norm 0.6315479278564453\n",
      "normalized perplex -4.924972743444081\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['how', 'much', 'time']\n",
      "Normalized ['what', '[SEP]', '[SEP]']\n",
      "perplex -5.60528039932251\n",
      "Norm 0.3228050768375397\n",
      "normalized perplex -17.364288239318856\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "When was Charles Darwin's theory of evolution published?\n",
      "Target ['charles', 'darwin', \"'\", 's', 'theory', 'of', 'evolution']\n",
      "Normalized ['principles', 'of', 'succession', '[SEP]', '[SEP]', '[SEP]', '[SEP]']\n",
      "perplex -3.661372423171997\n",
      "Norm 0.9161912798881531\n",
      "normalized perplex -3.996296956263293\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['published']\n",
      "Normalized ['published']\n",
      "perplex -0.7957601547241211\n",
      "Norm 0.7957601547241211\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['when']\n",
      "Normalized ['how']\n",
      "perplex -1.0626983642578125\n",
      "Norm 0.5129594802856445\n",
      "normalized perplex -2.071700407342199\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Why is it easy to use an organism's absence to show the age of a formation?\n",
      "Target ['organism', \"'\", 's']\n",
      "Normalized ['principles', 'of', 'succession']\n",
      "perplex -5.617847442626953\n",
      "Norm 0.9003005027770996\n",
      "normalized perplex -6.239969238379782\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['absence']\n",
      "Normalized ['absence']\n",
      "perplex -0.2429065704345703\n",
      "Norm 0.2429065704345703\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['age']\n",
      "Normalized ['age']\n",
      "perplex -1.4342365264892578\n",
      "Norm 1.4342365264892578\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['it']\n",
      "Normalized ['it']\n",
      "perplex -1.1665430068969727\n",
      "Norm 1.1665430068969727\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['use']\n",
      "Normalized ['provide']\n",
      "perplex -4.878263473510742\n",
      "Norm 1.3992290496826172\n",
      "normalized perplex -3.4863937927941557\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['formation']\n",
      "Normalized ['it']\n",
      "perplex -5.358642578125\n",
      "Norm 1.1428098678588867\n",
      "normalized perplex -4.68900621952512\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['why']\n",
      "Normalized ['how']\n",
      "perplex -1.2822790145874023\n",
      "Norm 0.6079549789428711\n",
      "normalized perplex -2.109167716361275\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Why is the theory of evolution so complex?\n",
      "Target ['theory', 'of', 'evolution']\n",
      "Normalized ['principles', 'of', 'succession']\n",
      "perplex -3.188722610473633\n",
      "Norm 0.9003005027770996\n",
      "normalized perplex -3.5418425299525915\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['so', 'complex']\n",
      "Normalized ['independently', '[SEP]']\n",
      "perplex -3.9576117992401123\n",
      "Norm 0.8410077095031738\n",
      "normalized perplex -4.705797288800213\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['why']\n",
      "Normalized ['why']\n",
      "perplex -0.009103775024414062\n",
      "Norm 0.009103775024414062\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Where can sedimentary rock not be found at the same time?\n",
      "Target ['at', 'the', 'same', 'time']\n",
      "Normalized ['on', 'the', '[SEP]', '[SEP]']\n",
      "perplex -2.3053717613220215\n",
      "Norm 1.3014228343963623\n",
      "normalized perplex -1.7714240909191667\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['be', 'found']\n",
      "Normalized ['be', 'found']\n",
      "perplex -0.7915129661560059\n",
      "Norm 0.7915129661560059\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ['sedimentary', 'rock']\n",
      "Normalized ['fossil', 'fossils']\n",
      "perplex -8.405275344848633\n",
      "Norm 0.8196568489074707\n",
      "normalized perplex -10.254627111396816\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['not']\n",
      "Normalized ['worldwide']\n",
      "perplex -4.417304992675781\n",
      "Norm 0.6023101806640625\n",
      "normalized perplex -7.333937121576774\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['where']\n",
      "Normalized ['where']\n",
      "perplex -1.1716604232788086\n",
      "Norm 1.1716604232788086\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Who wrote the principles of faunal succession?\n",
      "Target ['fauna', '##l', 'succession']\n",
      "Normalized ['principles', 'of', 'succession']\n",
      "perplex -4.8109893798828125\n",
      "Norm 0.9003005027770996\n",
      "normalized perplex -5.343759517008666\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['principles']\n",
      "Normalized ['fossils']\n",
      "perplex -5.020883560180664\n",
      "Norm 0.18271255493164062\n",
      "normalized perplex -27.47968557529699\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['wrote']\n",
      "Normalized ['developed']\n",
      "perplex -3.044300079345703\n",
      "Norm 1.0518131256103516\n",
      "normalized perplex -2.894335510007199\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Target ['who']\n",
      "Normalized ['who']\n",
      "perplex -0.10930728912353516\n",
      "Norm 0.10930728912353516\n",
      "normalized perplex -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "16.194401585117156 4.3052664277507775 32.91401385468727 9.965215378793467\n"
     ]
    }
   ],
   "source": [
    "contexts = random.sample(range(1203), 3)\n",
    "ans_e, unans_e = get_examples(contexts)\n",
    "ans_res, unans_res = {}, {}\n",
    "for context in contexts:\n",
    "    print(dataloader.dataset.contexts[context])\n",
    "    print(\"#\"*20)\n",
    "    print(\"Start Answerable\")\n",
    "    avg_ans_odds, max_ent_ans, r = get_avg_odds([e for e in ans_e if e[0] == context], eval_dataloader_ans)\n",
    "    ans_res.update(r)\n",
    "    print(\"Start Unanswerbale\")\n",
    "    avg_unans_odds, max_ent_unans, r = get_avg_odds([e for e in unans_e if e[0] == context], eval_dataloader_unans)\n",
    "    unans_res.update(r)\n",
    "    print(avg_ans_odds, avg_unans_odds, max_ent_ans, max_ent_unans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
