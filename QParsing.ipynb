{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Parsing\n",
    "To correctly parse questions, we can employ many techniques though none are trivial or have good coverage.  \n",
    "Instead, what we will do is write a bunch of rule and monitor the coverage and overlap on the training data.  \n",
    "We'll begin with focusing on extracting entities or key terms. We'll follow on with attributes, predicates and prepositions later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "# Load all questions \n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in nlp.Defaults.stop_words:\n",
    "    lex = nlp.vocab[word]\n",
    "    lex.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/train-v2.0.json\", 'r') as handle:\n",
    "    jdata = json.load(handle)\n",
    "    data = jdata['data']\n",
    "contexts = []\n",
    "questions = []\n",
    "unanswerable = []\n",
    "answerable = []\n",
    "for i in range(len(data)):\n",
    "    section = data[i]['paragraphs']\n",
    "    for sec in section:\n",
    "        context = sec['context']\n",
    "        contexts.append(context)\n",
    "        qas = sec['qas']\n",
    "        for j in range(len(qas)):\n",
    "            question = qas[j]['question']\n",
    "            questions.append(question)\n",
    "            label = qas[j]['is_impossible']\n",
    "            if label:\n",
    "                unanswerable.append((len(contexts)-1, len(questions)-1))\n",
    "            else:\n",
    "                answerable.append((len(contexts)-1, len(questions)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_words = ['what', 'when','where', 'who', 'how', 'why', 'which']\n",
    "def rule_nsubj(q, _):\n",
    "    q = nlp(q)\n",
    "    for chunk in q.noun_chunks:\n",
    "        if chunk.root.dep_ == 'nsubj' or chunk.root.dep_ == 'nsubjpass':\n",
    "            if chunk[0].text.lower() in q_words: \n",
    "                if len(chunk) > 1:\n",
    "                    if chunk[1].text.lower() == 'many':\n",
    "                        if len(chunk[2:]):\n",
    "                            return chunk[2:]\n",
    "                        else:\n",
    "                            return None\n",
    "                    return chunk[1:]\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return chunk\n",
    "\n",
    "def rule_ents(q, _):\n",
    "    q = nlp(q)\n",
    "    ents = list(q.ents)\n",
    "    if not ents:\n",
    "        return None\n",
    "    if len(ents) == 1:\n",
    "        return ents[0]\n",
    "    return_ents = []\n",
    "    for ent in ents:\n",
    "        if ent.root.dep_ != 'pobj':\n",
    "            return_ents.append(ent)\n",
    "    if len(ents) == 1:\n",
    "        return ents[0]\n",
    "    for ent in return_ents:\n",
    "        if ent.root.dep_ != 'nsubj' or ent.root.dep_ != 'nsubjpass':\n",
    "            return ent\n",
    "\n",
    "def overlapping_spans(q, c):\n",
    "    qt = tokenizer.tokenize(q)\n",
    "    ct = tokenizer.tokenize(c)\n",
    "    # build index\n",
    "    output_set = set()\n",
    "    context_ngram_set = set()\n",
    "    for i in range(len(ct)):\n",
    "        for j in range(10):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            context_ngram_set.add(tuple(ct[i:i+j]))\n",
    "    skip = 0\n",
    "    for i in range(len(qt)):\n",
    "        longest = None\n",
    "        if skip:\n",
    "            skip -= 1\n",
    "            continue\n",
    "        for j in range(10):\n",
    "            if j == 0 or len(qt[i:i+j]) < j:\n",
    "                continue\n",
    "            span = tuple(qt[i:i+j])\n",
    "            if span in context_ngram_set:\n",
    "                longest = span\n",
    "            if span not in context_ngram_set and longest:\n",
    "                output_set.add(longest)\n",
    "                skip = len(longest) - 1 \n",
    "                break\n",
    "    return output_set\n",
    "\n",
    "def rule_token_match(q, c):\n",
    "    spans = overlapping_spans(q,c)\n",
    "    kept_spans = []\n",
    "    for span in spans:\n",
    "        for token in span:\n",
    "            if token not in nlp.vocab or not nlp.vocab[token].is_stop:\n",
    "                kept_spans.append(span)\n",
    "                continue\n",
    "    max_span = None\n",
    "    for span in kept_spans:\n",
    "        if max_span is None:\n",
    "            max_span = span\n",
    "            continue\n",
    "        if len(span) > len(max_span):\n",
    "            max_span = span\n",
    "    return max_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(idx_tuples, rules):\n",
    "    total = len(idx_tuples)\n",
    "    coverage = 0\n",
    "    overlap = np.zeros((len(rules), len(rules)))\n",
    "    for i, (cid, qid) in enumerate(idx_tuples):\n",
    "        c = contexts[cid]\n",
    "        q = questions[qid]\n",
    "        overlapping_rules = set()\n",
    "        for rule_i, rule in enumerate(rules):\n",
    "            ent = rule(q,c)\n",
    "            if ent:\n",
    "                overlapping_rules.add(rule_i)\n",
    "        for r in overlapping_rules:\n",
    "            for rr in overlapping_rules:\n",
    "                overlap[r,rr] += 1\n",
    "        if len(overlapping_rules) > 0:\n",
    "            coverage += 1\n",
    "    print(\"Coverage: \", coverage / float(total))\n",
    "    print(\"Overlap matrix: \")\n",
    "    print(overlap)\n",
    "\n",
    "def gen_input_and_target(ent):\n",
    "    if type(ent) == tuple: # already tokenized\n",
    "        ent_tokenized = ent\n",
    "    else:\n",
    "        ent_tokenized = tokenizer.tokenize(ent.text)\n",
    "    return ent_tokenized\n",
    "\n",
    "def gen_dataset(idx_tuples, rules):\n",
    "    data = {}\n",
    "    for i, (cid, qid) in enumerate(idx_tuples):\n",
    "        c = contexts[cid]\n",
    "        q = questions[qid]\n",
    "        for rule_i, rule in enumerate(rules):\n",
    "            ent = rule(q,c)\n",
    "            if ent:\n",
    "                target = gen_input_and_target(ent)\n",
    "                if cid not in data:\n",
    "                    data[cid] = set()\n",
    "                data[cid].add(tuple(target))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage:  1.0\n",
      "Overlap matrix: \n",
      "[[ 79.  72.  79.]\n",
      " [ 72.  92.  92.]\n",
      " [ 79.  92. 100.]]\n"
     ]
    }
   ],
   "source": [
    "parse_all(answerable[:100], [rule_nsubj, rule_ents, rule_token_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = gen_dataset(answerable, [rule_nsubj, rule_ents, rule_token_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"entity_labels_v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18880"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who was the letter addressed to?\n",
      "None\n",
      "None\n",
      "('addressed', 'to')\n"
     ]
    }
   ],
   "source": [
    "cid, qid = random.sample(answerable[:500], 1)[0]\n",
    "c = contexts[cid]\n",
    "q = questions[qid]\n",
    "print(questions[qid])\n",
    "print(rule_nsubj(q,c))\n",
    "print(rule_ents(q,c))\n",
    "print(rule_token_match(q,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What NOUN\n",
      "was VERB\n",
      "Angela PROPN\n",
      "Merkel PROPN\n",
      "serving VERB\n",
      "as ADP\n",
      "in ADP\n",
      "relation NOUN\n",
      "to ADP\n",
      "the DET\n",
      "letter NOUN\n",
      "? PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(q):\n",
    "    print (token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107295\n"
     ]
    }
   ],
   "source": [
    "for i, question in enumerate(questions):\n",
    "    if \"first to invade Manchuria\" in question:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A series of international crises strained the League to its limits, the earliest being the invasion of Manchuria by Japan and the Abyssinian crisis of 1935/36 in which Italy invaded Abyssinia, one of the only free African nations at that time. The League tried to enforce economic sanctions upon Italy, but to no avail. The incident highlighted French and British weakness, exemplified by their reluctance to alienate Italy and lose her as their ally. The limited actions taken by the Western powers pushed Mussolini's Italy towards alliance with Hitler's Germany anyway. The Abyssinian war showed Hitler how weak the League was and encouraged the remilitarization of the Rhineland in flagrant disregard of the Treaty of Versailles. This was the first in a series of provocative acts culminating in the invasion of Poland in September 1939 and the beginning of the Second World War.\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[15759]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15759\n"
     ]
    }
   ],
   "source": [
    "for a,b in answerable:\n",
    "    if b == 107295:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues\n",
    "* nsubj rule:\n",
    "    * split possessives\n",
    "    * omit question words (eg. which song...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
