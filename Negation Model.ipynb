{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negation Model\n",
    "I have observed that negations are a common mechanism to create unanswerable questions. However, if we only look at negations generally, they occur at a similar rate in both answerable and unanswerable questions. However, if we look at the context, we find that if there is **no** negation in the context then the likelihood of a negation in the question is very low. Here we will encode this as a model.\n",
    "\n",
    "## Model\n",
    "We will only look at questions with negations. Training only on answerable questions.\n",
    "\n",
    "### Model 1 - Naive / binary\n",
    "P(q) = P(negation | context, question)\n",
    "This will not work because if we only train on answerable questions that have negations, the prability is 1.\n",
    "\n",
    "### Model 2 - Bayesian\n",
    "P(q) = P(DEP | context, question)P(neg | DEP, context, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretask 1:\n",
    "- What are dep tags of negations?\n",
    "- What are the parents of these tags?\n",
    "- How do we build a balanced set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "examples = []\n",
    "labels = []\n",
    "id2idx = {}\n",
    "train_questions = []\n",
    "train_contexts = []\n",
    "train_examples = []\n",
    "train_labels = []\n",
    "train_id2idx = {}\n",
    "dev_questions = []\n",
    "dev_contexts = []\n",
    "dev_examples = []\n",
    "dev_labels = []\n",
    "dev_id2idx = {}\n",
    "is_train = []\n",
    "files = [\"dataset/train-v2.0.json\",  \"dataset/dev-v2.0.json\"]\n",
    "for file in files:\n",
    "    with open(file, 'r') as handle:\n",
    "        jdata = json.load(handle)\n",
    "        data = jdata['data']\n",
    "    for i in range(len(data)):\n",
    "        section = data[i]['paragraphs']\n",
    "        for sec in section:\n",
    "            context = sec['context']\n",
    "            contexts.append(context)\n",
    "            other_context = train_contexts if file == files[0] else dev_contexts\n",
    "            other_context.append(context)\n",
    "            qas = sec['qas']\n",
    "            for j in range(len(qas)):\n",
    "                question = qas[j]['question']\n",
    "                is_imp = qas[j]['is_impossible']\n",
    "                qid = qas[j]['id']\n",
    "                questions.append(question)\n",
    "                if file == files[0]:\n",
    "                    is_train.append(True)\n",
    "                else:\n",
    "                    is_train.append(False)\n",
    "                other_questions = train_questions if file == files[0] else dev_questions\n",
    "                other_questions.append(question)\n",
    "                labels.append(is_imp)\n",
    "                other_labels = train_labels if file == files[0] else dev_labels\n",
    "                other_labels.append(is_imp)\n",
    "                examples.append((len(contexts)-1, len(questions)-1))\n",
    "                other_examples = train_examples if file == files[0] else dev_examples\n",
    "                other_examples.append((len(contexts)-1, len(questions)-1))\n",
    "                id2idx[qid] = len(questions)-1\n",
    "                other_id2idx = train_id2idx if file == files[0] else dev_id2idx\n",
    "                other_id2idx[qid] = len(questions)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_terms = [' not ',  \"n't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_neg_counter = Counter()\n",
    "q_with_neg = []\n",
    "# repr = (train, unans)\n",
    "for i, question in enumerate(questions):\n",
    "    for neg in negation_terms:\n",
    "        if neg in question:\n",
    "            question_neg_counter[(is_train[i], labels[i])] += 1\n",
    "            q_with_neg.append(i)\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(True, False): 1381,\n",
       "         (True, True): 3763,\n",
       "         (False, True): 644,\n",
       "         (False, False): 126})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_neg_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niave Classifier Train Acc: 0.7315318818040435\n",
      "Niave Classifier Train Coverage: 0.02887529830646337\n",
      "Niave Classifier Dev Acc: 0.8363636363636363\n",
      "Niave Classifier Dev Coverage: 0.05424071422555378\n"
     ]
    }
   ],
   "source": [
    "# Naive classifier of p(unans) = 1 if contains negation\n",
    "print(\"Niave Classifier Train Acc:\", question_neg_counter[(True, True)] / (question_neg_counter[(True, False)] +  question_neg_counter[(True, True)]))\n",
    "print(\"Niave Classifier Train Coverage:\", question_neg_counter[(True, True)] / np.sum(is_train))\n",
    "\n",
    "print(\"Niave Classifier Dev Acc:\", question_neg_counter[(False, True)] / (question_neg_counter[(False, False)] +  question_neg_counter[(False, True)]))\n",
    "print(\"Niave Classifier Dev Coverage:\", question_neg_counter[(False, True)] / (len(questions) - np.sum(is_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who nsubj win\n",
      "could aux win\n",
      "n't neg win\n",
      "win ROOT win\n",
      "the det presidency\n",
      "presidency dobj win\n",
      "? punct win\n"
     ]
    }
   ],
   "source": [
    "for t in nlp(\"who couldn't win the presidency?\"):\n",
    "    print(t, t.dep_, t.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_questions = []\n",
    "for i in q_with_neg:\n",
    "    q = questions[i]\n",
    "    neg_questions.append(nlp(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_counter = Counter()\n",
    "pos_counter = Counter()\n",
    "tok_counter = Counter()\n",
    "for q in neg_questions:\n",
    "    for t in q:\n",
    "        if t.dep_ == 'neg':\n",
    "            tok_counter[t.head.lemma_] += 1\n",
    "            dep_counter[t.head.dep_] += 1\n",
    "            pos_counter[t.head.pos_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ROOT', 3886),\n",
       " ('ccomp', 524),\n",
       " ('relcl', 342),\n",
       " ('advcl', 244),\n",
       " ('acl', 173),\n",
       " ('conj', 151),\n",
       " ('xcomp', 118),\n",
       " ('pcomp', 94),\n",
       " ('nsubj', 70),\n",
       " ('acomp', 65),\n",
       " ('amod', 48),\n",
       " ('auxpass', 46),\n",
       " ('prep', 33),\n",
       " ('aux', 22),\n",
       " ('csubj', 19),\n",
       " ('compound', 18),\n",
       " ('attr', 17),\n",
       " ('dep', 16),\n",
       " ('advmod', 15),\n",
       " ('oprd', 7),\n",
       " ('pobj', 7),\n",
       " ('nsubjpass', 7),\n",
       " ('nmod', 5),\n",
       " ('csubjpass', 5),\n",
       " ('appos', 4),\n",
       " ('npadvmod', 3),\n",
       " ('dobj', 3),\n",
       " ('intj', 2),\n",
       " ('cc', 1),\n",
       " ('parataxis', 1),\n",
       " ('mark', 1),\n",
       " ('det', 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VERB', 5479),\n",
       " ('NOUN', 217),\n",
       " ('ADJ', 158),\n",
       " ('ADP', 36),\n",
       " ('PROPN', 29),\n",
       " ('ADV', 24),\n",
       " ('DET', 2),\n",
       " ('CCONJ', 1),\n",
       " ('INTJ', 1),\n",
       " ('NUM', 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "What is economic liberalism not one of the causes of?\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-497b604e0b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for q in neg_questions:\n",
    "    for t in q:\n",
    "        if t.dep_ == 'neg':\n",
    "            if t.head.pos_ == 'NUM':\n",
    "                print(t.head)\n",
    "                print(q)\n",
    "                assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea, sample sentences that have the same word and pos but no neg as neg set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 1311),\n",
       " ('have', 275),\n",
       " ('use', 190),\n",
       " ('do', 95),\n",
       " ('allow', 94),\n",
       " ('consider', 72),\n",
       " ('require', 58),\n",
       " ('want', 56),\n",
       " ('make', 50),\n",
       " ('find', 50),\n",
       " ('include', 47),\n",
       " ('take', 45),\n",
       " ('know', 42),\n",
       " ('need', 35),\n",
       " ('define', 34),\n",
       " ('give', 34),\n",
       " ('believe', 34),\n",
       " ('exist', 33),\n",
       " ('locate', 32),\n",
       " ('become', 32),\n",
       " ('change', 31),\n",
       " ('support', 30),\n",
       " ('call', 29),\n",
       " ('contain', 27),\n",
       " ('help', 27),\n",
       " ('go', 26),\n",
       " ('recognize', 25),\n",
       " ('develop', 25),\n",
       " ('influence', 25),\n",
       " ('play', 25)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_counter.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling for labeling\n",
    "- Sample 1381 sentences for answerable questions w/o negations\n",
    "- have same distribution of POS heads\n",
    "- for each POS head, have same distribution of terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_with_neg = []\n",
    "for i, question in enumerate(questions):\n",
    "    for neg in negation_terms:\n",
    "        if neg in question and is_train[i] and not labels[i]:\n",
    "            train_q_with_neg.append(i)\n",
    "            break\n",
    "train_neg_questions = []\n",
    "for i in train_q_with_neg:\n",
    "    q = questions[i]\n",
    "    train_neg_questions.append(nlp(q))\n",
    "train_dep_counter = Counter()\n",
    "train_pos_counter = Counter()\n",
    "train_tok_counter = Counter()\n",
    "for q in train_neg_questions:\n",
    "    for t in q:\n",
    "        if t.dep_ == 'neg':\n",
    "            train_tok_counter[t.head.lemma_] += 1\n",
    "            train_dep_counter[t.head.dep_] += 1\n",
    "            train_pos_counter[t.head.pos_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB 0.9275887038377987\n",
      "ADJ 0.02896451846488052\n",
      "NOUN 0.02606806661839247\n",
      "ADP 0.011585807385952208\n",
      "ADV 0.0065170166545981175\n",
      "PROPN 0.004344677769732078\n",
      "DET 0.000724112961622013\n"
     ]
    }
   ],
   "source": [
    "for pos, count in train_pos_counter.most_common():\n",
    "    print(pos, count / question_neg_counter[(True, False)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be 0.18464880521361332\n",
      "have 0.06010137581462708\n",
      "use 0.03258508327299059\n",
      "allow 0.02172338884866039\n",
      "do 0.017378711078928313\n",
      "want 0.015930485155684286\n",
      "consider 0.010861694424330196\n",
      "exist 0.010861694424330196\n",
      "support 0.010137581462708182\n",
      "require 0.010137581462708182\n",
      "make 0.00941346850108617\n",
      "take 0.007965242577842143\n",
      "change 0.00724112961622013\n",
      "include 0.0065170166545981175\n",
      "find 0.0065170166545981175\n",
      "know 0.0065170166545981175\n",
      "need 0.005792903692976104\n",
      "like 0.005792903692976104\n",
      "follow 0.005792903692976104\n",
      "define 0.005792903692976104\n",
      "believe 0.005792903692976104\n",
      "recognize 0.005792903692976104\n",
      "agree 0.005068790731354091\n",
      "give 0.005068790731354091\n",
      "see 0.005068790731354091\n",
      "identify 0.005068790731354091\n",
      "become 0.005068790731354091\n",
      "go 0.004344677769732078\n",
      "intend 0.004344677769732078\n",
      "happen 0.004344677769732078\n",
      "hold 0.004344677769732078\n",
      "work 0.004344677769732078\n",
      "join 0.003620564808110065\n",
      "pay 0.003620564808110065\n",
      "get 0.003620564808110065\n",
      "part 0.003620564808110065\n",
      "in 0.003620564808110065\n",
      "understand 0.003620564808110065\n",
      "reach 0.003620564808110065\n",
      "observe 0.003620564808110065\n",
      "appear 0.003620564808110065\n",
      "affect 0.003620564808110065\n",
      "permit 0.003620564808110065\n",
      "meet 0.003620564808110065\n",
      "send 0.002896451846488052\n",
      "contain 0.002896451846488052\n",
      "live 0.002896451846488052\n",
      "receive 0.002896451846488052\n",
      "participate 0.002896451846488052\n",
      "experience 0.002896451846488052\n",
      "offer 0.002896451846488052\n",
      "rule 0.002896451846488052\n",
      "show 0.002896451846488052\n",
      "build 0.002896451846488052\n",
      "keep 0.002896451846488052\n",
      "return 0.002896451846488052\n",
      "connect 0.002896451846488052\n",
      "accept 0.002896451846488052\n",
      "apply 0.002896451846488052\n",
      "teach 0.002896451846488052\n",
      "defend 0.002896451846488052\n",
      "develop 0.002896451846488052\n",
      "report 0.002896451846488052\n",
      "establish 0.002896451846488052\n",
      "occur 0.002896451846488052\n",
      "create 0.002172338884866039\n",
      "mean 0.002172338884866039\n",
      "mention 0.002172338884866039\n",
      "implement 0.002172338884866039\n",
      "compete 0.002172338884866039\n",
      "own 0.002172338884866039\n",
      "reflect 0.002172338884866039\n",
      "release 0.002172338884866039\n",
      "care 0.002172338884866039\n",
      "open 0.002172338884866039\n",
      "reveal 0.002172338884866039\n",
      "come 0.002172338884866039\n",
      "carry 0.002172338884866039\n",
      "base 0.002172338884866039\n",
      "on 0.002172338884866039\n",
      "record 0.002172338884866039\n",
      "read 0.002172338884866039\n",
      "wear 0.002172338884866039\n",
      "play 0.002172338884866039\n",
      "provide 0.002172338884866039\n",
      "regard 0.002172338884866039\n",
      "involve 0.002172338884866039\n",
      "attend 0.002172338884866039\n",
      "grow 0.002172338884866039\n",
      "because 0.002172338884866039\n",
      "able 0.002172338884866039\n",
      "surrender 0.002172338884866039\n",
      "submit 0.002172338884866039\n",
      "associate 0.002172338884866039\n",
      "prepare 0.002172338884866039\n",
      "kill 0.002172338884866039\n",
      "enact 0.002172338884866039\n",
      "lead 0.002172338884866039\n",
      "produce 0.002172338884866039\n",
      "sign 0.002172338884866039\n",
      "Sum 0.6806661839246897\n"
     ]
    }
   ],
   "source": [
    "sm = 0\n",
    "for x, c in train_tok_counter.most_common(100):\n",
    "    print(x, c/question_neg_counter[(True, False)])\n",
    "    sm += c/question_neg_counter[(True, False)]\n",
    "print(\"Sum\", sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VERB', 5479),\n",
       " ('NOUN', 217),\n",
       " ('ADJ', 158),\n",
       " ('ADP', 36),\n",
       " ('PROPN', 29),\n",
       " ('ADV', 24),\n",
       " ('DET', 2),\n",
       " ('CCONJ', 1),\n",
       " ('INTJ', 1),\n",
       " ('NUM', 1)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3763"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_neg_counter[(True, True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0.09503239740820735\n",
      "finished 0.1951043916486681\n",
      "finished 0.29517638588912887\n",
      "finished 0.3952483801295896\n",
      "finished 0.4953203743700504\n",
      "finished 0.5953923686105111\n",
      "finished 0.6954643628509719\n",
      "finished 0.7955363570914327\n",
      "finished 0.8956083513318934\n",
      "Left 47\n",
      "Left 46\n",
      "Left 45\n",
      "Left 44\n",
      "Left 43\n",
      "Left 42\n",
      "Left 41\n",
      "Left 40\n",
      "Left 39\n",
      "Left 38\n",
      "Left 37\n",
      "Left 36\n",
      "Left 35\n",
      "Left 34\n",
      "Left 33\n",
      "Left 32\n",
      "Left 31\n",
      "Left 30\n",
      "Left 29\n",
      "Left 28\n",
      "Left 27\n",
      "Left 26\n",
      "Left 25\n",
      "Left 24\n",
      "Left 23\n",
      "Left 22\n",
      "Left 21\n",
      "Left 20\n",
      "Left 19\n",
      "Left 18\n",
      "Left 17\n",
      "Left 16\n",
      "Left 15\n",
      "Left 14\n",
      "Left 13\n",
      "Left 12\n",
      "Left 11\n",
      "Left 10\n",
      "Left 9\n",
      "Left 8\n",
      "Left 7\n",
      "Left 6\n",
      "Left 5\n",
      "Left 4\n",
      "Left 3\n",
      "Left 2\n",
      "Left 1\n",
      "Left 0\n"
     ]
    }
   ],
   "source": [
    "ignore_terms = ['what', 'in', 'who', 'as', 'of', 'record', 'do', 'many']\n",
    "# build training data:\n",
    "q_with_neg_set = set(q_with_neg)\n",
    "key_words = set(train_tok_counter.keys())\n",
    "progress_counter = Counter()\n",
    "pos_examples = []\n",
    "q_without_neg = set()\n",
    "q_without_neg_list = []\n",
    "q_without_neg_heads = []\n",
    "prev_prog = 0\n",
    "for i, q in enumerate(questions):\n",
    "    if not is_train[i] or i in q_with_neg_set or  labels[i] == True:\n",
    "        continue\n",
    "    parsed_q = nlp(q)\n",
    "    for t in parsed_q:\n",
    "        if t.lemma_ in key_words:\n",
    "            progress_counter[t.lemma_] += 1\n",
    "            if progress_counter[t.lemma_] >= train_tok_counter[t.lemma_]:\n",
    "                key_words.remove(t.lemma_)\n",
    "            pos_examples.append((q, parsed_q))\n",
    "            q_without_neg.add(i)\n",
    "            q_without_neg_list.append(i)\n",
    "            q_without_neg_heads.append(t.text)\n",
    "            break\n",
    "    pct_done = sum(progress_counter.values()) / sum(train_tok_counter.values()) \n",
    "    rounded_pct_done = round( pct_done * 100 ) \n",
    "    if pct_done > .96:\n",
    "        break\n",
    "    if rounded_pct_done % 10 == 0 and rounded_pct_done != prev_prog:\n",
    "        print(\"finished\", pct_done)\n",
    "        prev_prog = rounded_pct_done\n",
    "i == 0\n",
    "old_left = 99999\n",
    "while len(pos_examples) < question_neg_counter[(True, False)]:\n",
    "    q = questions[i]\n",
    "    if i in q_with_neg_set or  i in q_without_neg or labels[i] == True:\n",
    "        i += 1\n",
    "        continue\n",
    "    parsed_q = nlp(q)\n",
    "    for t in parsed_q:\n",
    "        if t.lemma_ in train_tok_counter.keys():\n",
    "            if t.lemma_ in ignore_terms:\n",
    "                continue\n",
    "            pos_examples.append((q, parsed_q))\n",
    "            progress_counter[t.lemma_] += 1\n",
    "            q_without_neg.add(i)\n",
    "            q_without_neg_list.append(i)\n",
    "            q_without_neg_heads.append(t.text)\n",
    "            break\n",
    "    i += 1\n",
    "    left = question_neg_counter[(True, False)]- len(pos_examples)\n",
    "    if left != old_left:\n",
    "        print(\"Left\", left)\n",
    "        old_left = left\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1381"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1381"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_neg_counter[(True, False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_done > .96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data\n",
    "- training set\n",
    "    - train questions w/ and w/o negation - all answerable\n",
    "    - for each question w/ negation, remove it\n",
    "    - find head words in non-negation questions\n",
    "    - (c, q-negation, head_word, label)\n",
    "\n",
    "- test set\n",
    "    - dev questions with negation and labels\n",
    "    - for each question, find the head word and remove the negation\n",
    "    - (c, q-negation, head_word, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "import random \n",
    "\n",
    "replace_map = {'ca': 'can', 'wo':'will'}\n",
    "\n",
    "def remove_negation(sent):\n",
    "    #parsed = nlp(sent)\n",
    "    neg_term = None\n",
    "    for t in sent:\n",
    "        if t.dep_ == 'neg':\n",
    "            neg_term = t\n",
    "    if sent[neg_term.i-1].text in ['ca', 'wo']:\n",
    "        new_doc = sent.text[:neg_term.idx-2] + replace_map[sent[neg_term.i-1].text] + sent.text[neg_term.idx+len(neg_term.text):]\n",
    "    else:\n",
    "        new_doc = sent.text[:neg_term.idx] + sent.text[neg_term.idx+len(neg_term.text):]\n",
    "    new_doc = new_doc.replace(\"  \", \" \")\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: Who won't command the reserves?\n",
      "AFTER:  Who will command the reserves?\n"
     ]
    }
   ],
   "source": [
    "for q in random.sample(neg_questions, 1000):\n",
    "    if \" won't \" not in q.text:\n",
    "        continue\n",
    "    print(\"BEFORE:\", q)\n",
    "    print(\"AFTER: \", remove_negation(q))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: You might want to convert \"did not do\" to \"does\" since it's more grammatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for ii, i in enumerate(q_without_neg_list[:1374]):\n",
    "    head_word = q_without_neg_heads[ii]\n",
    "    ci, _ = examples[i]\n",
    "    context = contexts[ci]\n",
    "    question = questions[i]\n",
    "    label = False\n",
    "    training_data.append((context, question, head_word, label))\n",
    "    \n",
    "for ci, qi in examples:\n",
    "    if not is_train[qi] or labels[qi]:\n",
    "        continue\n",
    "    context = contexts[ci]\n",
    "    question = questions[qi]\n",
    "    found = False\n",
    "    for neg in negation_terms:\n",
    "        if neg in question:\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        label = True\n",
    "        head_word = None\n",
    "        parsed_q = nlp(question)\n",
    "        for t in parsed_q:\n",
    "            if t.dep_ == 'neg':\n",
    "                head_word = t.head.text\n",
    "                break\n",
    "        if not head_word:\n",
    "            continue\n",
    "        #assert headword is not None, parsed_q.text + \"||\" + \" \".join([t.dep_ for t in parsed_q])\n",
    "        modified_q = remove_negation(parsed_q)\n",
    "        training_data.append((context, modified_q, head_word, label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for ci, qi in examples:\n",
    "    if is_train[qi]:\n",
    "        continue\n",
    "    context = contexts[ci]\n",
    "    question = questions[qi]\n",
    "    found = False\n",
    "    for neg in negation_terms:\n",
    "        if neg in question:\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        label = labels[qi]\n",
    "        head_word = None\n",
    "        parsed_q = nlp(question)\n",
    "        for t in parsed_q:\n",
    "            if t.dep_ == 'neg':\n",
    "                head_word = t.head.text\n",
    "                break\n",
    "        if not head_word:\n",
    "            continue\n",
    "        #assert headword is not None, parsed_q.text + \"||\" + \" \".join([t.dep_ for t in parsed_q])\n",
    "        if \"who did the mongols\" in parsed_q.text.lower():\n",
    "            print(\"WTF\")\n",
    "        modified_q = remove_negation(parsed_q)\n",
    "        if \"who did the mongols\" in modified_q.lower():\n",
    "            print(\"WTF\")\n",
    "        #print(modified_q)\n",
    "        test_data.append((context, modified_q, head_word, label))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just for testing and finding words to skip\n",
    "# for i in range(len(questions)):\n",
    "#     q = questions[i]\n",
    "#     if i in q_with_neg_set or  i in q_without_neg or labels[i] == True:\n",
    "#         continue\n",
    "#     parsed_q = nlp(q)\n",
    "#     for t in parsed_q:\n",
    "#         if t.lemma_ in train_tok_counter.keys() and t.pos_ == 'VERB':\n",
    "#             if t.lemma_ in ['what', 'in', 'who', 'as', 'of', 'record', 'do', 'many']:\n",
    "#                 continue\n",
    "#             print(i)\n",
    "#             print(t.lemma_)\n",
    "#             print(q)\n",
    "#             break\n",
    "#     if i > 200:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"negation_training_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(training_data, f)\n",
    "with open(\"negation_test_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(test_data, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'When did Beyonce start becoming popular?',\n",
       " 'did',\n",
       " False)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[138282]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who dobj\n",
      "did aux\n",
      "the det\n",
      "Mongols nsubj\n",
      "send ROOT\n",
      "to prep\n",
      "Bukhara pobj\n",
      "as prep\n",
      "administrators pobj\n",
      "? punct\n"
     ]
    }
   ],
   "source": [
    "for t in nlp(questions[138282]):\n",
    "    print(t, t.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for neg in negation_terms:\n",
    "    print(neg in questions[138282])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF  Who did the Mongols send to Bukhara as administrators?\n"
     ]
    }
   ],
   "source": [
    "for t in test_data:\n",
    "    if \"who did the mongols\" in t[1].lower():\n",
    "        print(\"WTF\", t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does have a metric counterpart?'"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci, qi in examples:\n",
    "    if is_train[qi]:\n",
    "        continue\n",
    "    context = contexts[ci]\n",
    "    question = questions[qi]\n",
    "    found = False\n",
    "    for neg in negation_terms:\n",
    "        if neg in question:\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        if qi == 138282:\n",
    "            print(\"WTF\")\n",
    "        if \"who did the mongols\" in question.lower():\n",
    "            print(\"WTF\")\n",
    "        head_word = None\n",
    "        parsed_q = nlp(question)\n",
    "        for t in parsed_q:\n",
    "            if t.dep_ == 'neg':\n",
    "                head_word = t.head.text\n",
    "                break\n",
    "        if not head_word:\n",
    "            continue\n",
    "        modified_q = remove_negation(parsed_q)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141607 When did British begin to build fort under William Trent?\n",
      "141611 When didn't British begin to build fort under William Trent?\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(questions):\n",
    "    if \"william trent\" in q.lower():\n",
    "        print(i,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
