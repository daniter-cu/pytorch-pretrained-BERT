{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../ner/BERT-NER/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import Ner\n",
    "\n",
    "model = Ner(\"../ner/BERT-NER/out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(\"When did the House of Burgundy revolt against Philip II?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'When': {'tag': 'O', 'confidence': 0.9998822212219238},\n",
       " 'did': {'tag': 'O', 'confidence': 0.999711811542511},\n",
       " 'the': {'tag': 'O', 'confidence': 0.9998853206634521},\n",
       " 'House': {'tag': 'B-ORG', 'confidence': 0.9997528195381165},\n",
       " 'of': {'tag': 'I-ORG', 'confidence': 0.9949380159378052},\n",
       " 'Burgundy': {'tag': 'I-ORG', 'confidence': 0.9900270104408264},\n",
       " 'revolt': {'tag': 'O', 'confidence': 0.9858018755912781},\n",
       " 'against': {'tag': 'O', 'confidence': 0.9998939037322998},\n",
       " 'Philip': {'tag': 'B-PER', 'confidence': 0.9998753070831299},\n",
       " 'II': {'tag': 'O', 'confidence': 0.9446985721588135},\n",
       " '?': {'tag': 'O', 'confidence': 0.36162233352661133}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ents(sent):\n",
    "    output =  model.predict(sent)\n",
    "    ents = []\n",
    "    ent = None\n",
    "    for k, v in output.items():\n",
    "        assert k is not None, k\n",
    "        if v['tag'] == 'O' and ent is not None:\n",
    "            ents.append(ent.lower())\n",
    "            ent = None\n",
    "        if v['tag'].startswith('B'):\n",
    "            if ent is not None:\n",
    "                ents.append(ent.lower())\n",
    "            ent = k\n",
    "        if v['tag'].startswith('I'):\n",
    "            if ent is None:\n",
    "                ent = k\n",
    "            elif k.startswith(\"'\"):\n",
    "                ent += k\n",
    "            else:\n",
    "                ent += ' ' + k\n",
    "    return ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ents(\"When did the House of Burgundy revolt against Philip II?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "examples = []\n",
    "labels = []\n",
    "id2idx = {}\n",
    "files = [\"dataset/train-v2.0.json\",  \"dataset/dev-v2.0.json\"]\n",
    "for file in files:\n",
    "    with open(file, 'r') as handle:\n",
    "        jdata = json.load(handle)\n",
    "        data = jdata['data']\n",
    "    for i in range(len(data)):\n",
    "        section = data[i]['paragraphs']\n",
    "        for sec in section:\n",
    "            context = sec['context']\n",
    "            contexts.append(context)\n",
    "            qas = sec['qas']\n",
    "            for j in range(len(qas)):\n",
    "                question = qas[j]['question']\n",
    "                is_imp = qas[j]['is_impossible']\n",
    "                qid = qas[j]['id']\n",
    "                questions.append(question)\n",
    "                labels.append(is_imp)\n",
    "                examples.append((len(contexts)-1, len(questions)-1))\n",
    "                id2idx[qid] = len(questions)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_examples_ans = []\n",
    "sampled_examples_unans = []\n",
    "for e in random.sample(examples, len(examples)):\n",
    "    if labels[e[1]] == True and len(sampled_examples_unans) < 50:\n",
    "        sampled_examples_unans.append(e)\n",
    "    elif labels[e[1]] == False and len(sampled_examples_ans) < 50:\n",
    "        sampled_examples_ans.append(e)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ents(sent):\n",
    "    output =  model.predict(sent)\n",
    "    ents = {}\n",
    "    ent = None\n",
    "    for k, v in output.items():\n",
    "        assert k is not None, k\n",
    "        if v['tag'] != 'O':\n",
    "            ents[k.lower()] = v['tag']\n",
    "    return ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNANS {'america': 'B-LOC', 'canadian': 'B-MISC', 'americam': 'B-MISC'}\n",
      "{'canada': 'B-LOC', 'canadian': 'B-MISC', 'american': 'B-MISC'}\n",
      "In America what term is used for both Canadian foobal and Americam football\n",
      "In Canada, the term \"football\" may refer to Canadian football and American football collectively, or to either sport specifically, depending on context. The two sports have shared origins and are closely related but have significant differences. In particular, Canadian football has 12 players on the field per team rather than 11; the field is roughly 10 yards wider, and 10 yards longer between end-zones that are themselves 10 yards deeper; and a team has only three downs to gain 10 yards, which results in less offensive rushing than in the American game. In the Canadian game all players on the defending team, when a down begins, must be at least 1 yard from the line of scrimmage. (The American game has a similar \"neutral zone\" but it is only the length of the football.)\n",
      "####################\n",
      "UNANS {'america': 'B-LOC', 'canadian': 'B-MISC', 'americam': 'B-MISC'}\n",
      "{'canada': 'B-LOC', 'canadian': 'B-MISC', 'american': 'B-MISC'}\n",
      "In America what term is used for both Canadian foobal and Americam football\n",
      "In Canada, the term \"football\" may refer to Canadian football and American football collectively, or to either sport specifically, depending on context. The two sports have shared origins and are closely related but have significant differences. In particular, Canadian football has 12 players on the field per team rather than 11; the field is roughly 10 yards wider, and 10 yards longer between end-zones that are themselves 10 yards deeper; and a team has only three downs to gain 10 yards, which results in less offensive rushing than in the American game. In the Canadian game all players on the defending team, when a down begins, must be at least 1 yard from the line of scrimmage. (The American game has a similar \"neutral zone\" but it is only the length of the football.)\n",
      "####################\n",
      "UNANS {'imperial': 'B-ORG', 'st': 'B-LOC', 'maries': 'I-LOC'}\n",
      "{'imperial': 'B-ORG', 'st': 'B-LOC', 'mary': 'I-LOC', 'hospital': 'I-LOC', 'medical': 'I-ORG', 'school': 'I-ORG', 'the': 'B-ORG', 'college': 'B-ORG', 'science': 'I-ORG', 'technology': 'I-ORG', 'medicine': 'I-ORG', 'press': 'I-ORG', 'world': 'B-ORG', 'scientific': 'I-ORG', 'national': 'B-ORG', 'heart': 'I-ORG', 'lung': 'I-ORG', 'institute': 'I-ORG', 'charing': 'B-LOC', 'cross': 'I-LOC', 'westminster': 'B-LOC', 'royal': 'B-ORG', 'postgraduate': 'I-ORG', 'rpms': 'B-ORG', 'obstetrics': 'I-ORG', 'gynaecology': 'I-ORG', 'act': 'I-MISC', 'alexander': 'B-PER', 'fleming': 'I-LOC', 'building': 'I-LOC', 'elizabeth': 'B-PER'}\n",
      "What scool split into Imperial and and St Maries?\n",
      "In 1988 Imperial merged with St Mary's Hospital Medical School, becoming The Imperial College of Science, Technology and Medicine. In 1995 Imperial launched its own academic publishing house, Imperial College Press, in partnership with World Scientific. Imperial merged with the National Heart and Lung Institute in 1995 and the Charing Cross and Westminster Medical School, Royal Postgraduate Medical School (RPMS) and the Institute of Obstetrics and Gynaecology in 1997. In the same year the Imperial College School of Medicine was formally established and all of the property of Charing Cross and Westminster Medical School, the National Heart and Lung Institute and the Royal Postgraduate Medical School were transferred to Imperial as the result of the Imperial College Act 1997. In 1998 the Sir Alexander Fleming Building was opened by Queen Elizabeth II to provide a headquarters for the College's medical and biomedical research.\n",
      "####################\n",
      "UNANS {'dtd': 'B-ORG'}\n",
      "{'united': 'B-LOC', 'kingdom': 'I-LOC', 'european': 'B-MISC', 'dvb-t2': 'B-MISC', 'digital': 'B-ORG', 'tv': 'I-ORG', 'group': 'I-ORG', 'dtg': 'B-ORG'}\n",
      " What does DTD stand for?\n",
      "In December 2009 the United Kingdom became the first European country to deploy high definition content using the new DVB-T2 transmission standard, as specified in the Digital TV Group (DTG) D-book, on digital terrestrial television.\n",
      "####################\n",
      "UNANS {'paris': 'B-LOC', 'english': 'B-MISC'}\n",
      "{'louis': 'B-PER', 'xiv': 'I-PER', 'paris': 'B-LOC', 'europe': 'B-LOC', 'parlement': 'B-ORG'}\n",
      "What was the title of the bottom of Paris's police, in English?\n",
      "The first centrally organised police force was created by the government of King Louis XIV in 1667 to police the city of Paris, then the largest city in Europe. The royal edict, registered by the Parlement of Paris on March 15, 1667 created the office of lieutenant général de police (\"lieutenant general of police\"), who was to be the head of the new Paris police force, and defined the task of the police as \"ensuring the peace and quiet of the public and of private individuals, purging the city of what may cause disturbances, procuring abundance, and having each and everyone live according to their station and their duties\".\n",
      "####################\n",
      "UNANS {'wilshire': 'B-LOC', 'blvd': 'I-LOC', '.': 'X', '?': 'X'}\n",
      "{'downtown': 'B-LOC', 'district': 'I-LOC', 'third': 'B-LOC', 'street': 'I-LOC', 'wilshire': 'B-LOC', 'blvd': 'I-LOC', 'broadway': 'B-LOC', 'los': 'B-LOC', 'angeles': 'I-LOC', 'santa': 'B-LOC', 'monica': 'I-LOC', 'place': 'I-LOC', 'bloomingdale': 'B-ORG', \"'s\": 'I-LOC', 'nordstrom': 'B-ORG'}\n",
      "How long is Wilshire Blvd.?\n",
      "The Downtown District is the home of the Third Street Promenade, a major outdoor pedestrian-only shopping district that stretches for three blocks between Wilshire Blvd. and Broadway (not the same Broadway in downtown and south Los Angeles). Third Street is closed to vehicles for those three blocks to allow people to stroll, congregate, shop and enjoy street performers. Santa Monica Place, featuring Bloomingdale's and Nordstrom in a three-level outdoor environment, is located at the south end of the Promenade. After a period of redevelopment, the mall reopened in the fall of 2010 as a modern shopping, entertainment and dining complex with more outdoor space.\n",
      "####################\n",
      "UNANS {'wilshire': 'B-LOC', 'blvd': 'I-LOC', '.': 'X', '?': 'X'}\n",
      "{'downtown': 'B-LOC', 'district': 'I-LOC', 'third': 'B-LOC', 'street': 'I-LOC', 'wilshire': 'B-LOC', 'blvd': 'I-LOC', 'broadway': 'B-LOC', 'los': 'B-LOC', 'angeles': 'I-LOC', 'santa': 'B-LOC', 'monica': 'I-LOC', 'place': 'I-LOC', 'bloomingdale': 'B-ORG', \"'s\": 'I-LOC', 'nordstrom': 'B-ORG'}\n",
      "How long is Wilshire Blvd.?\n",
      "The Downtown District is the home of the Third Street Promenade, a major outdoor pedestrian-only shopping district that stretches for three blocks between Wilshire Blvd. and Broadway (not the same Broadway in downtown and south Los Angeles). Third Street is closed to vehicles for those three blocks to allow people to stroll, congregate, shop and enjoy street performers. Santa Monica Place, featuring Bloomingdale's and Nordstrom in a three-level outdoor environment, is located at the south end of the Promenade. After a period of redevelopment, the mall reopened in the fall of 2010 as a modern shopping, entertainment and dining complex with more outdoor space.\n",
      "####################\n",
      "UNANS {'finnish': 'B-MISC'}\n",
      "{'finland': 'B-LOC'}\n",
      "What age ranges does Finnish uncomprehensive school cover?\n",
      "Finland has used comprehensive schools since the 1970s, in the sense that everyone is expected to complete the nine grades of peruskoulu, from the age 7 to 16. The division to lower comprehensive school (grades 1–6, ala-aste, alakoulu) and upper comprehensive school (grades 7–9, yläaste, yläkoulu) has been discontinued.\n",
      "####################\n",
      "UNANS {'north': 'B-LOC', 'carolina': 'I-LOC'}\n",
      "{'william': 'B-PER', 'enston': 'I-LOC', 'home': 'I-LOC', 'and': 'I-ORG', 'united': 'B-ORG', 'states': 'I-ORG', 'post': 'I-ORG', 'office': 'I-ORG', 'courthouse': 'I-ORG', 'democrat-dominated': 'B-MISC'}\n",
      "Which party dominated North Carolina's state legislature?\n",
      "Investment in the city continued. The William Enston Home, a planned community for the city's aged and infirm, was built in 1889. An elaborate public building, the United States Post Office and Courthouse, was completed by the federal government in 1896 in the heart of the city. The Democrat-dominated state legislature passed a new constitution in 1895 that disfranchised blacks, effectively excluding them entirely from the political process, a second-class status that was maintained for more than six decades in a state that was majority black until about 1930.\n",
      "####################\n",
      "UNANS {'north': 'B-LOC', 'carolina': 'I-LOC'}\n",
      "{'william': 'B-PER', 'enston': 'I-LOC', 'home': 'I-LOC', 'and': 'I-ORG', 'united': 'B-ORG', 'states': 'I-ORG', 'post': 'I-ORG', 'office': 'I-ORG', 'courthouse': 'I-ORG', 'democrat-dominated': 'B-MISC'}\n",
      "Which party dominated North Carolina's state legislature?\n",
      "Investment in the city continued. The William Enston Home, a planned community for the city's aged and infirm, was built in 1889. An elaborate public building, the United States Post Office and Courthouse, was completed by the federal government in 1896 in the heart of the city. The Democrat-dominated state legislature passed a new constitution in 1895 that disfranchised blacks, effectively excluding them entirely from the political process, a second-class status that was maintained for more than six decades in a state that was majority black until about 1930.\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNANS {'arsenal': 'B-ORG'}\n",
      "{'the': 'B-ORG', 'art': 'B-MISC', 'deco-style': 'I-MISC', 'herbert': 'B-PER', 'chapman': 'I-PER', 'cup': 'B-MISC', 'final': 'I-MISC', 'highbury': 'B-LOC', 'stadium': 'I-LOC', 'gunners': 'I-ORG'}\n",
      "What was worn on Arsenal shirts prior to 1967?\n",
      "The monogram theme was developed into an Art Deco-style badge on which the letters A and C framed a football rather than the letter F, the whole set within a hexagonal border. This early example of a corporate logo, introduced as part of Herbert Chapman's rebranding of the club in the 1930s, was used not only on Cup Final shirts but as a design feature throughout Highbury Stadium, including above the main entrance and inlaid in the floors. From 1967, a white cannon was regularly worn on the shirts, until replaced by the club crest, sometimes with the addition of the nickname \"The Gunners\", in the 1990s.\n",
      "####################\n",
      "0 11\n"
     ]
    }
   ],
   "source": [
    "ent_not_mentioned_ans = 0\n",
    "ent_not_mentioned_unans = 0\n",
    "\n",
    "# for ci, qi in sampled_examples_ans:\n",
    "#     q = questions[qi]\n",
    "#     c = contexts[ci]\n",
    "#     cents = get_ents(c)\n",
    "#     ents = get_ents(q)\n",
    "#     for ent in ents.keys():\n",
    "#         if ent not in cents.keys():\n",
    "#             ent_not_mentioned_ans += 1\n",
    "#             print(\"ANS\", ents)\n",
    "#             print(cents)\n",
    "#             print(q)\n",
    "#             print(c)\n",
    "#             print(\"#\"*20)\n",
    "    \n",
    "\n",
    "for ci, qi in sampled_examples_unans:\n",
    "    q = questions[qi]\n",
    "    c = contexts[ci]\n",
    "    ents = get_ents(q)\n",
    "    cents = get_ents(c)\n",
    "    for ent in ents.keys():\n",
    "        if ent not in cents.keys():\n",
    "            ent_not_mentioned_unans += 1\n",
    "            print(\"UNANS\", ents)\n",
    "            print(cents)\n",
    "            print(q)\n",
    "            print(c)\n",
    "            print(\"#\"*20)\n",
    "\n",
    "print(ent_not_mentioned_ans, ent_not_mentioned_unans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_targets = {}\n",
    "for i in range(24):\n",
    "    with open(\"qparts/copy_parts2/parsed_qs_labels%s.pkl\"%str(i), \"rb\") as handle:\n",
    "        raw_targets.update(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "import spacy\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_in_y_int(query, base):\n",
    "    try:\n",
    "        l = len(query)\n",
    "    except TypeError:\n",
    "        l = 1\n",
    "        query = type(base)((query,))\n",
    "\n",
    "    for i in range(len(base)):\n",
    "        if base[i:i + l] == query:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def mask_question(tokens_b, target_span):\n",
    "    if not len(target_span):\n",
    "        return tokens_b\n",
    "    if len(target_span) > 1:\n",
    "        if target_span[0] in ['ca', 'can', 'is', 'was', 'do', 'does', 'were', 'are', 'have', 'did',\n",
    "                             'would', 'should', 'could'] and target_span[1] == 'n':\n",
    "            new_tok = target_span[0]+target_span[1]\n",
    "            del target_span[0]\n",
    "            del target_span[0]\n",
    "            target_span.insert(0, new_tok)\n",
    "        elif target_span[0] == 'can' and target_span[1] == 'not' and 'cannot' in tokens_b:\n",
    "            del target_span[0]\n",
    "            del target_span[0]\n",
    "            target_span.insert(0, 'cannot')\n",
    "        elif target_span[0] == 'n' and target_span[1] == \"'\":\n",
    "            del target_span[0]\n",
    "#         elif target_span[0].startswith(\"'\") and len(target_span[0]) == 2:\n",
    "#             print(\"NOT SURE IF HTIS IS WRITE\")\n",
    "#             del target_span[0]\n",
    "    span_start = x_in_y_int(target_span, tokens_b)\n",
    "    if span_start >= 0:\n",
    "        for i in range(span_start, span_start+len(target_span)):\n",
    "            del tokens_b[span_start]\n",
    "        tokens_b.insert(span_start, '[MASK]')\n",
    "    else:\n",
    "        # find first tok\n",
    "        while len(target_span) > 0 and target_span[0] not in tokens_b:\n",
    "            target_span = target_span[1:]\n",
    "        if len(target_span) == 0:\n",
    "            print(\"This sux\")\n",
    "            return tokens_b\n",
    "        first_tok = tokens_b.index(target_span[0])\n",
    "        for tok in tokens_b:\n",
    "            if tok in target_span:\n",
    "                tokens_b.remove(tok)\n",
    "        tokens_b.insert(first_tok, '[MASK]')\n",
    "    return tokens_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sux\n",
      "This sux\n",
      "This sux\n",
      "This sux\n",
      "This sux\n",
      "This sux\n",
      "This sux\n",
      "This sux\n"
     ]
    }
   ],
   "source": [
    "for i in random.sample(raw_targets.keys(), 100000 ):\n",
    "    targs = [word for word, _ in raw_targets[i]]\n",
    "    idx = id2idx[i]\n",
    "    question = questions[idx]\n",
    "    if not targs:\n",
    "        continue\n",
    "    targ = random.sample(targs, 1)[0]\n",
    "    x = mask_question(tokenizer.tokenize(question), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Torah im Derech Eretz insisted that Jews should attempt to engage and influence what?\n",
      "['m']\n",
      "['the', 'torah', 'im', 'der', '##ech', 'er', '##etz', 'insisted', 'that', 'jews', 'should', 'attempt', 'to', 'engage', 'and', 'influence', 'what', '?']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c1f6e8e850c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-cfd3b0db58a4>\u001b[0m in \u001b[0;36mmask_question\u001b[0;34m(tokens_b, target_span)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# find first tok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mtarget_span\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtarget_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_span\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mfirst_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_span\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "print(question)\n",
    "print(targ)\n",
    "print(tokenizer.tokenize(question))\n",
    "print(mask_question(tokenizer.tokenize(question), targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'2774'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binascii.hexlify(bytearray(targ[0],'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ[0] == \"'t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'2774'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binascii.hexlify(bytearray(\"'t\",'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "for targ in raw_targets.keys():\n",
    "    if targ[0]==\"'t\":\n",
    "        print(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
