{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "examples = []\n",
    "labels = []\n",
    "id2idx = {}\n",
    "files = [\"dataset/train-v2.0.json\",  \"dataset/dev-v2.0.json\"]\n",
    "for file in files:\n",
    "    with open(file, 'r') as handle:\n",
    "        jdata = json.load(handle)\n",
    "        data = jdata['data']\n",
    "    for i in range(len(data)):\n",
    "        section = data[i]['paragraphs']\n",
    "        for sec in section:\n",
    "            context = sec['context']\n",
    "            contexts.append(context)\n",
    "            qas = sec['qas']\n",
    "            for j in range(len(qas)):\n",
    "                question = qas[j]['question']\n",
    "                is_imp = qas[j]['is_impossible']\n",
    "                qid = qas[j]['id']\n",
    "                questions.append(question)\n",
    "                labels.append(is_imp)\n",
    "                examples.append((len(contexts)-1, len(questions)-1))\n",
    "                id2idx[qid] = len(questions)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmp = \"qparts/copy_parts2/parsed_qs_labels%s.pkl\"\n",
    "parses = {}\n",
    "for i in range(24):\n",
    "    fname = ftmp % str(i)\n",
    "    with open(fname, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        parses.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_terms = [' not ', \"don't\", \"couldn't\", \"wouldn't\", \"wasn't\", \"isn't\", \"doesn't\", \"aren't\", \"didn't\", \"n't\"]\n",
    "negation_terms = [' not ',  \"n't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_counter = Counter()\n",
    "for i, q in enumerate(questions):\n",
    "    for t in negation_terms:\n",
    "        if t in q:\n",
    "            neg_counter['total'] += 1\n",
    "            neg_counter[t] += 1\n",
    "            if labels[i] == False:\n",
    "                neg_counter['ans'] += 1\n",
    "            else:\n",
    "                neg_counter['unans'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142192\n",
      "Total negs: 5925\n",
      "Total negs in Ans 1509\n",
      "Total negs in Unans 4416\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))\n",
    "print(\"Total negs:\", neg_counter['total'])\n",
    "print(\"Total negs in Ans\", neg_counter['ans'])\n",
    "print(\"Total negs in Unans\", neg_counter['unans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'total': 5925,\n",
       "         ' not ': 4002,\n",
       "         'ans': 1509,\n",
       "         \"n't\": 1923,\n",
       "         'unans': 4416})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_neg = []\n",
    "for i, q in enumerate(questions):\n",
    "    found = False\n",
    "    for t in negation_terms:\n",
    "        if t in q and labels[i] == False:\n",
    "            ans_neg.append(q)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In The Sing-Off, where did the groups not from the United States come from?\n",
      "Was there a time this was not the case? \n",
      "Who questioned the claim that South Korean did not provoke the KPA?\n",
      "Peter J. Wallison's conclusions regarding the financial crisis are not in agreement with this economist's views?\n",
      "During what year was Barcelona not allowed to use  their transfer windows?\n",
      "A contract can be given to someone who is not the best what?\n",
      "What is not an established science?\n",
      "Who was one person who did not fully believe the struggle of conscience?\n",
      "The Air Ministry and which other group decided to not make night defense a top priority?\n",
      "Are adolescents or children better able to understand that people do not have complete control over their thoughts?\n",
      "Richard Lewontin, upon looking at the FST ratios, concluded race wasn't an appropriate or useful way to describe what?\n",
      "Who declared that France would not yield \"an inch of its territory?\"\n",
      "How are the votes weighted to ensure that smaller states aren't dominated by larger ones?\n",
      "A component might not be able to be made any smaller because of its mechanical limitations or what other need?\n",
      "Why isn't the southwest Spanish speaking?\n",
      "In which publication does Hawking say that any events that existed before the Big Bang would not be accessible to us?\n",
      "What was the name of the single unit that didn't surrender?\n",
      "What are other terms that do not make similar assignments?\n",
      "What squadron is present but not an official part of the Brigade?\n",
      "Which city notably opted not to become carbon neutral in 2009?\n",
      "Germany doesn't have an imperialistic past until when?\n",
      "Who is the archaeologist that does not believe early humans were hunters?\n",
      "Which three major companies do not consider Guam as domestic when shipping is involved?\n",
      "By not going back to Poland Chopin became part of what?\n",
      "What was the fault not considered in the early theories of day length?\n"
     ]
    }
   ],
   "source": [
    "for q in random.sample(ans_neg, 25):\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for i, q in enumerate(questions):\n",
    "    context = contexts[examples[i][0]]\n",
    "    found_in_q = False\n",
    "    found_in_c = False\n",
    "    for t in negation_terms:\n",
    "        if t in q:\n",
    "            found_in_q = True\n",
    "    for t in negation_terms:\n",
    "        if t in context:\n",
    "            found_in_c = True\n",
    "    if found_in_q:\n",
    "        if labels[i] == False:\n",
    "            counter[('ANS', found_in_c)] += 1\n",
    "        else:\n",
    "            counter[('UNANS', found_in_c)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('ANS', True): 1047,\n",
       "         ('ANS', False): 460,\n",
       "         ('UNANS', False): 2901,\n",
       "         ('UNANS', True): 1506})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8631359714370723"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(UNANS | q=Neg, c=NF)\n",
    "2901 / (2901 + 460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% coverage 5.867362417329046\n"
     ]
    }
   ],
   "source": [
    "print(\"% coverage\", 2901 / 49443 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49443"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([1 for l in labels if l == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575\n",
      "Who was not frustrated with the Spectre project?\n",
      "In November 2014, Sony Pictures Entertainment was targeted by hackers who released details of confidential e-mails between Sony executives regarding several high-profile film projects. Included within these were several memos relating to the production of Spectre, claiming that the film was over budget, detailing early drafts of the script written by John Logan, and expressing Sony's frustration with the project. Eon Productions later issued a statement confirming the leak of what they called \"an early version of the screenplay\".\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-419-e86b9d876c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#counter = Counter()\n",
    "for i, q in enumerate(questions):\n",
    "    context = contexts[examples[i][0]]\n",
    "    found_in_q = False\n",
    "    found_in_c = False\n",
    "    for t in negation_terms:\n",
    "        if t in q:\n",
    "            found_in_q = True\n",
    "    for t in negation_terms:\n",
    "        if t in context:\n",
    "            found_in_c = True\n",
    "    if found_in_q:\n",
    "        if labels[i] == False:\n",
    "            pass\n",
    "        else:\n",
    "            if not found_in_c and i > 2467:\n",
    "                print(i)\n",
    "                print(q)\n",
    "                print(context)\n",
    "                assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/daniter/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "import spacy\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_stop = [\"a\", \"an\", \"and\", \"as\", \"or\", \"the\", \"that\", \"which\", \"when\", \"whose\", \"is\", \"was\", \"what\", \"to\", \"of\"]\n",
    "\n",
    "def simple_filter(term):\n",
    "    if term in strip_stop or (term in nlp.vocab and nlp.vocab[term].is_punct):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def individual_filter(term):\n",
    "    if term.startswith(\"##\"):\n",
    "        return False\n",
    "    if term in nlp.vocab and (nlp.vocab[term].is_stop or nlp.vocab[term].is_punct):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def strip_terms(phrase):\n",
    "    fltr = [simple_filter(t) for t in phrase]\n",
    "    start = fltr.index(True)\n",
    "    end = list(reversed(fltr)).index(True)\n",
    "    return phrase[start:len(fltr) - end]\n",
    "\n",
    "def matcher(source, target):\n",
    "    i = 0\n",
    "    matches = []\n",
    "    while i < len(source):\n",
    "        ii = 1\n",
    "        current = []\n",
    "        for j in range(len(target)):\n",
    "            if source[i] == target[j]:\n",
    "                cand = []\n",
    "                for ii in range(len(source) - i):\n",
    "                    if j + ii > len(target) - 1:\n",
    "                        break\n",
    "                    if source[i + ii] == target[j + ii]:\n",
    "                        cand.append(source[i + ii])\n",
    "                    else:\n",
    "                        if len(cand) > len(current):\n",
    "                            current = list(cand)\n",
    "                        break\n",
    "                if len(cand) > len(current):\n",
    "                    current = list(cand)\n",
    "        if current:\n",
    "            matches.append(current)\n",
    "        i += len(current) if current else 1\n",
    "\n",
    "    ## filters\n",
    "    matches = [m for m in matches if sum(\n",
    "        [individual_filter(token) for token in m]) > 0]\n",
    "\n",
    "    matches = [strip_terms(m) for m in matches]\n",
    "    return matches\n",
    "\n",
    "def get_copies(q, c, parse=None):\n",
    "    copies = matcher(tokenizer.tokenize(q), tokenizer.tokenize(c))\n",
    "    return copies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n"
     ]
    }
   ],
   "source": [
    "copies = [None]*len(questions)\n",
    "for e in examples:\n",
    "    c, q = e\n",
    "    context= contexts[c]\n",
    "    question = questions[q]\n",
    "    x = get_copies(question, context)\n",
    "    copies[q] = x\n",
    "    if q % 1000 == 0:\n",
    "        print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "num_bins = 15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist([len(x) for x in copies], num_bins)\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_copies = []\n",
    "unans_copies = []\n",
    "for i, cop in enumerate(copies):\n",
    "    ll = 0\n",
    "    if cop is not None and cop:\n",
    "        cop_lens = [len(x) for x in cop]\n",
    "        ll = max(cop_lens)\n",
    "    if labels[i] == False:\n",
    "        ans_copies.append(ll)\n",
    "    else:\n",
    "        unans_copies.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "num_bins = 50\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(ans_copies, range(40))\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFX1JREFUeJzt3X+sX/V93/HnazjkV5sYwh1jtjd7jZWKRC2hd4QqVZXBCiZEMZPSCJQOL7PqTSVbumVLTCbNGykS0baSoDVMNLiYKoMgmharkFILiLJJhWAC4WcYt0CCLcC3MZB2UcmcvPfH9+Pmi7nX19zvtb+fe+/zIV3dc97nc873/T2y78vnfD8+N1WFJEm9+VvjbkCSpJkYUJKkLhlQkqQuGVCSpC4ZUJKkLhlQkqQuGVCSpC4ZUJKkLhlQkqQurRh3A/N10kkn1dq1a8fdhiTpNbrvvvv+oqom5hq3aANq7dq17N69e9xtSJJeoyTfOZJxc97iS7I9yb4kD8+w7RNJKslJbT1JrkoyleTBJKcPjd2U5In2tWmo/gtJHmr7XJUkR/YWJUlL2ZF8BnUdsOHQYpI1wDnAd4fK5wHr29cW4Oo29kRgG/Ae4AxgW5IT2j5XA78+tN+rXkuStPzMGVBV9XVg/wybrgQ+CQw/Dn0jcH0N3A2sTHIKcC6wq6r2V9ULwC5gQ9v2lqq6uwaPVb8euGC0tyRJWgrmNYsvyUZgb1V965BNq4Bnhtb3tNrh6ntmqM/2uluS7E6ye3p6ej6tS5IWidccUEneBHwa+I8L387hVdU1VTVZVZMTE3NOAJEkLWLzuYL6GWAd8K0kTwOrgW8m+TvAXmDN0NjVrXa4+uoZ6pKkZe41B1RVPVRVf7uq1lbVWga35U6vqueAncDFbTbfmcBLVfUscDtwTpIT2uSIc4Db27bvJzmzzd67GLhlgd6bJGkRO5Jp5jcAfwa8I8meJJsPM/w24ElgCvhd4DcAqmo/8Bng3vZ1WavRxnyx7fPnwFfn91YkSUtJBpPnFp/JycnyP+pK0uKT5L6qmpxrnM/ikyR1adE+6qgXa7feetjtT19x/jHqRJKWFq+gJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV2aM6CSbE+yL8nDQ7X/kuTbSR5M8odJVg5tuzTJVJLHk5w7VN/QalNJtg7V1yW5p9W/nOT4hXyDkqTF6UiuoK4DNhxS2wW8q6p+Dvg/wKUASU4FLgTe2fb5QpLjkhwH/A5wHnAqcFEbC/BZ4MqqejvwArB5pHckSVoS5gyoqvo6sP+Q2p9W1YG2ejewui1vBG6sqper6ilgCjijfU1V1ZNV9UPgRmBjkgBnATe3/XcAF4z4niRJS8BCfAb1z4GvtuVVwDND2/a02mz1twEvDoXdwbokaZkbKaCS/AfgAPClhWlnztfbkmR3kt3T09PH4iUlSWMy74BK8s+ADwAfqapq5b3AmqFhq1tttvr3gJVJVhxSn1FVXVNVk1U1OTExMd/WJUmLwLwCKskG4JPAB6vqB0ObdgIXJnl9knXAeuAbwL3A+jZj73gGEyl2tmC7C/hQ238TcMv83ookaSk5kmnmNwB/BrwjyZ4km4H/Dvw0sCvJA0n+B0BVPQLcBDwK/AlwSVX9qH3G9DHgduAx4KY2FuBTwL9NMsXgM6lrF/QdSpIWpRVzDaiqi2YozxoiVXU5cPkM9duA22aoP8lglp8kSX/DJ0lIkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6tGLcDfRs7dZbj8kxnr7i/JFfR5KWGq+gJEldMqAkSV0yoCRJXTKgJEldmjOgkmxPsi/Jw0O1E5PsSvJE+35CqyfJVUmmkjyY5PShfTa18U8k2TRU/4UkD7V9rkqShX6TkqTF50iuoK4DNhxS2wrcUVXrgTvaOsB5wPr2tQW4GgaBBmwD3gOcAWw7GGptzK8P7Xfoa0mSlqE5A6qqvg7sP6S8EdjRlncAFwzVr6+Bu4GVSU4BzgV2VdX+qnoB2AVsaNveUlV3V1UB1w8dS5K0jM33M6iTq+rZtvwccHJbXgU8MzRuT6sdrr5nhvqMkmxJsjvJ7unp6Xm2LklaDEaeJNGufGoBejmS17qmqiaranJiYuJYvKQkaUzmG1DPt9tztO/7Wn0vsGZo3OpWO1x99Qx1SdIyN9+A2gkcnIm3CbhlqH5xm813JvBSuxV4O3BOkhPa5IhzgNvbtu8nObPN3rt46FiSpGVszmfxJbkBeB9wUpI9DGbjXQHclGQz8B3gw234bcD7gSngB8BHAapqf5LPAPe2cZdV1cGJF7/BYKbgG4Gvti9J0jI3Z0BV1UWzbDp7hrEFXDLLcbYD22eo7wbeNVcfkqTlxSdJSJK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6NFJAJfk3SR5J8nCSG5K8Icm6JPckmUry5STHt7Gvb+tTbfvaoeNc2uqPJzl3tLckSVoK5h1QSVYB/xqYrKp3AccBFwKfBa6sqrcDLwCb2y6bgRda/co2jiSntv3eCWwAvpDkuPn2JUlaGka9xbcCeGOSFcCbgGeBs4Cb2/YdwAVteWNbp20/O0la/caqermqngKmgDNG7EuStMjNO6Cqai/wX4HvMgiml4D7gBer6kAbtgdY1ZZXAc+0fQ+08W8brs+wzysk2ZJkd5Ld09PT821dkrQIjHKL7wQGVz/rgL8LvJnBLbqjpqquqarJqpqcmJg4mi8lSRqzUW7x/WPgqaqarqr/B3wFeC+wst3yA1gN7G3Le4E1AG37W4HvDddn2EeStEyNElDfBc5M8qb2WdLZwKPAXcCH2phNwC1teWdbp22/s6qq1S9ss/zWAeuBb4zQlyRpCVgx95CZVdU9SW4GvgkcAO4HrgFuBW5M8lutdm3b5Vrg95NMAfsZzNyjqh5JchODcDsAXFJVP5pvX5KkpWHeAQVQVduAbYeUn2SGWXhV9dfAr85ynMuBy0fpRZK0tPgkCUlSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXVoy7AcHarbcedvvTV5x/jDqRpH54BSVJ6pIBJUnq0kgBlWRlkpuTfDvJY0l+McmJSXYleaJ9P6GNTZKrkkwleTDJ6UPH2dTGP5Fk06hvSpK0+I16BfV54E+q6meBnwceA7YCd1TVeuCOtg5wHrC+fW0BrgZIciKwDXgPcAaw7WCoSZKWr3kHVJK3Ar8MXAtQVT+sqheBjcCONmwHcEFb3ghcXwN3AyuTnAKcC+yqqv1V9QKwC9gw374kSUvDKFdQ64Bp4PeS3J/ki0neDJxcVc+2Mc8BJ7flVcAzQ/vvabXZ6q+SZEuS3Ul2T09Pj9C6JKl3owTUCuB04Oqqejfwf/nJ7TwAqqqAGuE1XqGqrqmqyaqanJiYWKjDSpI6NEpA7QH2VNU9bf1mBoH1fLt1R/u+r23fC6wZ2n91q81WlyQtY/MOqKp6DngmyTta6WzgUWAncHAm3ibglra8E7i4zeY7E3ip3Qq8HTgnyQltcsQ5rSZJWsZGfZLEvwK+lOR44EngowxC76Ykm4HvAB9uY28D3g9MAT9oY6mq/Uk+A9zbxl1WVftH7EuStMiNFFBV9QAwOcOms2cYW8AlsxxnO7B9lF4kSUuLT5KQJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHVp5IBKclyS+5P8cVtfl+SeJFNJvpzk+FZ/fVufatvXDh3j0lZ/PMm5o/YkSVr8FuIK6uPAY0PrnwWurKq3Ay8Am1t9M/BCq1/ZxpHkVOBC4J3ABuALSY5bgL4kSYvYSAGVZDVwPvDFth7gLODmNmQHcEFb3tjWadvPbuM3AjdW1ctV9RQwBZwxSl+SpMVv1CuozwGfBH7c1t8GvFhVB9r6HmBVW14FPAPQtr/Uxv9NfYZ9XiHJliS7k+yenp4esXVJUs/mHVBJPgDsq6r7FrCfw6qqa6pqsqomJyYmjtXLSpLGYMUI+74X+GCS9wNvAN4CfB5YmWRFu0paDext4/cCa4A9SVYAbwW+N1Q/aHgfSdIyNe8rqKq6tKpWV9VaBpMc7qyqjwB3AR9qwzYBt7TlnW2dtv3OqqpWv7DN8lsHrAe+Md++JElLwyhXULP5FHBjkt8C7geubfVrgd9PMgXsZxBqVNUjSW4CHgUOAJdU1Y+OQl+SpEVkQQKqqr4GfK0tP8kMs/Cq6q+BX51l/8uByxeiF0nS0uCTJCRJXTKgJEldMqAkSV0yoCRJXToas/i0wNZuvXXOMU9fcf4x6ESSjh2voCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldMqAkSV0yoCRJXTKgJEldmndAJVmT5K4kjyZ5JMnHW/3EJLuSPNG+n9DqSXJVkqkkDyY5fehYm9r4J5JsGv1tSZIWu1GuoA4An6iqU4EzgUuSnApsBe6oqvXAHW0d4DxgffvaAlwNg0ADtgHvAc4Ath0MNUnS8jXvgKqqZ6vqm235L4HHgFXARmBHG7YDuKAtbwSur4G7gZVJTgHOBXZV1f6qegHYBWyYb1+SpKVhQT6DSrIWeDdwD3ByVT3bNj0HnNyWVwHPDO22p9Vmq8/0OluS7E6ye3p6eiFalyR1auSASvJTwB8Av1lV3x/eVlUF1KivMXS8a6pqsqomJyYmFuqwkqQOrRhl5ySvYxBOX6qqr7Ty80lOqapn2y28fa2+F1gztPvqVtsLvO+Q+tdG6Ws5Wrv11jnHPH3F+cegE0laGKPM4gtwLfBYVf320KadwMGZeJuAW4bqF7fZfGcCL7VbgbcD5yQ5oU2OOKfVJEnL2ChXUO8F/inwUJIHWu3TwBXATUk2A98BPty23Qa8H5gCfgB8FKCq9if5DHBvG3dZVe0foS9J0hIw74Cqqv8NZJbNZ88wvoBLZjnWdmD7fHuRJC09PklCktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUpZF+H5QWl7l+Z5S/L0pST7yCkiR1yYCSJHVp2d7iO5JfkS5JGh+voCRJXTKgJEldMqAkSV1atp9B6dWO5HM5p6JLOla8gpIkdcmAkiR1yYCSJHXJz6D0mvi4JEnHildQkqQuGVCSpC51c4svyQbg88BxwBer6ooxt6R5cKq6pIXSRUAlOQ74HeBXgD3AvUl2VtWj4+1MR4OfY0k6El0EFHAGMFVVTwIkuRHYCBhQy1BPD/I1LKXx6SWgVgHPDK3vAd5z6KAkW4AtbfWvkjw+wmueBPzFCPsfS/Z6dMzZaz57jDqZ25I6rx2x16Njrl7//pEcpJeAOiJVdQ1wzUIcK8nuqppciGMdbfZ6dNjr0WGvR8dy7LWXWXx7gTVD66tbTZK0TPUSUPcC65OsS3I8cCGwc8w9SZLGqItbfFV1IMnHgNsZTDPfXlWPHOWXXZBbhceIvR4d9np02OvRsex6TVUtxHEkSVpQvdzikyTpFQwoSVKXlmVAJdmQ5PEkU0m2jrufw0nydJKHkjyQZPe4+xmWZHuSfUkeHqqdmGRXkifa9xPG2eNBs/T6n5Lsbef2gSTvH2ePByVZk+SuJI8meSTJx1u9u3N7mF67O7dJ3pDkG0m+1Xr9z62+Lsk97efBl9tErR77vC7JU0Pn9LRx9jksyXFJ7k/yx219Qc7psguooccqnQecClyU5NTxdjWnf1RVp3X4fyCuAzYcUtsK3FFV64E72noPruPVvQJc2c7taVV12zHuaTYHgE9U1anAmcAl7c9oj+d2tl6hv3P7MnBWVf08cBqwIcmZwGcZ9Pp24AVg8xh7hNn7BPj3Q+f0gfG1+CofBx4bWl+Qc7rsAoqhxypV1Q+Bg49V0mtUVV8H9h9S3gjsaMs7gAuOaVOzmKXXLlXVs1X1zbb8lwz+4q+iw3N7mF67UwN/1VZf174KOAu4udXHfl4P02eXkqwGzge+2NbDAp3T5RhQMz1Wqcu/UE0Bf5rkvvaop96dXFXPtuXngJPH2cwR+FiSB9stwLHfMjtUkrXAu4F76PzcHtIrdHhu262oB4B9wC7gz4EXq+pAG9LFz4ND+6yqg+f08nZOr0zy+jG2OOxzwCeBH7f1t7FA53Q5BtRi80tVdTqDW5KXJPnlcTd0pGrwfxi6/ZcfcDXwMwxuozwL/LfxtvNKSX4K+APgN6vq+8Pbeju3M/Ta5bmtqh9V1WkMnlZzBvCzY25pRof2meRdwKUM+v2HwInAp8bYIgBJPgDsq6r7jsbxl2NALarHKlXV3vZ9H/CHDP5S9ez5JKcAtO/7xtzPrKrq+faD4MfA79LRuU3yOgY/8L9UVV9p5S7P7Uy99nxuAarqReAu4BeBlUkOPrSgq58HQ31uaLdTq6peBn6PPs7pe4EPJnmawcclZzH4vX4Lck6XY0AtmscqJXlzkp8+uAycAzx8+L3GbiewqS1vAm4ZYy+HdfCHffNP6OTctnv41wKPVdVvD23q7tzO1muP5zbJRJKVbfmNDH7/3GMMAuBDbdjYz+ssfX576B8nYfCZztjPaVVdWlWrq2otg5+ld1bVR1igc7osnyTRprx+jp88VunyMbc0oyT/gMFVEwweS/U/e+o1yQ3A+xg8Wv95YBvwR8BNwN8DvgN8uKrGPjlhll7fx+AWVAFPA/9i6DOesUnyS8D/Ah7iJ/f1P83gs52uzu1her2Izs5tkp9j8IH9cQz+cX5TVV3W/p7dyOC22f3Ar7WrlN76vBOYAAI8APzLockUY5fkfcC/q6oPLNQ5XZYBJUnq33K8xSdJWgQMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpf+PxwrsctxAPA/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "num_bins = 15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(unans_copies, range(40))\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common words in fake questions that aren't in context\n",
    "# condition on parse tree?\n",
    "# copies spans that have something swapped and antonym detector?\n",
    "# not, date, change name, swap in a copy, antonym\n",
    "# templating with BERT by doing the IsA trick\n",
    "\n",
    "\n",
    "# The House of Lords introduced qualifications for which position?\n",
    "#-> change of entity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_contexts = []\n",
    "for c in contexts:\n",
    "    tokenized_contexts.append(tokenizer.tokenize(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_in_y_int(query, base):\n",
    "    try:\n",
    "        l = len(query)\n",
    "    except TypeError:\n",
    "        l = 1\n",
    "        query = type(base)((query,))\n",
    "\n",
    "    for i in range(len(base)):\n",
    "        if base[i:i + l] == query:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min distance between 2 copied sections\n",
    "dist_counter = {True: Counter(), False: Counter()}\n",
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    copy_starts = [x_in_y_int(copy, ct) for copy in copy_set]\n",
    "    min_dist = 99999\n",
    "    for i, i_start in enumerate(copy_starts):\n",
    "        for j, j_start in enumerate(copy_starts):\n",
    "            if i == j or i_start > j_start:\n",
    "                continue\n",
    "            \n",
    "            dist = j_start - i_start - len(copy_set[i])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "    label = labels[qi]\n",
    "    dist_counter[label][min_dist] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2140\n",
      "1 5474\n",
      "2 3782\n",
      "3 2434\n",
      "4 1793\n",
      "-1 471\n",
      "99999 11654\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(5)) + [-1, 99999]:\n",
    "    print(i, dist_counter[True][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4950\n",
      "1 11900\n",
      "2 7966\n",
      "3 4763\n",
      "4 3711\n",
      "-1 1108\n",
      "99999 20302\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(5)) + [-1, 99999]:\n",
    "    print(i, dist_counter[False][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "What album made her a worldwide known artist?\n",
      "[['album'], ['worldwide'], ['artist']]\n"
     ]
    }
   ],
   "source": [
    "#dist_counter = {True: Counter(), False: Counter()}\n",
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    copy_starts = [x_in_y_int(copy, ct) for copy in copy_set]\n",
    "    min_dist = 99999\n",
    "    for i, i_start in enumerate(copy_starts):\n",
    "        for j, j_start in enumerate(copy_starts):\n",
    "            if i == j or i_start > j_start:\n",
    "                continue\n",
    "            \n",
    "            dist = j_start - i_start - len(copy_set[i])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "    if min_dist == 0:\n",
    "        print(q)\n",
    "        print(c)\n",
    "        print(q)\n",
    "        print(copy_set)\n",
    "        break\n",
    "    label = labels[qi]\n",
    "    #dist_counter[label][min_dist] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min distance between 2 copied sections\n",
    "dist_counter = {True: Counter(), False: Counter()}\n",
    "none_counter = 0\n",
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    copy_starts = [x_in_y_int(copy, ct) for copy in copy_set]\n",
    "    min_dist = 99999\n",
    "    for i, i_start in enumerate(copy_starts):\n",
    "        if i >= len(copy_starts) - 1:\n",
    "            break\n",
    "        j_start = copy_starts[i+1]\n",
    "        dist = j_start - i_start - len(copy_set[i])\n",
    "        if dist == 1:\n",
    "            tok = ct[j_start-1]\n",
    "            if tok in nlp.vocab and nlp.vocab[tok].is_punct or nlp.vocab[tok].is_stop:\n",
    "                continue\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "    if min_dist < 99999:\n",
    "        label = labels[qi]\n",
    "        dist_counter[label][min_dist] += 1\n",
    "    else:\n",
    "        none_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37064, 70521)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dist_counter[True].values()), sum(dist_counter[False].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4002805957263114\n",
      "1 2.4660047485430607\n",
      "2 4.883444852147637\n",
      "3 2.897690481329592\n",
      "4 1.902115260090654\n",
      "-1 0.1915605439240233\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(5)) + [-1]:\n",
    "    print(i, dist_counter[True][i] / sum(dist_counter[True].values()) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.7002027764779284\n",
      "1 2.1794926333999802\n",
      "2 5.032543497681542\n",
      "3 2.8232725003899546\n",
      "4 2.0674692644744117\n",
      "-1 0.21837466853844956\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(5)) + [-1]:\n",
    "    print(i, dist_counter[False][i] / sum(dist_counter[False].values()) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2727\n",
      "After wrapping up in England, production travelled to Morocco in June, with filming taking place in Oujda, Tangier and Erfoud, after preliminary work was completed by the production's second unit. An explosion filmed in Morocco holds a Guinness World Record for the \"Largest film stunt explosion\" in cinematic history, with the record credited to production designer Chris Corbould. Principal photography concluded on 5 July 2015. A wrap-up party for Spectre was held in commemoration before entering post-production. Filming took 128 days.\n",
      "True An explosion filmed in what city holds the Guinness World Record for \"Smallest film stunt explosion\"?\n",
      "[['explosion', 'filmed', 'in'], ['holds'], ['guinness', 'world', 'record', 'for'], ['film', 'stunt', 'explosion']]\n"
     ]
    }
   ],
   "source": [
    "# min distance between 2 copied sections\n",
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    copy_starts = [x_in_y_int(copy, ct) for copy in copy_set]\n",
    "    min_dist = 99999\n",
    "    for i, i_start in enumerate(copy_starts):\n",
    "        if i >= len(copy_starts) - 1:\n",
    "            break\n",
    "        j_start = copy_starts[i+1]\n",
    "        dist = j_start - i_start - len(copy_set[i])\n",
    "        if dist == 1:\n",
    "            tok = ct[j_start-1]\n",
    "            if tok in nlp.vocab and nlp.vocab[tok].is_punct or nlp.vocab[tok].is_stop:\n",
    "                continue\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "    if min_dist == 1 and qi > 2723 and labels[qi] == True:\n",
    "        print(qi)\n",
    "        print(c)\n",
    "        print(labels[qi], q)\n",
    "        print(copy_set)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_token = {True: Counter(), False: Counter()}\n",
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    copy_starts = [x_in_y_int(copy, ct) for copy in copy_set]\n",
    "    min_dist = 99999\n",
    "    min_j = -1\n",
    "    for i, i_start in enumerate(copy_starts):\n",
    "        if i >= len(copy_starts) - 1:\n",
    "            break\n",
    "        j_start = copy_starts[i+1]\n",
    "        dist = j_start - i_start - len(copy_set[i])\n",
    "        if dist == 1:\n",
    "            tok = ct[j_start-1]\n",
    "            if tok in nlp.vocab and nlp.vocab[tok].is_punct or nlp.vocab[tok].is_stop:\n",
    "                continue\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_j = j_start\n",
    "    if min_dist == 1:\n",
    "        label = labels[qi]\n",
    "        middle_token[label][ct[min_j-1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('took', 7),\n",
       " ('##s', 7),\n",
       " ('began', 7),\n",
       " ('largest', 7),\n",
       " ('large', 6),\n",
       " ('north', 6),\n",
       " ('political', 6),\n",
       " ('second', 5),\n",
       " ('low', 5),\n",
       " ('significant', 5),\n",
       " ('typically', 4),\n",
       " ('hd', 4),\n",
       " ('lines', 4),\n",
       " ('human', 4),\n",
       " ('electric', 4),\n",
       " ('new', 4),\n",
       " ('8', 4),\n",
       " ('dark', 4),\n",
       " ('##ed', 3),\n",
       " ('eastern', 3),\n",
       " ('western', 3),\n",
       " ('northwest', 3),\n",
       " ('navigation', 3),\n",
       " ('20th', 3),\n",
       " ('aircraft', 3)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_token[True].most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('##s', 22),\n",
       " ('took', 12),\n",
       " ('##ing', 10),\n",
       " ('began', 9),\n",
       " ('studio', 8),\n",
       " ('national', 8),\n",
       " ('gave', 7),\n",
       " ('known', 7),\n",
       " ('natural', 6),\n",
       " ('gained', 6),\n",
       " ('announced', 6),\n",
       " ('different', 6),\n",
       " ('##berg', 6),\n",
       " ('largest', 5),\n",
       " ('developed', 5),\n",
       " ('went', 5),\n",
       " ('single', 5),\n",
       " ('entered', 5),\n",
       " ('visited', 5),\n",
       " ('granted', 5),\n",
       " ('names', 4),\n",
       " ('television', 4),\n",
       " ('november', 4),\n",
       " ('##ed', 4),\n",
       " ('acquired', 4)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_token[False].most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142192"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dist_counter[True].values()) + sum(dist_counter[False].values()) + none_counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142192"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8768\n",
      "Most of the Low Countries had come under the rule of the House of Burgundy and subsequently the House of Habsburg. In 1549 Holy Roman Emperor Charles V issued the Pragmatic Sanction, which further unified the Seventeen Provinces under his rule. Charles was succeeded by his son, King Philip II of Spain. In 1568 the Netherlands, led by William I of Orange, revolted against Philip II because of high taxes, persecution of Protestants by the government, and Philip's efforts to modernize and centralize the devolved-medieval government structures of the provinces. This was the start of the Eighty Years' War.\n",
      "True When did the House of Burgundy revolt against Philip II?\n",
      "[['house', 'of', 'burgundy'], ['revolt'], ['against', 'philip', 'ii']]\n"
     ]
    }
   ],
   "source": [
    "# min distance between 2 copied sections\n",
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    copy_starts = [x_in_y_int(copy, ct) for copy in copy_set]\n",
    "    min_dist = 99999\n",
    "    min_j = -1\n",
    "    for i, i_start in enumerate(copy_starts):\n",
    "        if i >= len(copy_starts) - 1:\n",
    "            break\n",
    "        j_start = copy_starts[i+1]\n",
    "        dist = j_start - i_start - len(copy_set[i])\n",
    "        if dist == 1:\n",
    "            tok = ct[j_start-1]\n",
    "            if tok in nlp.vocab and nlp.vocab[tok].is_punct or nlp.vocab[tok].is_stop:\n",
    "                continue\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_j = j_start\n",
    "    if min_dist == 1 and ct[min_j-1] == '##ed' and qi > 5453:\n",
    "        print(qi)\n",
    "        print(c)\n",
    "        print(labels[qi], q)\n",
    "        print(copy_set)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_questions = []\n",
    "for q in questions:\n",
    "    tokenized_questions.append(tokenizer.tokenize(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "of_counter = {True:0, False:0}\n",
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    qt = tokenized_questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    for copy in copy_set:\n",
    "        start = x_in_y_int(copy, qt)\n",
    "        cstart = x_in_y_int(copy, ct)\n",
    "        if (start != 0 and qt[start-1] == 'of' and cstart !=0 and ct[cstart-1] == 'of') or \\\n",
    "        ((start+len(copy)) < len(qt) and qt[start+len(copy)] == 'of' and cstart+len(copy) < len(ct) and ct[cstart+len(copy)] == 'of'):\n",
    "            of_counter[labels[qi]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 || False || What is included at the end of Glory?\n",
      "On January 7, 2012, Beyoncé gave birth to a daughter, Blue Ivy Carter, at Lenox Hill Hospital in New York under heavy security. Two days later, Jay Z released \"Glory\", a song dedicated to their child, on his website Lifeandtimes.com. The song detailed the couple's pregnancy struggles, including a miscarriage Beyoncé suffered before becoming pregnant with Blue Ivy. Blue Ivy's cries are included at the end of the song, and she was officially credited as \"B.I.C.\" on it. At two days old, she became the youngest person ever to appear on a Billboard chart when \"Glory\" debuted on the Hot R&B/Hip-Hop Songs chart.\n",
      "[['included', 'at', 'the', 'end'], ['glory']]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-391-75361c8ee186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    qt = tokenized_questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    for copy in copy_set:\n",
    "        start = x_in_y_int(copy, qt)\n",
    "        cstart = x_in_y_int(copy, ct)\n",
    "        if (start != 0 and qt[start-1] == 'of' and cstart !=0 and ct[cstart-1] == 'of') or \\\n",
    "        ((start+len(copy)) < len(qt) and qt[start+len(copy)] == 'of' and cstart+len(copy) < len(ct) and ct[cstart+len(copy)] == 'of'):\n",
    "            if qi > 342 and labels[qi] == False:\n",
    "                print(qi, \"||\",labels[qi], \"||\", q)\n",
    "                print(c)\n",
    "                print(copy_set)\n",
    "                assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07584491232328136, 0.06279312984506571)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "of_counter[True]/ np.sum(labels), of_counter[False]/ (len(labels) - np.sum(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075 || True || What category of game is Legend of Zelda: Australia Twilight?\n",
      "The Legend of Zelda: Twilight Princess (Japanese: ゼルダの伝説 トワイライトプリンセス, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]\n",
      "[['game'], ['legend', 'of', 'ze', '##lda'], ['australia'], ['twilight']]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-412-85d7c61150c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in examples:\n",
    "    ci, qi = e\n",
    "    c = contexts[ci]\n",
    "    ct = tokenized_contexts[ci]\n",
    "    q = questions[qi]\n",
    "    qt = tokenized_questions[qi]\n",
    "    copy_set = copies[qi]\n",
    "    for copy in copy_set:\n",
    "        start = x_in_y_int(copy, qt)\n",
    "        cstart = x_in_y_int(copy, ct)\n",
    "        if labels[qi] == True and qi > 0:\n",
    "            print(qi, \"||\",labels[qi], \"||\", q)\n",
    "            print(c)\n",
    "            print(copy_set)\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"of\" trick doesn't really work becaue while there are many cases where the question replaces the X of Y with x' or y' where x != x', there are many cases where x' is a paraphrasing of x, which is the case in the answerable questions. It also has some to do with co-reference (the song vs Glory) or just parse errors (As of Aug..-> where as of are removed because they are stop words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting change of meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/daniter/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmpjml12ham\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cpu')\n",
    "segments_tensors = segments_tensors.to('cpu')\n",
    "model.to('cpu')\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "assert predicted_token == 'henson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_masked(text):\n",
    "    tokenized_text = tokenizer.tokenize(\"[CLS] \" + text)\n",
    "    tokenized_text = [t if not t=='@' else '[MASK]' for t in tokenized_text]\n",
    "    masked_index = tokenized_text.index('[MASK]')\n",
    "    print(tokenized_text)\n",
    "\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "    if '[SEP]' not in tokenized_text:\n",
    "        segments_ids = [0]*len(indexed_tokens)\n",
    "    else:\n",
    "        idx = tokenized_text.index('[SEP]')\n",
    "        segments_ids = [0]*idx + [1] * (len(indexed_tokens) - idx)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # If you have a GPU, put everything on cuda\n",
    "    tokens_tensor = tokens_tensor.to('cpu')\n",
    "    segments_tensors = segments_tensors.to('cpu')\n",
    "\n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # confirm we were able to predict 'henson'\n",
    "    predictions = predictions[0, masked_index]\n",
    "    scores = Counter()\n",
    "    for i, score in enumerate(predictions):\n",
    "        scores[tokenizer.convert_ids_to_tokens([i])[0]] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'largest', '[MASK]', 'smallest']\n",
      "and tensor(8.1508)\n",
      "or tensor(6.4708)\n",
      ", tensor(6.2725)\n",
      "& tensor(5.9001)\n",
      "- tensor(5.7513)\n",
      "of tensor(5.3609)\n",
      "/ tensor(4.7303)\n",
      "the tensor(4.4213)\n",
      ": tensor(4.3504)\n",
      ". tensor(4.1448)\n",
      ") tensor(4.1330)\n",
      "to tensor(4.0987)\n",
      "( tensor(3.9033)\n",
      "group tensor(3.6704)\n",
      "is tensor(3.3524)\n",
      "in tensor(3.2864)\n",
      "; tensor(3.2606)\n",
      "non tensor(3.2527)\n",
      "with tensor(3.1733)\n",
      "family tensor(3.0458)\n"
     ]
    }
   ],
   "source": [
    "c = top_k_masked(\"largest @ smallest\")\n",
    "for a,b in c.most_common(20):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideas\n",
    "x log-odds of words  \n",
    "x import wordnet and find antonyms  \n",
    "x look at 'of' in edge words  \n",
    "look at adversarial training (teach model opposites / alternative nouns/entities)  \n",
    "copy model (given mask, predict if it's copied and if so, just do span match)  \n",
    "make coverage + precision map  \n",
    "\n",
    "- train new model w/ adversarial  \n",
    "- train model with new mask feature  \n",
    "- train model with copy feature and distribution  \n",
    "- think about how we can determine if someting is a surprise vs a paraphrase?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tokens = Counter()\n",
    "for c in tokenized_contexts:\n",
    "    for tok in c:\n",
    "        context_tokens[tok] += 1\n",
    "tokens = {True: Counter(), False: Counter()}\n",
    "for i, qt in enumerate(tokenized_questions):\n",
    "    label = labels[i]\n",
    "    for tok in qt:\n",
    "        tokens[label][tok] += 1\n",
    "normalized_tokens = {True: Counter(), False: Counter()}\n",
    "for k, v in tokens.items():\n",
    "    for tok, count in v.items():\n",
    "        normalized_tokens[k][tok] = count / context_tokens[tok] if tok in context_tokens else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_counter = Counter()\n",
    "for k,v in normalized_tokens[False].items():\n",
    "    diff_counter[k] = normalized_tokens[True][k] - v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weren', 17.799999999999997),\n",
       " ('isn', 16.23076923076923),\n",
       " ('wasn', 11.916666666666666),\n",
       " ('aren', 10.0),\n",
       " ('hasn', 7.5),\n",
       " ('didn', 6.837209302325581),\n",
       " ('doesn', 6.066666666666666),\n",
       " ('smallest', 2.926829268292683),\n",
       " ('cares', 2.0),\n",
       " ('gora', 2.0),\n",
       " ('##lowe', 2.0),\n",
       " ('sd', 1.8636363636363635),\n",
       " ('wouldn', 1.8571428571428572),\n",
       " ('t', 1.7075718015665795),\n",
       " ('uncommon', 1.5588235294117647),\n",
       " ('shouldn', 1.5),\n",
       " ('sherlock', 1.3333333333333335),\n",
       " ('stalking', 1.3333333333333335),\n",
       " ('benedictine', 1.2941176470588234),\n",
       " ('never', 1.292929292929293),\n",
       " ('fake', 1.25),\n",
       " ('unofficially', 1.222222222222222),\n",
       " ('2018', 1.2),\n",
       " ('unpublished', 1.1666666666666665),\n",
       " ('steal', 1.1428571428571428)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_counter.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 340.97769516728624),\n",
       " ('what', 57.39936440677966),\n",
       " ('how', 20.770020533880903),\n",
       " ('nyc', 19.8),\n",
       " ('kanye', 14.666666666666666),\n",
       " ('did', 14.586327782646801),\n",
       " ('announce', 10.555555555555555),\n",
       " ('_', 10.4),\n",
       " ('why', 9.426573426573427),\n",
       " ('happens', 8.434782608695652),\n",
       " ('does', 8.373493975903614),\n",
       " ('frederic', 7.4375),\n",
       " ('wwii', 7.166666666666667),\n",
       " ('advises', 7.0),\n",
       " ('##enity', 7.0),\n",
       " ('##sir', 7.0),\n",
       " ('feb', 7.0),\n",
       " ('percentage', 6.608),\n",
       " ('happened', 6.468085106382978),\n",
       " ('straightening', 6.0),\n",
       " ('type', 5.263392857142857),\n",
       " ('##with', 5.0),\n",
       " ('cops', 5.0),\n",
       " ('begin', 4.547169811320755),\n",
       " ('kind', 4.535714285714286)]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tokens[False].most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 182.46468401486987),\n",
       " ('what', 33.20762711864407),\n",
       " ('weren', 19.4),\n",
       " ('isn', 18.23076923076923),\n",
       " ('wasn', 12.875),\n",
       " ('aren', 12.222222222222221),\n",
       " ('how', 9.634496919917865),\n",
       " ('hasn', 9.0),\n",
       " ('didn', 8.0),\n",
       " ('happens', 7.695652173913044),\n",
       " ('doesn', 7.466666666666667),\n",
       " ('did', 7.257668711656442),\n",
       " ('happened', 6.042553191489362),\n",
       " ('why', 5.5174825174825175),\n",
       " ('does', 5.010327022375215),\n",
       " ('wraps', 5.0),\n",
       " ('ripley', 5.0),\n",
       " ('cops', 5.0),\n",
       " ('mbc', 5.0),\n",
       " ('announce', 4.555555555555555),\n",
       " ('steals', 4.0),\n",
       " ('##with', 4.0),\n",
       " ('smallest', 3.5609756097560976),\n",
       " ('percentage', 3.44),\n",
       " ('wwii', 3.1666666666666665)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tokens[True].most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antonyms : check if antonyms occur often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_examples_ans = []\n",
    "sampled_examples_unans = []\n",
    "for e in random.sample(examples, len(examples)):\n",
    "    if labels[e[1]] == True and len(sampled_examples_unans) < 200:\n",
    "        sampled_examples_unans.append(e)\n",
    "    elif labels[e[1]] == False and len(sampled_examples_ans) < 200:\n",
    "        sampled_examples_ans.append(e)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 100\n",
      "17 14\n",
      "[('new', 5), ('most', 5), ('type', 4), ('some', 4), ('power', 4), ('powerfulness', 4), ('former', 3), ('inside', 3), ('all', 3), ('southern', 3), ('other', 3), ('necessitate', 2), ('believe', 2), ('defeat', 2), ('beginning', 2), ('complexity', 2), ('let', 2), ('belief', 2), ('likely', 2), ('high', 2), ('king', 2), ('male_monarch', 2), ('woman', 2), ('no', 1), ('relevant', 1)]\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "[('type', 6), ('most', 5), ('new', 5), ('unremarkably', 4), ('black', 2), ('there', 2), ('necessitate', 2), ('agreement', 2), ('woman', 2), ('believe', 2), ('early', 2), ('color', 2), ('different', 2), ('able', 2), ('high', 2), ('never', 2), ('lose', 1), ('decrease', 1), ('arm', 1), ('security', 1), ('nuclear', 1), ('other', 1), ('king', 1), ('male_monarch', 1), ('asset', 1)]\n"
     ]
    }
   ],
   "source": [
    "count_has_ant_ans = 0\n",
    "count_has_ant_unans = 0\n",
    "common_words_ans = Counter()\n",
    "common_words_unans = Counter()\n",
    "ant_in_context_ans = 0\n",
    "ant_in_context_unans = 0\n",
    "for ci, qi in sampled_examples_ans:\n",
    "    q = questions[qi]\n",
    "    c = contexts[ci]\n",
    "    for tok in nlp(q):\n",
    "        ss = wn.synsets(tok.lemma_)\n",
    "        if ss:\n",
    "            for l in ss[0].lemmas():\n",
    "                if l.name() in ['on', 'many']:\n",
    "                    continue\n",
    "                if l.antonyms():\n",
    "                    count_has_ant_ans += 1\n",
    "                    common_words_ans[l.name()] +=1\n",
    "                    for ant in l.antonyms()[0].synset().lemma_names():\n",
    "                        if ant in c:\n",
    "                            ant_in_context_ans += 1\n",
    "for ci, qi in sampled_examples_unans:\n",
    "    q = questions[qi]\n",
    "    c = contexts[ci]\n",
    "    for tok in nlp(q):\n",
    "        ss = wn.synsets(tok.lemma_)\n",
    "        if ss:\n",
    "            for l in ss[0].lemmas():\n",
    "                if l.name() in ['on', 'many']:\n",
    "                    continue\n",
    "                if l.antonyms():\n",
    "                    count_has_ant_unans += 1\n",
    "                    common_words_unans[l.name()] +=1\n",
    "                    for ant in l.antonyms()[0].synset().lemma_names():\n",
    "                        if ant in c:\n",
    "                            ant_in_context_unans += 1\n",
    "print(count_has_ant_ans, count_has_ant_unans)\n",
    "print(ant_in_context_ans, ant_in_context_unans)\n",
    "print(common_words_ans.most_common(25))\n",
    "print(\"~\"*20)\n",
    "print(common_words_unans.most_common(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What decreased the pressure for people of African descent to be claimed by the black community?\n",
      "After the Civil War, racial segregation forced African Americans to share more of a common lot in society than they might have given widely varying ancestry, educational and economic levels. The binary division altered the separate status of the traditionally free people of color in Louisiana, for instance, although they maintained a strong Louisiana Créole culture related to French culture and language, and practice of Catholicism. African Americans began to create common cause—regardless of their multiracial admixture or social and economic stratification. In 20th-century changes, during the rise of the Civil Rights and Black Power movements, the African-American community increased its own pressure for people of any portion of African descent to be claimed by the black community to add to its power.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-420-fb678da9728e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ci, qi in sampled_examples_unans:\n",
    "    q = questions[qi]\n",
    "    c = contexts[ci]\n",
    "    for tok in nlp(q):\n",
    "        ss = wn.synsets(tok.lemma_)\n",
    "        if ss:\n",
    "            for l in ss[0].lemmas():\n",
    "                if l.name() in ['on', 'many']:\n",
    "                    continue\n",
    "                if l.antonyms():\n",
    "                    for ant in l.antonyms()[0].synset().lemma_names():\n",
    "                        if ant in c:\n",
    "                            print(q)\n",
    "                            print(c)\n",
    "                            assert False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('small.a.01.small')]\n",
      "[Lemma('small.a.01.little')]\n"
     ]
    }
   ],
   "source": [
    "for l in wn.synsets('largest')[0].lemmas():\n",
    "    print(l.antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['large', 'big']\n",
      "['large']\n",
      "['bombastic', 'declamatory', 'large', 'orotund', 'tumid', 'turgid']\n",
      "['big', 'large', 'magnanimous']\n",
      "['big', 'large', 'prominent']\n",
      "['large']\n",
      "['big', 'enceinte', 'expectant', 'gravid', 'great', 'large', 'heavy', 'with_child']\n"
     ]
    }
   ],
   "source": [
    "for s in wn.synsets('largest'):\n",
    "    print(s.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do mens sexual orientations tend be focused on?\n",
      "What\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "do\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "mens\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "sexual\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "orientations\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "tend\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "be\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "focused\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "on\n",
      "['off']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "?\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What improved in 1936 because of the Royal Air Force?\n",
      "What\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "improved\n",
      "['worsen', 'aggravate', 'exacerbate', 'exasperate']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "in\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "1936\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "because\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "of\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Royal\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Air\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Force\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "?\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Who was the Collector for the port of Pennsylvania in 1715?\n",
      "Who\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "was\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Collector\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "for\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "port\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "of\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Pennsylvania\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "in\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "1715\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "?\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      " When did the Estudiantina Figaro leave the US?\n",
      " \n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "When\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "did\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Estudiantina\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Figaro\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "leave\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "US\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "?\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "What is the most uncommon interpretation of the word \"ummi\" that the Quran applies to Muhammad?\n",
      "What\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "is\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "most\n",
      "['fewest']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "uncommon\n",
      "['common']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "interpretation\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "of\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "word\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\"\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "ummi\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\"\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "that\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "the\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Quran\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "applies\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "to\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Muhammad\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "?\n",
      "~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for q in random.sample(questions, 5):\n",
    "    print(q)\n",
    "    for tok in nlp(q):\n",
    "        print(tok)\n",
    "        ss = wn.synsets(tok.lemma_)\n",
    "        if ss:\n",
    "            #print(ss)\n",
    "            for l in ss[0].lemmas():\n",
    "                if l.antonyms():\n",
    "                    print(l.antonyms()[0].synset().lemma_names())\n",
    "        print(\"~\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slow']"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('fast')[3].lemmas()[0].antonyms()[0].synset().lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_all_hypernyms',\n",
       " '_definition',\n",
       " '_examples',\n",
       " '_frame_ids',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_iter_hypernym_lists',\n",
       " '_lemma_names',\n",
       " '_lemma_pointers',\n",
       " '_lemmas',\n",
       " '_lexname',\n",
       " '_max_depth',\n",
       " '_min_depth',\n",
       " '_name',\n",
       " '_needs_root',\n",
       " '_offset',\n",
       " '_pointers',\n",
       " '_pos',\n",
       " '_related',\n",
       " '_shortest_hypernym_paths',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'closure',\n",
       " 'common_hypernyms',\n",
       " 'definition',\n",
       " 'entailments',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'hypernym_distances',\n",
       " 'hypernym_paths',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'jcn_similarity',\n",
       " 'lch_similarity',\n",
       " 'lemma_names',\n",
       " 'lemmas',\n",
       " 'lexname',\n",
       " 'lin_similarity',\n",
       " 'lowest_common_hypernyms',\n",
       " 'max_depth',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'min_depth',\n",
       " 'name',\n",
       " 'offset',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'path_similarity',\n",
       " 'pos',\n",
       " 'region_domains',\n",
       " 'res_similarity',\n",
       " 'root_hypernyms',\n",
       " 'shortest_path_distance',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'topic_domains',\n",
       " 'tree',\n",
       " 'unicode_repr',\n",
       " 'usage_domains',\n",
       " 'verb_groups',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wn.synsets('fast')[3].lemmas()[0].antonyms()[0].synset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:allennlp.common.file_utils:https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz not found in cache, downloading to /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmppcopo7z3\n",
      "100%|██████████| 46175392/46175392 [00:17<00:00, 2675461.71B/s]\n",
      "INFO:allennlp.common.file_utils:copying /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmppcopo7z3 to cache at /Users/daniter/.allennlp/cache/6b2f329c57e41fb613be7e3538001f1f74dabceaf0a8562def91090fa652bef3.0b385ab2f40b25a4b2289de2798c8c7ffd779392f1b7a21a1f1ed81e49859300\n",
      "INFO:allennlp.common.file_utils:creating metadata file for /Users/daniter/.allennlp/cache/6b2f329c57e41fb613be7e3538001f1f74dabceaf0a8562def91090fa652bef3.0b385ab2f40b25a4b2289de2798c8c7ffd779392f1b7a21a1f1ed81e49859300\n",
      "INFO:allennlp.common.file_utils:removing temp file /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmppcopo7z3\n",
      "INFO:allennlp.models.archival:loading archive file https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz from cache at /Users/daniter/.allennlp/cache/6b2f329c57e41fb613be7e3538001f1f74dabceaf0a8562def91090fa652bef3.0b385ab2f40b25a4b2289de2798c8c7ffd779392f1b7a21a1f1ed81e49859300\n",
      "INFO:allennlp.models.archival:extracting archive file /Users/daniter/.allennlp/cache/6b2f329c57e41fb613be7e3538001f1f74dabceaf0a8562def91090fa652bef3.0b385ab2f40b25a4b2289de2798c8c7ffd779392f1b7a21a1f1ed81e49859300 to temp dir /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmpnrj9sfd2\n",
      "INFO:allennlp.common.params:type = default\n",
      "INFO:allennlp.data.vocabulary:Loading token dictionary from /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmpnrj9sfd2/vocabulary.\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': 0.2, 'modeling_layer': {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 800, 'num_layers': 2, 'type': 'lstm'}, 'num_highway_layers': 2, 'phrase_layer': {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 200, 'num_layers': 1, 'type': 'lstm'}, 'similarity_function': {'combination': 'x,y,x*y', 'tensor_1_dim': 200, 'tensor_2_dim': 200, 'type': 'linear'}, 'span_end_encoder': {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 1400, 'num_layers': 1, 'type': 'lstm'}, 'text_field_embedder': {'token_characters': {'dropout': 0.2, 'embedding': {'embedding_dim': 16, 'num_embeddings': 262}, 'encoder': {'embedding_dim': 16, 'ngram_filter_sizes': [5], 'num_filters': 100, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 100, 'trainable': False, 'type': 'embedding'}}, 'type': 'bidaf'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.type = bidaf\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow'> from params {'dropout': 0.2, 'modeling_layer': {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 800, 'num_layers': 2, 'type': 'lstm'}, 'num_highway_layers': 2, 'phrase_layer': {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 200, 'num_layers': 1, 'type': 'lstm'}, 'similarity_function': {'combination': 'x,y,x*y', 'tensor_1_dim': 200, 'tensor_2_dim': 200, 'type': 'linear'}, 'span_end_encoder': {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 1400, 'num_layers': 1, 'type': 'lstm'}, 'text_field_embedder': {'token_characters': {'dropout': 0.2, 'embedding': {'embedding_dim': 16, 'num_embeddings': 262}, 'encoder': {'embedding_dim': 16, 'ngram_filter_sizes': [5], 'num_filters': 100, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 100, 'trainable': False, 'type': 'embedding'}}} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_characters': {'dropout': 0.2, 'embedding': {'embedding_dim': 16, 'num_embeddings': 262}, 'encoder': {'embedding_dim': 16, 'ngram_filter_sizes': [5], 'num_filters': 100, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 100, 'trainable': False, 'type': 'embedding'}} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.type = basic\n",
      "INFO:allennlp.common.params:model.text_field_embedder.embedder_to_indexer_map = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.allow_unmatched_keys = False\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders = None\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'dropout': 0.2, 'embedding': {'embedding_dim': 16, 'num_embeddings': 262}, 'encoder': {'embedding_dim': 16, 'ngram_filter_sizes': [5], 'num_filters': 100, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.type = character_encoding\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.num_embeddings = 262\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.vocab_namespace = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.embedding_dim = 16\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.pretrained_file = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.projection_dim = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.trainable = True\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.padding_index = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.max_norm = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.norm_type = 2.0\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.scale_grad_by_freq = False\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.embedding.sparse = False\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 16, 'ngram_filter_sizes': [5], 'num_filters': 100, 'type': 'cnn'} and extras {}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.encoder.type = cnn\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'embedding_dim': 16, 'ngram_filter_sizes': [5], 'num_filters': 100} and extras {}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.encoder.embedding_dim = 16\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.encoder.num_filters = 100\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.encoder.ngram_filter_sizes = [5]\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.encoder.output_dim = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_characters.dropout = 0.2\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 100, 'trainable': False, 'type': 'embedding'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.type = embedding\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.num_embeddings = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.vocab_namespace = tokens\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.embedding_dim = 100\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.pretrained_file = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.projection_dim = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.trainable = False\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.padding_index = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.max_norm = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.norm_type = 2.0\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.scale_grad_by_freq = False\n",
      "INFO:allennlp.common.params:model.text_field_embedder.tokens.sparse = False\n",
      "INFO:allennlp.common.params:model.num_highway_layers = 2\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 200, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.phrase_layer.type = lstm\n",
      "INFO:allennlp.common.params:model.phrase_layer.batch_first = True\n",
      "INFO:allennlp.common.params:model.phrase_layer.stateful = False\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "INFO:allennlp.common.params:model.phrase_layer.bidirectional = True\n",
      "INFO:allennlp.common.params:model.phrase_layer.dropout = 0.2\n",
      "INFO:allennlp.common.params:model.phrase_layer.hidden_size = 100\n",
      "INFO:allennlp.common.params:model.phrase_layer.input_size = 200\n",
      "INFO:allennlp.common.params:model.phrase_layer.num_layers = 1\n",
      "INFO:allennlp.common.params:model.phrase_layer.batch_first = True\n",
      "/Users/daniter/anaconda3/envs/allen/lib/python3.7/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.similarity_functions.similarity_function.SimilarityFunction'> from params {'combination': 'x,y,x*y', 'tensor_1_dim': 200, 'tensor_2_dim': 200, 'type': 'linear'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.similarity_function.type = linear\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.similarity_functions.linear.LinearSimilarity'> from params {'combination': 'x,y,x*y', 'tensor_1_dim': 200, 'tensor_2_dim': 200} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.similarity_function.tensor_1_dim = 200\n",
      "INFO:allennlp.common.params:model.similarity_function.tensor_2_dim = 200\n",
      "INFO:allennlp.common.params:model.similarity_function.combination = x,y,x*y\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 800, 'num_layers': 2, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.modeling_layer.type = lstm\n",
      "INFO:allennlp.common.params:model.modeling_layer.batch_first = True\n",
      "INFO:allennlp.common.params:model.modeling_layer.stateful = False\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "INFO:allennlp.common.params:model.modeling_layer.bidirectional = True\n",
      "INFO:allennlp.common.params:model.modeling_layer.dropout = 0.2\n",
      "INFO:allennlp.common.params:model.modeling_layer.hidden_size = 100\n",
      "INFO:allennlp.common.params:model.modeling_layer.input_size = 800\n",
      "INFO:allennlp.common.params:model.modeling_layer.num_layers = 2\n",
      "INFO:allennlp.common.params:model.modeling_layer.batch_first = True\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.2, 'hidden_size': 100, 'input_size': 1400, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 97914 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "INFO:allennlp.common.params:model.span_end_encoder.type = lstm\n",
      "INFO:allennlp.common.params:model.span_end_encoder.batch_first = True\n",
      "INFO:allennlp.common.params:model.span_end_encoder.stateful = False\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "INFO:allennlp.common.params:model.span_end_encoder.bidirectional = True\n",
      "INFO:allennlp.common.params:model.span_end_encoder.dropout = 0.2\n",
      "INFO:allennlp.common.params:model.span_end_encoder.hidden_size = 100\n",
      "INFO:allennlp.common.params:model.span_end_encoder.input_size = 1400\n",
      "INFO:allennlp.common.params:model.span_end_encoder.num_layers = 1\n",
      "INFO:allennlp.common.params:model.span_end_encoder.batch_first = True\n",
      "INFO:allennlp.common.params:model.dropout = 0.2\n",
      "INFO:allennlp.common.params:model.mask_lstms = True\n",
      "INFO:allennlp.nn.initializers:Initializing parameters\n",
      "INFO:allennlp.nn.initializers:Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.0.bias\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.0.weight\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.1.bias\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.1.weight\n",
      "INFO:allennlp.nn.initializers:   _matrix_attention._similarity_function._bias\n",
      "INFO:allennlp.nn.initializers:   _matrix_attention._similarity_function._weight_vector\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.bias_ih_l0_reverse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _span_end_encoder._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _span_end_predictor._module.bias\n",
      "INFO:allennlp.nn.initializers:   _span_end_predictor._module.weight\n",
      "INFO:allennlp.nn.initializers:   _span_start_predictor._module.bias\n",
      "INFO:allennlp.nn.initializers:   _span_start_predictor._module.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_token_characters._embedding._module.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_tokens.weight\n",
      "INFO:root:Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'token_characters': {'character_tokenizer': {'byte_encoding': 'utf-8', 'end_tokens': [260, 0, 0, 0, 0, 0], 'start_tokens': [259]}, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'squad'} and extras {}\n",
      "INFO:allennlp.common.params:dataset_reader.type = squad\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.dataset_readers.reading_comprehension.squad.SquadReader'> from params {'token_indexers': {'token_characters': {'character_tokenizer': {'byte_encoding': 'utf-8', 'end_tokens': [260, 0, 0, 0, 0, 0], 'start_tokens': [259]}, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras {}\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'character_tokenizer': {'byte_encoding': 'utf-8', 'end_tokens': [260, 0, 0, 0, 0, 0], 'start_tokens': [259]}, 'type': 'characters'} and extras {}\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.type = characters\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'character_tokenizer': {'byte_encoding': 'utf-8', 'end_tokens': [260, 0, 0, 0, 0, 0], 'start_tokens': [259]}} and extras {}\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.namespace = token_characters\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer'> from params {'byte_encoding': 'utf-8', 'end_tokens': [260, 0, 0, 0, 0, 0], 'start_tokens': [259]} and extras {}\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.byte_encoding = utf-8\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.lowercase_characters = False\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.start_tokens = [259]\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.end_tokens = [260, 0, 0, 0, 0, 0]\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.start_tokens = None\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.end_tokens = None\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.min_padding_length = 0\n",
      "/Users/daniter/anaconda3/envs/allen/lib/python3.7/site-packages/allennlp/data/token_indexers/token_characters_indexer.py:51: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  UserWarning)\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'lowercase_tokens': True, 'type': 'single_id'} and extras {}\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.type = single_id\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer'> from params {'lowercase_tokens': True} and extras {}\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.namespace = tokens\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.lowercase_tokens = True\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.start_tokens = None\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.end_tokens = None\n",
      "INFO:allennlp.common.params:dataset_reader.lazy = False\n",
      "INFO:allennlp.common.params:dataset_reader.passage_length_limit = None\n",
      "INFO:allennlp.common.params:dataset_reader.question_length_limit = None\n",
      "INFO:allennlp.common.params:dataset_reader.skip_invalid_examples = False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'passage_question_attention': [[0.2332495003938675,\n",
       "   0.13020572066307068,\n",
       "   0.05738387629389763,\n",
       "   0.4639679491519928,\n",
       "   0.07980171591043472,\n",
       "   0.03539126738905907],\n",
       "  [0.022366061806678772,\n",
       "   0.041481345891952515,\n",
       "   0.004440483637154102,\n",
       "   0.010942183434963226,\n",
       "   0.9152997136116028,\n",
       "   0.0054702130146324635],\n",
       "  [0.4210350513458252,\n",
       "   0.14624372124671936,\n",
       "   0.1435588300228119,\n",
       "   0.04770353436470032,\n",
       "   0.06846389174461365,\n",
       "   0.17299500107765198],\n",
       "  [0.41911062598228455,\n",
       "   0.22678565979003906,\n",
       "   0.1360650211572647,\n",
       "   0.09948630630970001,\n",
       "   0.03831887245178223,\n",
       "   0.08023352175951004],\n",
       "  [0.3584285080432892,\n",
       "   0.24447961151599884,\n",
       "   0.14123569428920746,\n",
       "   0.05731037259101868,\n",
       "   0.04445306584239006,\n",
       "   0.15409281849861145],\n",
       "  [0.38292989134788513,\n",
       "   0.2086879014968872,\n",
       "   0.18444578349590302,\n",
       "   0.04652712121605873,\n",
       "   0.05981538072228432,\n",
       "   0.11759379506111145],\n",
       "  [0.2734203040599823,\n",
       "   0.43692219257354736,\n",
       "   0.12022325396537781,\n",
       "   0.05061645060777664,\n",
       "   0.04319247603416443,\n",
       "   0.07562530040740967],\n",
       "  [0.38028809428215027,\n",
       "   0.22147662937641144,\n",
       "   0.1514977067708969,\n",
       "   0.04230892285704613,\n",
       "   0.06067905202507973,\n",
       "   0.14374954998493195],\n",
       "  [0.20701520144939423,\n",
       "   0.6529343128204346,\n",
       "   0.05335557833313942,\n",
       "   0.030425921082496643,\n",
       "   0.01688573509454727,\n",
       "   0.03938324749469757],\n",
       "  [0.3757022023200989,\n",
       "   0.4054017663002014,\n",
       "   0.11001678556203842,\n",
       "   0.030622372403740883,\n",
       "   0.012740373611450195,\n",
       "   0.06551644951105118],\n",
       "  [0.3762320578098297,\n",
       "   0.30895861983299255,\n",
       "   0.1288117915391922,\n",
       "   0.03828492388129234,\n",
       "   0.043564703315496445,\n",
       "   0.10414791852235794],\n",
       "  [0.23995651304721832,\n",
       "   0.5173619389533997,\n",
       "   0.14735373854637146,\n",
       "   0.02119225449860096,\n",
       "   0.030748846009373665,\n",
       "   0.04338667914271355],\n",
       "  [0.5362122654914856,\n",
       "   0.22999195754528046,\n",
       "   0.13562169671058655,\n",
       "   0.03991175815463066,\n",
       "   0.01448744349181652,\n",
       "   0.043774865567684174],\n",
       "  [0.39066681265830994,\n",
       "   0.1639799177646637,\n",
       "   0.08167308568954468,\n",
       "   0.2545568645000458,\n",
       "   0.06439410150051117,\n",
       "   0.04472923278808594],\n",
       "  [0.5753822326660156,\n",
       "   0.17080940306186676,\n",
       "   0.09764169901609421,\n",
       "   0.048742931336164474,\n",
       "   0.028262760490179062,\n",
       "   0.07916092127561569],\n",
       "  [0.46991047263145447,\n",
       "   0.215935617685318,\n",
       "   0.13028644025325775,\n",
       "   0.028421608731150627,\n",
       "   0.022220822051167488,\n",
       "   0.1332249790430069],\n",
       "  [0.0858984887599945,\n",
       "   0.814933180809021,\n",
       "   0.058611150830984116,\n",
       "   0.012726872228085995,\n",
       "   0.013628118671476841,\n",
       "   0.014202198944985867],\n",
       "  [0.46810483932495117,\n",
       "   0.21825282275676727,\n",
       "   0.14365920424461365,\n",
       "   0.06745883077383041,\n",
       "   0.0262183528393507,\n",
       "   0.07630602270364761],\n",
       "  [0.5294859409332275,\n",
       "   0.32860496640205383,\n",
       "   0.057414889335632324,\n",
       "   0.03020152635872364,\n",
       "   0.024775952100753784,\n",
       "   0.02951677516102791],\n",
       "  [0.504204273223877,\n",
       "   0.24159002304077148,\n",
       "   0.10108640044927597,\n",
       "   0.033121541142463684,\n",
       "   0.018227217718958855,\n",
       "   0.10177057236433029],\n",
       "  [0.4753439128398895,\n",
       "   0.3484322428703308,\n",
       "   0.05208754539489746,\n",
       "   0.04740211367607117,\n",
       "   0.03449329361319542,\n",
       "   0.042240824550390244],\n",
       "  [0.46683210134506226,\n",
       "   0.2324444204568863,\n",
       "   0.14504462480545044,\n",
       "   0.04767437279224396,\n",
       "   0.025548141449689865,\n",
       "   0.08245634287595749],\n",
       "  [0.45386284589767456,\n",
       "   0.26022276282310486,\n",
       "   0.11508559435606003,\n",
       "   0.033375825732946396,\n",
       "   0.020926177501678467,\n",
       "   0.11652681976556778],\n",
       "  [0.2768806219100952,\n",
       "   0.467685341835022,\n",
       "   0.14218202233314514,\n",
       "   0.058773718774318695,\n",
       "   0.023659348487854004,\n",
       "   0.03081902116537094],\n",
       "  [0.33605656027793884,\n",
       "   0.3249633014202118,\n",
       "   0.12654466927051544,\n",
       "   0.07307291775941849,\n",
       "   0.0530836395919323,\n",
       "   0.08627894520759583],\n",
       "  [0.39453914761543274,\n",
       "   0.40092790126800537,\n",
       "   0.07611125707626343,\n",
       "   0.037632688879966736,\n",
       "   0.02702946774661541,\n",
       "   0.06375959515571594],\n",
       "  [0.42709070444107056,\n",
       "   0.3307698369026184,\n",
       "   0.09292299300432205,\n",
       "   0.036885302513837814,\n",
       "   0.04790489375591278,\n",
       "   0.06442629545927048],\n",
       "  [0.41639620065689087,\n",
       "   0.29000425338745117,\n",
       "   0.11744493991136551,\n",
       "   0.04312222823500633,\n",
       "   0.019891509786248207,\n",
       "   0.11314087361097336],\n",
       "  [0.34833818674087524,\n",
       "   0.44272366166114807,\n",
       "   0.08012454211711884,\n",
       "   0.06688601523637772,\n",
       "   0.013647161424160004,\n",
       "   0.04828045144677162],\n",
       "  [0.16671594977378845,\n",
       "   0.3693898022174835,\n",
       "   0.1716020703315735,\n",
       "   0.05465523526072502,\n",
       "   0.14880810678005219,\n",
       "   0.08882879465818405],\n",
       "  [0.4178599417209625,\n",
       "   0.2066992223262787,\n",
       "   0.1609138548374176,\n",
       "   0.042814988642930984,\n",
       "   0.021052569150924683,\n",
       "   0.1506595015525818],\n",
       "  [0.3391202986240387,\n",
       "   0.30233290791511536,\n",
       "   0.16754677891731262,\n",
       "   0.03853306174278259,\n",
       "   0.04089030623435974,\n",
       "   0.11157658696174622],\n",
       "  [0.42356443405151367,\n",
       "   0.3913770020008087,\n",
       "   0.06196532025933266,\n",
       "   0.06772445142269135,\n",
       "   0.016300564631819725,\n",
       "   0.03906828165054321],\n",
       "  [0.43833544850349426,\n",
       "   0.25936275720596313,\n",
       "   0.12661392986774445,\n",
       "   0.04813048243522644,\n",
       "   0.03326721861958504,\n",
       "   0.09429024904966354],\n",
       "  [0.3788672983646393,\n",
       "   0.21498353779315948,\n",
       "   0.14707235991954803,\n",
       "   0.018567074090242386,\n",
       "   0.023097755387425423,\n",
       "   0.21741196513175964]],\n",
       " 'span_start_logits': [-5.953884124755859,\n",
       "  -8.586532592773438,\n",
       "  -10.135902404785156,\n",
       "  -8.620035171508789,\n",
       "  -6.538768768310547,\n",
       "  -6.87559700012207,\n",
       "  -7.628232955932617,\n",
       "  -6.9283294677734375,\n",
       "  -5.371942520141602,\n",
       "  -4.803886890411377,\n",
       "  -6.992992401123047,\n",
       "  -4.278493881225586,\n",
       "  -2.577834129333496,\n",
       "  2.7175984382629395,\n",
       "  0.811732292175293,\n",
       "  -3.326984405517578,\n",
       "  1.5627280473709106,\n",
       "  6.507514476776123,\n",
       "  2.078734874725342,\n",
       "  -4.025775909423828,\n",
       "  1.0333174467086792,\n",
       "  -2.778010368347168,\n",
       "  -5.054042339324951,\n",
       "  1.3354295492172241,\n",
       "  -5.0851287841796875,\n",
       "  -1.8765974044799805,\n",
       "  -2.060133934020996,\n",
       "  -5.716587066650391,\n",
       "  -0.47243189811706543,\n",
       "  -4.1644062995910645,\n",
       "  -5.429741859436035,\n",
       "  -4.0580291748046875,\n",
       "  2.4887351989746094,\n",
       "  -3.0644073486328125,\n",
       "  -4.27820348739624],\n",
       " 'span_start_probs': [3.60407625521475e-06,\n",
       "  2.590891767795256e-07,\n",
       "  5.502581501559689e-08,\n",
       "  2.5055280161723203e-07,\n",
       "  2.008083583859843e-06,\n",
       "  1.433834881936491e-06,\n",
       "  6.755126946700329e-07,\n",
       "  1.3601843420474324e-06,\n",
       "  6.449528882512823e-06,\n",
       "  1.1382342563592829e-05,\n",
       "  1.275014142265718e-06,\n",
       "  1.9248936951044016e-05,\n",
       "  0.00010543729877099395,\n",
       "  0.02102670446038246,\n",
       "  0.0031265404541045427,\n",
       "  4.9847341870190576e-05,\n",
       "  0.006625479087233543,\n",
       "  0.930488109588623,\n",
       "  0.011099829338490963,\n",
       "  2.478339047229383e-05,\n",
       "  0.0039020904805511236,\n",
       "  8.630955562693998e-05,\n",
       "  8.863198672770523e-06,\n",
       "  0.00527840806171298,\n",
       "  8.591909136157483e-06,\n",
       "  0.00021258738706819713,\n",
       "  0.00017694105918053538,\n",
       "  4.569311840896262e-06,\n",
       "  0.000865682668518275,\n",
       "  2.1575184291577898e-05,\n",
       "  6.0873248912685085e-06,\n",
       "  2.3996797608560883e-05,\n",
       "  0.01672542653977871,\n",
       "  6.481534364866093e-05,\n",
       "  1.925453580042813e-05],\n",
       " 'span_end_logits': [-9.945730209350586,\n",
       "  -7.664916515350342,\n",
       "  -12.830272674560547,\n",
       "  -13.46401596069336,\n",
       "  -9.577171325683594,\n",
       "  -11.889190673828125,\n",
       "  -10.717411041259766,\n",
       "  -11.042154312133789,\n",
       "  -10.707710266113281,\n",
       "  -10.720155715942383,\n",
       "  -13.018817901611328,\n",
       "  -12.035852432250977,\n",
       "  -12.693790435791016,\n",
       "  -10.399894714355469,\n",
       "  -3.2795748710632324,\n",
       "  -9.449384689331055,\n",
       "  -10.865655899047852,\n",
       "  -7.539453029632568,\n",
       "  -2.2614214420318604,\n",
       "  -6.141225814819336,\n",
       "  -6.705333709716797,\n",
       "  -1.816023826599121,\n",
       "  -4.1802592277526855,\n",
       "  -7.49323034286499,\n",
       "  -8.971895217895508,\n",
       "  -6.12739896774292,\n",
       "  -1.221642017364502,\n",
       "  -5.761321067810059,\n",
       "  -2.9145925045013428,\n",
       "  -1.8542823791503906,\n",
       "  -5.335267066955566,\n",
       "  -7.927475452423096,\n",
       "  -3.9228224754333496,\n",
       "  2.782109260559082,\n",
       "  0.44113409519195557],\n",
       " 'span_end_probs': [2.5813424144871533e-06,\n",
       "  2.5257513698306866e-05,\n",
       "  1.442463144485373e-07,\n",
       "  7.653743949731506e-08,\n",
       "  3.731716560650966e-06,\n",
       "  3.696676174058666e-07,\n",
       "  1.1931880408155848e-06,\n",
       "  8.623322855783044e-07,\n",
       "  1.204819113809208e-06,\n",
       "  1.1899174978680094e-06,\n",
       "  1.1945947164804238e-07,\n",
       "  3.192398310147837e-07,\n",
       "  1.653401113799191e-07,\n",
       "  1.6390961263823556e-06,\n",
       "  0.002027309499680996,\n",
       "  4.240388989273924e-06,\n",
       "  1.0287905070072156e-06,\n",
       "  2.8633781766984612e-05,\n",
       "  0.005611753556877375,\n",
       "  0.00011590998474275693,\n",
       "  6.593741272808984e-05,\n",
       "  0.00876056682318449,\n",
       "  0.0008236786816269159,\n",
       "  2.9988375899847597e-05,\n",
       "  6.835601197963115e-06,\n",
       "  0.00011752384307328612,\n",
       "  0.015873363241553307,\n",
       "  0.00016947723634075373,\n",
       "  0.0029203156009316444,\n",
       "  0.008431730791926384,\n",
       "  0.00025950412964448333,\n",
       "  1.9425056962063536e-05,\n",
       "  0.0010655189398676157,\n",
       "  0.8699133992195129,\n",
       "  0.08371502161026001],\n",
       " 'best_span': [17, 33],\n",
       " 'best_span_str': 'Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano',\n",
       " 'question_tokens': ['Who', 'stars', 'in', 'The', 'Matrix', '?'],\n",
       " 'passage_tokens': ['The',\n",
       "  'Matrix',\n",
       "  'is',\n",
       "  'a',\n",
       "  '1999',\n",
       "  'science',\n",
       "  'fiction',\n",
       "  'action',\n",
       "  'film',\n",
       "  'written',\n",
       "  'and',\n",
       "  'directed',\n",
       "  'by',\n",
       "  'The',\n",
       "  'Wachowskis',\n",
       "  ',',\n",
       "  'starring',\n",
       "  'Keanu',\n",
       "  'Reeves',\n",
       "  ',',\n",
       "  'Laurence',\n",
       "  'Fishburne',\n",
       "  ',',\n",
       "  'Carrie',\n",
       "  '-',\n",
       "  'Anne',\n",
       "  'Moss',\n",
       "  ',',\n",
       "  'Hugo',\n",
       "  'Weaving',\n",
       "  ',',\n",
       "  'and',\n",
       "  'Joe',\n",
       "  'Pantoliano',\n",
       "  '.']}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz\")\n",
    "predictor.predict(\n",
    "  passage=\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\",\n",
    "  question=\"Who stars in The Matrix?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['passage_question_attention', 'span_start_logits', 'span_start_probs', 'span_end_logits', 'span_end_probs', 'best_span', 'best_span_str', 'question_tokens', 'passage_tokens'])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(\n",
    "  passage=\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\",\n",
    "  question=\"Who stars in The Matrix?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2332495003938675,\n",
       " 0.13020572066307068,\n",
       " 0.05738387629389763,\n",
       " 0.4639679491519928,\n",
       " 0.07980171591043472,\n",
       " 0.03539126738905907]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"passage_question_attention\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['passage_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage=\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\"\n",
    "len(passage.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five Great Lakes are located in the north-central portion of the country, four of them forming part of the border with Canada, only Lake Michigan situated entirely within United States. The southeast United States contain subtropical forests and, near the gulf coast, mangrove wetlands, especially in Florida. West of the Appalachians lies the Mississippi River basin and two large eastern tributaries, the Ohio River and the Tennessee River. The Ohio and Tennessee Valleys and the Midwest consist largely of rolling hills and productive farmland, stretching south to the Gulf Coast.\n",
      "Which major river is located east of the Appalachian Mountains\n"
     ]
    }
   ],
   "source": [
    "for c,q in examples:\n",
    "    context = contexts[c]\n",
    "    question = questions[q]\n",
    "    if ' east ' in question and ' river ' in question and \"Appalachian Mountains\" in question:\n",
    "        print(context)\n",
    "        print (question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- get attention for all squad  \n",
    "- find all antonyms and do adversarial training\n",
    "- use bertscore for paraphrasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x log-odds of words  \n",
    "x import wordnet and find antonyms  \n",
    "x look at 'of' in edge words  \n",
    "look at adversarial training (teach model opposites / alternative nouns/entities)   \n",
    "copy model (given mask, predict if it's copied and if so, just do span match)  \n",
    "make coverage + precision map  \n",
    " \n",
    "train new model w/ adversarial  \n",
    "train model with new mask feature  \n",
    "train model with copy feature and distribution  \n",
    "think about how we can determine if someting is a surprise vs a paraphrase?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the mid 17th century, after the English Civil War (1642–1651), Parliament strengthened its position relative to the monarch then gained more power through the Glorious Revolution of 1688 and passage of the Bill of Rights in 1689. The monarch could no longer establish any law or impose any tax without its permission and thus the House of Commons became a part of the government. It is at this point that a modern style of prime minister begins to emerge.\n",
      "From 1721 this was the Whig politician Robert Walpole, who held office for twenty-one years. Walpole chaired cabinet meetings, appointed all the other ministers, dispensed the royal patronage and packed the House of Commons with his supporters. Under Walpole, the doctrine of cabinet solidarity developed. Walpole required that no minister other than himself have private dealings with the king, and also that when the cabinet had agreed on a policy, all ministers must defend it in public, or resign. As a later prime minister, Lord Melbourne, said, \"It matters not what we say, gentlemen, so long as we all say the same thing.\"\n",
      "Most prime ministers in parliamentary systems are not appointed for a specific term in office and in effect may remain in power through a number of elections and parliaments. For example, Margaret Thatcher was only ever appointed prime minister on one occasion, in 1979. She remained continuously in power until 1990, though she used the assembly of each House of Commons after a general election to reshuffle her cabinet.\n",
      "The Canadian constitution determines that the Commander-in-Chief of the Canadian Armed Forces is the country's sovereign, who, since 1904, has authorized his or her viceroy, the governor general, to exercise the duties ascribed to the post of Commander-in-Chief and to hold the associated title since 1905. All troop deployment and disposition orders, including declarations of war, fall within the royal prerogative and are issued as Orders in Council, which must be signed by either the monarch or governor general. Under the Westminster system's parliamentary customs and practices, however, the monarch and viceroy must generally follow the advice of his or her ministers in Cabinet, including the prime minister and minister of national defence, who are accountable to the elected House of Commons.\n",
      "Strict separation of powers did not operate in The United Kingdom, the political structure of which served in most instances[citation needed] as a model for the government created by the U.S. Constitution.[citation needed] Under the UK Westminster system, based on parliamentary sovereignty and responsible government, Parliament (consisting of the Sovereign (King-in-Parliament), House of Lords and House of Commons) was the supreme lawmaking authority. The executive branch acted in the name of the King (\"His Majesty's Government\"), as did the judiciary. The King's Ministers were in most cases members of one of the two Houses of Parliament, and the Government needed to sustain the support of a majority in the House of Commons. One minister, the Lord Chancellor, was at the same time the sole judge in the Court of Chancery and the presiding officer in the House of Lords. Therefore, it may be seen that the three branches of British government often violated the strict principle of separation of powers, even though there were many occasions when the different branches of the government disagreed with each other. Some U.S. states did not observe a strict separation of powers in the 18th century. In New Jersey, the Governor also functioned as a member of the state's highest court and as the presiding officer of one house of the New Jersey Legislature. The President of Delaware was a member of the Court of Appeals; the presiding officers of the two houses of the state legislature also served in the executive department as Vice Presidents. In both Delaware and Pennsylvania, members of the executive council served at the same time as judges. On the other hand, many southern states explicitly required separation of powers. Maryland, Virginia, North Carolina and Georgia all kept the branches of government \"separate and distinct.\"\n",
      "Modern DST was first proposed by the New Zealand entomologist George Hudson, whose shift-work job gave him leisure time to collect insects, and led him to value after-hours daylight. In 1895 he presented a paper to the Wellington Philosophical Society proposing a two-hour daylight-saving shift, and after considerable interest was expressed in Christchurch, he followed up in an 1898 paper. Many publications credit DST's proposal to the prominent English builder and outdoorsman William Willett, who independently conceived DST in 1905 during a pre-breakfast ride, when he observed with dismay how many Londoners slept through a large part of a summer's day. An avid golfer, he also disliked cutting short his round at dusk. His solution was to advance the clock during the summer months, a proposal he published two years later. The proposal was taken up by the Liberal Member of Parliament (MP) Robert Pearce, who introduced the first Daylight Saving Bill to the House of Commons on 12 February 1908. A select committee was set up to examine the issue, but Pearce's bill did not become law, and several other bills failed in the following years. Willett lobbied for the proposal in the UK until his death in 1915.\n",
      "Westminster Abbey is a collegiate church governed by the Dean and Chapter of Westminster, as established by Royal charter of Queen Elizabeth I in 1560, which created it as the Collegiate Church of St Peter Westminster and a Royal Peculiar under the personal jurisdiction of the Sovereign. The members of the Chapter are the Dean and four canons residentiary, assisted by the Receiver General and Chapter Clerk. One of the canons is also Rector of St Margaret's Church, Westminster, and often holds also the post of Chaplain to the Speaker of the House of Commons.\n",
      "Between 1941 and 1946, the left-wing British historian E.H. Carr was Assistant Editor. Carr was well known for the strongly pro-Soviet tone of his editorials. In December 1944, when fighting broke out in Athens between the Greek Communist ELAS and the British Army, Carr in a Times editorial sided with the Communists, leading Winston Churchill to condemn him and that leader in a speech to the House of Commons. As a result of Carr's editorial, The Times became popularly known during that stage of World War II as the threepenny Daily Worker (the price of the Daily Worker being one penny).\n",
      "Through Victoria's reign, the gradual establishment of a modern constitutional monarchy in Britain continued. Reforms of the voting system increased the power of the House of Commons at the expense of the House of Lords and the monarch. In 1867, Walter Bagehot wrote that the monarch only retained \"the right to be consulted, the right to encourage, and the right to warn\". As Victoria's monarchy became more symbolic than political, it placed a strong emphasis on morality and family values, in contrast to the sexual, financial and personal scandals that had been associated with previous members of the House of Hanover and which had discredited the monarchy. The concept of the \"family monarchy\", with which the burgeoning middle classes could identify, was solidified.\n",
      "For years Burke pursued impeachment efforts against Warren Hastings, formerly Governor-General of Bengal, that resulted in the trial during 1786. His interaction with the British dominion of India began well before Hastings' impeachment trial. For two decades prior to the impeachment, Parliament had dealt with the Indian issue. This trial was the pinnacle of years of unrest and deliberation. In 1781 Burke was first able to delve into the issues surrounding the East India Company when he was appointed Chairman of the Commons Select Committee on East Indian Affairs—from that point until the end of the trial; India was Burke's primary concern. This committee was charged \"to investigate alleged injustices in Bengal, the war with Hyder Ali, and other Indian difficulties\". While Burke and the committee focused their attention on these matters, a second 'secret' committee was formed to assess the same issues. Both committee reports were written by Burke. Among other purposes, the reports conveyed to the Indian princes that Britain would not wage war on them, along with demanding that the HEIC recall Hastings. This was Burke's first call for substantive change regarding imperial practices. When addressing the whole House of Commons regarding the committee report, Burke described the Indian issue as one that \"began 'in commerce' but 'ended in empire.'\"\n",
      "On 4 April 1786, Burke presented the Commons with the Article of Charge of High Crimes and Misdemeanors against Hastings. The impeachment in Westminster Hall, which did not begin until 14 February 1788, would be the \"first major public discursive event of its kind in England\", bringing the morality and duty of imperialism to the forefront of public perception. Burke already was known for his eloquent rhetorical skills and his involvement in the trial only enhanced its popularity and significance. Burke's indictment, fuelled by emotional indignation, branded Hastings a 'captain-general of iniquity'; who never dined without 'creating a famine'; whose heart was 'gangrened to the core', and who resembled both a 'spider of Hell' and a 'ravenous vulture devouring the carcasses of the dead'. The House of Commons eventually impeached Hastings, but subsequently, the House of Lords acquitted him of all charges.\n",
      "In the nineteenth century Burke was praised by both liberals and conservatives. Burke's friend Philip Francis wrote that Burke \"was a man who truly & prophetically foresaw all the consequences which would rise from the adoption of the French principles\" but because Burke wrote with so much passion, people were doubtful of his arguments. William Windham spoke from the same bench in the House of Commons as Burke had, when he had separated from Fox, and an observer said Windham spoke \"like the ghost of Burke\" when he made a speech against peace with France in 1801. William Hazlitt, a political opponent of Burke, regarded him as amongst his three favourite writers (the others being Junius and Rousseau), and made it \"a test of the sense and candour of any one belonging to the opposite party, whether he allowed Burke to be a great man\". William Wordsworth was originally a supporter of the French Revolution and attacked Burke in 'A Letter to the Bishop of Llandaff' (1793), but by the early nineteenth century he had changed his mind and came to admire Burke. In his Two Addresses to the Freeholders of Westmorland Wordsworth called Burke \"the most sagacious Politician of his age\" whose predictions \"time has verified\". He later revised his poem The Prelude to include praise of Burke (\"Genius of Burke! forgive the pen seduced/By specious wonders\") and portrayed him as an old oak. Samuel Taylor Coleridge came to have a similar conversion: he had criticised Burke in The Watchman, but in his Friend (1809–10) Coleridge defended Burke from charges of inconsistency. Later, in his Biographia Literaria (1817) Coleridge hails Burke as a prophet and praises Burke for referring \"habitually to principles. He was a scientific statesman; and therefore a seer\". Henry Brougham wrote of Burke: \"... all his predictions, save one momentary expression, had been more than fulfilled: anarchy and bloodshed had borne sway in France; conquest and convulsion had desolated Europe...the providence of mortals is not often able to penetrate so far as this into futurity\". George Canning believed that Burke's Reflections \"has been justified by the course of subsequent events; and almost every prophecy has been strictly fulfilled\". In 1823 Canning wrote that he took Burke's \"last works and words [as] the manual of my politics\". The Conservative Prime Minister Benjamin Disraeli \"was deeply penetrated with the spirit and sentiment of Burke's later writings\".\n",
      "In February 1853, the British government of Lord Aberdeen, the prime minister, re-appointed Stratford Canning as British ambassador to the Ottoman Empire.:110 Having resigned the ambassadorship in January, he had been replaced by Colonel Rose as chargé d'affaires. Lord Stratford then turned around and sailed back to Constantinople, arriving there on 5 April 1853. There he convinced the Sultan to reject the Russian treaty proposal, as compromising the independence of the Turks. The Leader of the Opposition in the British House of Commons, Benjamin Disraeli, blamed Aberdeen and Stratford's actions for making war inevitable, thus starting the process which would eventually force the Aberdeen government to resign in January 1855, over the war.\n",
      "On February 18, 2015, Canadian Transport Minister Lisa Raitt announced that Canada has agreed to pay the entire cost to build a $250 million U.S. Customs plaza adjacent to the planned new Detroit–Windsor bridge, now the Gordie Howe International Bridge. Canada had already planned to pay for 95 per cent of the bridge, which will cost $2.1 billion, and is expected to open in 2020. \"This allows Canada and Michigan to move the project forward immediately to its next steps which include further design work and property acquisition on the U.S. side of the border,\" Raitt said in a statement issued after she spoke in the House of Commons. \n",
      "Originally, legislative power was exercised by the sovereign acting on the advice of the Curia Regis, or Royal Council, in which important magnates and clerics participated and which evolved into parliament. The so-called Model Parliament included bishops, abbots, earls, barons, and two knights from each shire and two burgesses from each borough among its members. In 1265, the Earl of Leicester irregularly called a full parliament without royal authorisation. The body eventually came to be divided into two branches: bishops, abbots, earls, and barons formed the House of Lords, while the shire and borough representatives formed the House of Commons. The King would seek the advice and consent of both houses before making any law. During Henry VI's reign, it became regular practice for the two houses to originate legislation in the form of bills, which would not become law unless the sovereign's assent was obtained, as the sovereign was, and still remains, the enactor of laws. Hence, all acts include the clause \"Be it enacted by the Queen's (King's) most Excellent Majesty, by and with the advice and consent of the Lords Spiritual and Temporal, and Commons, in this present Parliament assembled, and by the authority of the same, as follows...\". The Parliament Acts 1911 and 1949 provide a second potential preamble if the House of Lords were to be excluded from the process.\n",
      "If the Governor General of Canada is unable to give assent, it can be done by either the Deputy of the Governor General of Canada—the Chief Justice of Canada—or another justice of the Supreme Court of Canada. It is not actually necessary for the governor general to sign a bill passed by a legislature, the signature being merely an attestation. In each case, the parliament must be apprised of the granting of assent before the bill is considered to have become law. Two methods are available: the sovereign's representatives may grant assent in the presence of both houses of parliament; alternatively, each house may be notified separately, usually by the speaker of that house. However, though both houses must be notified on the same day, notice to the House of Commons while it is not in session may be given by way of publishing a special issue of the Journals of the House of Commons, whereas the Senate must be sitting and the governor general's letter read aloud by the speaker.\n",
      "In the United Kingdom, a bill is presented for royal assent after it has passed all the required stages in both the House of Commons and the House of Lords. Under the Parliament Acts 1911 and 1949, the House of Commons may, under certain circumstances, direct that a bill be presented for assent despite lack of passage by the House of Lords. Officially, assent is granted by the sovereign or by Lords Commissioners authorised to act by letters patent. It may be granted in parliament or outside parliament; in the latter case, each house must be separately notified before the bill takes effect.\n",
      "During the 1960s, the ceremony of assenting by commission was discontinued and is now only employed once a year, at the end of the annual parliamentary session. In 1960, the Gentleman Usher of the Black Rod arrived to summon the House of Commons during a heated debate and several members protested against the disruption by refusing to attend the ceremony. The debacle was repeated in 1965; this time, when the Speaker left the chair to go to the House of Lords, some members continued to make speeches. As a result, the Royal Assent Act 1967 was passed, creating an additional form for the granting of royal assent. As the attorney-general explained, \"there has been a good deal of resentment not only at the loss of Parliamentary time that has been involved but at the breaking of the thread of a possibly eloquent speech and the disruption of a debate that may be caused.\" The granting of assent by the monarch in person, or by commission, is still possible, but this third form is used on a day-to-day basis.\n",
      "The Royal Assent ceremony takes place in the Senate, as the sovereign is traditionally barred from the House of Commons. On the day of the event, the Speaker of the Senate will read to the chamber a notice from the secretary to the governor general indicating when the viceroy or a deputy thereof will arrive. The Senate thereafter cannot adjourn until after the ceremony. The speaker moves to sit beside the throne, the Mace Bearer, with mace in hand, stands adjacent to him or her, and the governor general enters to take the speaker's chair. The Usher of the Black Rod is then commanded by the speaker to summon the Members of Parliament, who follow Black Rod back to the Senate, the Sergeant-at-Arms carrying the mace of the House of Commons. In the Senate, those from the commons stand behind the bar, while Black Rod proceeds to stand next to the governor general, who then nods his or her head to signify Royal Assent to the presented bills (which do not include appropriations bills). Once the list of bills is complete, the Clerk of the Senate states: \"in Her Majesty's name, His [or Her] Excellency the Governor General [or the deputy] doth assent to these bills.\" If there are any appropriation bills to receive Royal Assent, the Speaker of the House of Commons will read their titles and the Senate clerk repeats them to the governor general, who nods his or her head to communicate Royal Assent. When these bills have all been assented to, the Clerk of the Senate recites \"in Her Majesty's name, His [or Her] Excellency the Governor General [or the deputy] thanks her loyal subjects, accepts their benevolence and assents to these bills. The governor general or his or her deputy then depart parliament.\n",
      "The growing likelihood of war in Europe dominated the early reign of George VI. The King was constitutionally bound to support Prime Minister Neville Chamberlain's appeasement of Hitler. However, when the King and Queen greeted Chamberlain on his return from negotiating the Munich Agreement in 1938, they invited him to appear on the balcony of Buckingham Palace with them. This public association of the monarchy with a politician was exceptional, as balcony appearances were traditionally restricted to the royal family. While broadly popular among the general public, Chamberlain's policy towards Hitler was the subject of some opposition in the House of Commons, which led historian John Grigg to describe the King's behaviour in associating himself so prominently with a politician as \"the most unconstitutional act by a British sovereign in the present century\".\n",
      "The 1910 election saw 42 Labour MPs elected to the House of Commons, a significant victory since, a year before the election, the House of Lords had passed the Osborne judgment ruling that Trades Unions in the United Kingdom could no longer donate money to fund the election campaigns and wages of Labour MPs. The governing Liberals were unwilling to repeal this judicial decision with primary legislation. The height of Liberal compromise was to introduce a wage for Members of Parliament to remove the need to involve the Trade Unions. By 1913, faced with the opposition of the largest Trades Unions, the Liberal government passed the Trade Disputes Act to allow Trade Unions to fund Labour MPs once more.\n",
      "The Communist Party of Great Britain was refused affiliation to the Labour Party between 1921 and 1923. Meanwhile, the Liberal Party declined rapidly, and the party also suffered a catastrophic split which allowed the Labour Party to gain much of the Liberals' support. With the Liberals thus in disarray, Labour won 142 seats in 1922, making it the second largest political group in the House of Commons and the official opposition to the Conservative government. After the election the now-rehabilitated Ramsay MacDonald was voted the first official leader of the Labour Party.\n",
      "The 1923 general election was fought on the Conservatives' protectionist proposals but, although they got the most votes and remained the largest party, they lost their majority in parliament, necessitating the formation of a government supporting free trade. Thus, with the acquiescence of Asquith's Liberals, Ramsay MacDonald became the first ever Labour Prime Minister in January 1924, forming the first Labour government, despite Labour only having 191 MPs (less than a third of the House of Commons).\n",
      "The 2015 General Election resulted in a net loss of seats throughout Great Britain, with Labour representation falling to 232 seats in the House of Commons. The Party lost 40 of its 41 seats in Scotland in the face of record breaking swings to the Scottish National Party. The scale of the decline in Labour's support was much greater than what had occurred at the 2011 elections for the Scottish parliament. Though Labour gained more than 20 seats in England and Wales, mostly from the Liberal Democrats but also from the Conservative Party, it lost more seats to Conservative challengers, including that of Ed Balls, for net losses overall.\n",
      "For many years Labour held to a policy of not allowing residents of Northern Ireland to apply for membership, instead supporting the Social Democratic and Labour Party (SDLP) which informally takes the Labour whip in the House of Commons. The 2003 Labour Party Conference accepted legal advice that the party could not continue to prohibit residents of the province joining, and whilst the National Executive has established a regional constituency party it has not yet agreed to contest elections there. In December 2015 a meeting of the members of the Labour Party in Northern Ireland decided unanimously to contest the elections for the Northern Ireland Assembly held in May 2016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In surveys made in Europe and the United States, green is the color most commonly associated with nature, life, health, youth, spring, hope and envy. In Europe and the U.S. green is sometimes associated with death (green has several seemingly contrary associations), sickness, or the devil, but in China its associations are very positive, as the symbol of fertility and happiness. In the Middle Ages and Renaissance, when the color of clothing showed the owner's social status, green was worn by merchants, bankers and the gentry, while red was the color of the nobility. The Mona Lisa by Leonardo da Vinci wears green, showing she is not from a noble family; the benches in the British House of Commons are green, while those in the House of Lords are red. Green is also the traditional color of safety and permission; a green light means go ahead, a green card permits permanent residence in the United States. It is the most important color in Islam. It was the color of the banner of Muhammad, and is found in the flags of nearly all Islamic countries, and represents the lush vegetation of Paradise. It is also often associated with the culture of Gaelic Ireland, and is a color of the flag of Ireland. Because of its association with nature, it is the color of the environmental movement. Political groups advocating environmental protection and social justice describe themselves as part of the Green movement, some naming themselves Green parties. This has led to similar campaigns in advertising, as companies have sold green, or environmentally friendly, products.\n",
      "The last major attack on London was on 10/11 May 1941, on which the Luftwaffe flew 571 sorties and dropped 800 tonnes of bombs. This caused more than 2,000 fires. 1,436 people were killed and 1,792 seriously injured, which affected morale badly. Another raid was carried out on 11/12 May 1941. Westminster Abbey and the Law Courts were damaged, while the Chamber of the House of Commons was destroyed. One-third of London's streets were impassable. All but one railway station line was blocked for several weeks. This raid was significant, as 63 German fighters were sent with the bombers, indicating the growing effectiveness of RAF night fighter defences.\n",
      "YouTube relies on its users to flag the content of videos as inappropriate, and a YouTube employee will view a flagged video to determine whether it violates the site's terms of service. In July 2008, the Culture and Media Committee of the House of Commons of the United Kingdom stated that it was \"unimpressed\" with YouTube's system for policing its videos, and argued that \"proactive review of content should be standard practice for sites hosting user-generated content\". YouTube responded by stating:\n",
      "The first item of business on Wednesdays is usually Time for Reflection, at which a speaker addresses members for up to four minutes, sharing a perspective on issues of faith. This contrasts with the formal style of \"Prayers\", which is the first item of business in meetings of the House of Commons. Speakers are drawn from across Scotland and are chosen to represent the balance of religious beliefs according to the Scottish census. Invitations to address Parliament in this manner are determined by the Presiding Officer on the advice of the parliamentary bureau. Faith groups can make direct representations to the Presiding Officer to nominate speakers.\n",
      "As in the House of Commons, a number of qualifications apply to being an MSP. Such qualifications were introduced under the House of Commons Disqualification Act 1975 and the British Nationality Act 1981. Specifically, members must be over the age of 18 and must be a citizen of the United Kingdom, the Republic of Ireland, one of the countries in the Commonwealth of Nations, a citizen of a British overseas territory, or a European Union citizen resident in the UK. Members of the police and the armed forces are disqualified from sitting in the Scottish Parliament as elected MSPs, and similarly, civil servants and members of foreign legislatures are disqualified. An individual may not sit in the Scottish Parliament if he or she is judged to be insane under the terms of the Mental Health (Care and Treatment) (Scotland) Act 2003.\n",
      "A procedural consequence of the establishment of the Scottish Parliament is that Scottish MPs sitting in the UK House of Commons are able to vote on domestic legislation that applies only to England, Wales and Northern Ireland – whilst English, Scottish, Welsh and Northern Irish Westminster MPs are unable to vote on the domestic legislation of the Scottish Parliament. This phenomenon is known as the West Lothian question and has led to criticism. Following the Conservative victory in the 2015 UK election, standing orders of the House of Commons were changed to give MPs representing English constituencies a new \"veto\" over laws only affecting England.\n"
     ]
    }
   ],
   "source": [
    "for c in contexts:\n",
    "    if 'House of Commons' in c:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
