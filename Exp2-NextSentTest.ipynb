{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/17/2019 23:55:08 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/daniter/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "01/17/2019 23:55:08 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/17/2019 23:55:08 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmpaw0hm1mn\n",
      "01/17/2019 23:55:12 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "01/17/2019 23:55:14 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForNextSentencePrediction\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenized input\n",
    "text = \"Who was Jim Henson ? Jim Henson was a puppeteer\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Predict all tokens\n",
    "predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "# predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "# predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "# assert predicted_token == 'henson'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sent1, sent2):\n",
    "    # Tokenized input\n",
    "    sent1_tokens =  tokenizer.tokenize(sent1)\n",
    "    sent2_tokens =  tokenizer.tokenize(sent2)\n",
    "    tokenized_text = tokenizer.tokenize(sent1 + \" \" + sent2)\n",
    "\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "    segments_ids = [0]*len(sent1_tokens) + [1]*len(sent2_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "\n",
    "    # Predict all tokens\n",
    "    #predictions = model(torch.cat((tokens_tensor, tokens_tensor), 0), torch.cat((segments_tensors, segments_tensors), 0))\n",
    "    predictions = model(tokens_tensor,  segments_tensors)\n",
    "    #print (predictions)\n",
    "    return predictions[0][0] - predictions[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/17/2019 23:55:51 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/17/2019 23:55:51 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmpk0l90y0r\n",
      "01/17/2019 23:55:54 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "01/17/2019 23:55:56 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.5192, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"The boy went to the store and bought a fish.\"\n",
    "sent2 = \"Toys are always more fun than homework\"\n",
    "print(test(sent1,sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Can we rewrite questions with answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/dev-v2.0.json\", 'r') as handle:\n",
    "    jdata = json.load(handle)\n",
    "    data = jdata['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "questions = []\n",
    "unanswerable = []\n",
    "answerable = []\n",
    "for i in range(len(data)):\n",
    "    section = data[i]['paragraphs']\n",
    "    for sec in section:\n",
    "        context = sec['context']\n",
    "        contexts.append(context)\n",
    "        qas = sec['qas']\n",
    "        for j in range(len(qas)):\n",
    "            question = qas[j]['question']\n",
    "            questions.append(question)\n",
    "            label = qas[j]['is_impossible']\n",
    "            if label:\n",
    "                unanswerable.append((len(contexts)-1, len(questions)-1))\n",
    "            else:\n",
    "                answerable.append((len(contexts)-1, len(questions)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7530f182385c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munanswerable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munanswerable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"##\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(range(len(unanswerable)))\n",
    "c_i, q_i = unanswerable[i]\n",
    "print(contexts[c_i])\n",
    "print(\"##\"*10)\n",
    "print(questions[q_i])\n",
    "print(test(contexts[c_i], questions[q_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After World War II, under a Communist regime set up by the conquering Soviets, the \"Bricks for Warsaw\" campaign was initiated, and large prefabricated housing projects were erected in Warsaw to address the housing shortage, along with other typical buildings of an Eastern Bloc city, such as the Palace of Culture and Science, a gift from the Soviet Union. The city resumed its role as the capital of Poland and the country's centre of political and economic life. Many of the historic streets, buildings, and churches were restored to their original form. In 1980, Warsaw's historic Old Town was inscribed onto UNESCO's World Heritage list.\n",
      "####################\n",
      "What were the structures built by the Soviets typical of?\n",
      "tensor(5.2437, grad_fn=<SubBackward0>)\n",
      "CPU times: user 5.91 s, sys: 972 ms, total: 6.88 s\n",
      "Wall time: 6.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = np.random.choice(range(len(answerable)))\n",
    "c_i, q_i = answerable[i]\n",
    "print(contexts[c_i])\n",
    "print(\"##\"*10)\n",
    "print(questions[q_i])\n",
    "print(test(contexts[c_i], questions[q_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all the next sentence predictions for Squad\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from examples.run_qa_lm_finetune import BERTDataset\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForNextSentencePrediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/17/2019 23:58:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/daniter/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "Loading Squad: 100%|██████████| 35/35 [00:00<00:00, 4549.00it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "max_seq_length = 128\n",
    "train_dataset = BERTDataset(\"dataset/dev-v2.0.json\", tokenizer, seq_len=max_seq_length,\n",
    "                                     on_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/17/2019 23:58:36 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "01/17/2019 23:58:36 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /Users/daniter/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/xx/8h5l1j614vv5wmbx9fbj69wm0000gn/T/tmpgcz0song\n",
      "01/17/2019 23:58:39 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "01/17/2019 23:58:41 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "def test_multi(sent1_list, sent2_list, model):\n",
    "    # Predict all tokens\n",
    "    predictions = model(sent1_list, sent2_list)\n",
    "    #print (predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/186 [00:00<?, ?it/s]01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   *** Example ***\n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   guid: 0\n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   tokens: [CLS] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - [SEP] [MASK] what country is normandy located ? [SEP]\n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   input_ids: 101 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 102 103 2054 2406 2003 13298 2284 1029 102\n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   LM label: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1999, -1, -1, -1, -1, -1, -1, -1] \n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   Is next sentence label: 0 \n",
      "01/17/2019 23:58:41 - INFO - examples.run_qa_lm_finetune -   *** Example ***\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   guid: 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   tokens: [CLS] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian [SEP] when were the norman ##s [MASK] [MASK] ? [SEP]\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_ids: 101 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 102 2043 2020 1996 5879 2015 103 103 1029 102\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   LM label: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1999, 13298, -1, -1] \n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   Is next sentence label: 0 \n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   *** Example ***\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   guid: 2\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   tokens: [CLS] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian [SEP] [MASK] which countries [MASK] the conquered originate ? [SEP]\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_ids: 101 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 102 103 2029 3032 103 1996 11438 21754 1029 102\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   LM label: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2013, -1, -1, 2106, -1, 15342, -1, -1, -1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   Is next sentence label: 0 \n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   *** Example ***\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   guid: 3\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   tokens: [CLS] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based [SEP] who was the norse leader ? [SEP]\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_ids: 101 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 102 2040 2001 1996 15342 3003 1029 102\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   LM label: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1] \n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   Is next sentence label: 0 \n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   *** Example ***\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   guid: 4\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   tokens: [CLS] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with [SEP] [MASK] century did the norman ##s first [MASK] their separate identity ? [SEP]\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_ids: 101 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 102 103 2301 2106 1996 5879 2015 2034 103 2037 3584 4767 1029 102\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   LM label: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2054, -1, -1, -1, -1, -1, -1, 5114, -1, -1, -1, -1, -1] \n",
      "01/17/2019 23:58:42 - INFO - examples.run_qa_lm_finetune -   Is next sentence label: 0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.9191, -5.6865],\n",
      "        [ 6.1558, -5.9778],\n",
      "        [ 3.1260, -2.0181],\n",
      "        [ 6.2322, -6.1348],\n",
      "        [ 6.2923, -6.1853],\n",
      "        [ 3.4570, -2.5800],\n",
      "        [ 6.2002, -6.0441],\n",
      "        [ 6.1843, -6.1073],\n",
      "        [ 6.3741, -6.2566],\n",
      "        [ 6.3830, -6.2630],\n",
      "        [ 6.3597, -6.2517],\n",
      "        [ 6.4111, -6.3297],\n",
      "        [ 5.7352, -5.1993],\n",
      "        [ 5.5352, -4.9631],\n",
      "        [ 6.0173, -5.7273],\n",
      "        [ 6.2732, -6.1182],\n",
      "        [ 5.5546, -5.0173],\n",
      "        [ 6.2370, -6.0499],\n",
      "        [ 6.2640, -6.1043],\n",
      "        [ 6.4198, -6.3765],\n",
      "        [ 6.3961, -6.3139],\n",
      "        [ 5.4202, -4.8951],\n",
      "        [ 6.3817, -6.3047],\n",
      "        [ 6.4175, -6.3831],\n",
      "        [ 6.4491, -6.3593],\n",
      "        [ 3.4403, -2.2939],\n",
      "        [ 4.5917, -3.9043],\n",
      "        [ 3.7436, -2.5898],\n",
      "        [ 6.2464, -6.0598],\n",
      "        [ 5.9751, -5.7331],\n",
      "        [ 5.3952, -4.6008],\n",
      "        [ 6.3138, -6.2016]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, segment_ids, lm_label_ids, is_next = batch\n",
    "    print(test_multi(input_ids, segment_ids, model))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.1265, -5.9967],\n",
      "        [ 6.2441, -6.0882],\n",
      "        [ 6.1823, -5.9816],\n",
      "        [ 5.5371, -4.9621],\n",
      "        [ 6.3424, -6.2344],\n",
      "        [ 5.2208, -4.7500],\n",
      "        [ 6.2002, -6.0441],\n",
      "        [-2.1503,  4.6283],\n",
      "        [ 6.2251, -6.0152],\n",
      "        [ 6.3551, -6.2389],\n",
      "        [ 6.2981, -6.1389],\n",
      "        [ 6.3772, -6.2689],\n",
      "        [-2.1128,  4.4824],\n",
      "        [ 6.0253, -5.7061],\n",
      "        [ 6.1853, -6.0180],\n",
      "        [ 6.2732, -6.1182],\n",
      "        [ 5.8994, -5.5320],\n",
      "        [ 6.3360, -6.2196],\n",
      "        [ 6.4162, -6.3704],\n",
      "        [ 6.4157, -6.3625],\n",
      "        [ 6.4249, -6.3512],\n",
      "        [ 5.7378, -5.4084],\n",
      "        [ 6.1788, -5.9174],\n",
      "        [ 6.3058, -6.1782],\n",
      "        [ 5.4878, -4.7047],\n",
      "        [ 6.1572, -5.9165],\n",
      "        [ 5.6450, -5.2820],\n",
      "        [ 5.8424, -5.4555],\n",
      "        [ 4.9847, -4.1712],\n",
      "        [ 5.3419, -4.6825],\n",
      "        [ 6.3137, -6.0859],\n",
      "        [ 6.3559, -6.2961]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(test_multi(input_ids, segment_ids, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "old1, old2 = input_ids, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6a97281c7f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mold1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "assert old1 == input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(tensor(1999), tensor(103), 5, 121)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0cbc2598297c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0mold1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: (tensor(1999), tensor(103), 5, 121)"
     ]
    }
   ],
   "source": [
    "for i in range(5,32):\n",
    "    for j in range(128):\n",
    "        assert input_ids[i,j] ==  old1[i,j], (input_ids[i,j], old1[i,j], i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
